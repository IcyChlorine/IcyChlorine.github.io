{"pages":[{"title":"","text":"google-site-verification: googlec901bff64dbae6ea.html","link":"/googlec901bff64dbae6ea.html"}],"posts":[{"title":"Fourier方法专栏(二)-从傅里叶级数到傅里叶变换","text":"李辰剑 2020-12-14 写在前面自从大一学了傅里叶级数（并且没学好），大二的数理方法又错过了讲傅里叶变换的那节课（数理方法），就一直对傅里叶变换感觉懵懵懂懂，没学进去；虽然道理能搞懂、公式能照搬，但用起来总是感觉心里没底，缺乏信心；再加之傅里叶变换的具体方法和公式种类繁多，更让我摸不着头脑。由于计算物理要讲FFT, 便打算趁这个机会查缺补漏，把傅里叶变换没有搞懂的地方彻底搞懂（指我自己的问题），整理成笔记。 这系列笔记的内容应该包括： 从傅里叶级数到傅里叶变换的”推导“（是如何过渡过去的？） 这里便会牵涉到各种不同的傅里叶公式 ——这也是这篇笔记的内容.因此，这个系列的第一篇其实是”(二)”出于逻辑完整性，最开始的内容应该是傅里叶方法和傅里叶级数的引入，以及级数敛散性的讨论，因此这篇过渡到傅里叶变换的笔记就是(二)了; 什么？你问我(一)和后面的内容会不会填坑？我估计大概率不会(坏笑 关于傅里叶级数敛散性的一些讨论 -&gt;(一)（刘旭峰留下的坑，看了伍胜健的《数学分析II》中的相关内容才明白） 卷积的推导 -&gt; (三) DFT 和 FFT -&gt; (四) 从三角傅里叶级数到复傅里叶级数在高数课本中，给出的傅里叶级数公式为： \\label{Fourier_series} f(x)=\\frac{a_0}{2}+\\sum_{n=1}^\\infty (a_n\\cos nx+b_n \\sin nx) \\tag{1} 简单起见，我们假设函数$f(x)$没有瑕点，级数总能收敛 其中系数由积分给出： \\left\\{\\begin{array}{l} a_n=\\frac{1}{\\pi}\\int_\\pi^\\pi f(x)\\cos nx \\mathrm{d}x \\\\ b_n=\\frac{1}{\\pi}\\int_\\pi^\\pi f(x)\\sin nx \\mathrm{d}x \\\\ \\end{array}\\right.\\tag{2}这种做法的合理性来自于三角函数系的正交性: \\left\\{\\begin{array}{l} \\langle \\cos mx|\\cos nx\\rangle=\\pi\\delta_{mn},\\langle \\sin mx|\\sin nx\\rangle=\\pi\\delta_{mn} \\\\ \\langle \\cos mx|\\sin nx\\rangle=0 \\end{array}\\right.\\tag{3}其中，内积$\\langle\\cdot|\\cdot\\rangle$是由$[-\\pi, \\pi]$上的定积分定义的；对正弦函数而言，参数$n$不能为$0$, 而对余弦函数而言，$n$可以为零，但此时的正交关系为$\\langle\\cos nx|\\cos nx\\rangle=\\langle 1|1\\rangle=2\\pi$而非$\\pi$. 这个结果看上去非常美丽，但仍有一些问题： 为什么$n=0$的项要搞特殊？强迫症很痛苦啊！ 进一步来说，从数学上，为什么$n=0$的项很特殊呢？(显然我并不满足那个简单的定积分公式) 整个三角函数系看上去还是有点冗余/复杂. 如果能化成单参数的函数族就好了. 这个形式要求$f(x)$必须是以$2\\pi$为周期的函数，对一般函数不太好处理. 这个形式很不容易推广/过渡到傅里叶变换上. 所幸我这两天找到了一个巧妙的方法, 可以解决这些问题. 在$\\eqref{Fourier_series}$中，我们首先把把正弦项扔掉(或者说假定函数是偶函数)，只看余弦项: f(x)=\\frac{a_0}{2}+\\sum_{n=1}^\\infty a_n\\cos nx \\nonumber再把在正半轴上求和的余弦项分一半出来，翻到负半轴上求和： f(x)=\\sum_{n=-\\infty}^{-1}\\frac{a_n}{2}\\cos nx+\\frac{a_0}{2}+\\sum_{n=1}^{\\infty}\\frac{a_n}{2}\\cos nx=\\sum_{n=-\\infty}^\\infty \\frac{a_n}{2}\\cos nx\\tag{4}瞬间就统一了!整个式子变得更扁平化了, 那个原本搞特殊的$a_0$，现在也服服帖帖地收到求和号里去了. 但是问题还没有结束. . . 这个trick对正弦项来说并不能推广. 事实上——上式更好的用法是当作一个不严谨的insight, 作为一个入口. 我们一会儿会回来再看一个式子. 更好的做法是, 先向复数推广, 我们考虑下列复傅里叶级数: \\sum_{n=-\\infty}^{\\infty}e_ne^{inx},\\ e_n\\in\\mathbb{C}\\tag{5}函数系$(e^{inx})_{n=-\\infty}^{+\\infty}$的正交性比三角函数系更有意思, 也更令强迫症满意: \\begin{aligned} \\langle e^{imx}|e^{inx}\\rangle&=\\int_{-\\pi}^{\\pi}e^{imx}e^{inx}\\mathrm{d}x=\\int_{-\\pi}^{\\pi}e^{i(m+n)x}\\mathrm{d}x\\\\&=\\left.\\frac{e^{i(m+n)x}}{i(m+n)}\\right|_{-\\pi}^\\pi \\end{aligned}\\tag{6}等等, 这怎么好像和我们以前看到的不一样?当$m\\neq n$时上式并不一定为$0$，并没有得到我们期望的正交性. 啊, 让第二个指数项的指数加个负号就对了. . . 这不就是共轭内积的定义吗!大师我悟了!内积为什么要定义成共轭内积的样子?——不这样做, 就无法得出指数函数系$(e^{inx})_{n=-\\infty}^{+\\infty}$的正交性了. 改变后的式子为: \\begin{aligned} \\langle e^{imx}|e^{inx}\\rangle&=\\int_{-\\pi}^{\\pi}e^{imx}e^{-inx}\\mathrm{d}x=\\int_{-\\pi}^{\\pi}e^{i(m-n)x}\\mathrm{d}x\\\\ &=\\left.\\frac{e^{i(m-n)x}}{i(m-n)}\\right|_{-\\pi}^\\pi=\\frac{e^{i(m-n)\\pi}-e^{i(m-n)-\\pi}}{i(m-n)}=\\frac{2}{m-n}\\sin (m-n)\\pi=0 \\end{aligned}\\tag{7}当然, 看到分母上的$m-n$后, 我立马反应过来, 这应该是$m\\neq n$时的情况… 对于$m=n$的情况, 应该是: \\langle e^{inx}|e^{inx}\\rangle=\\int_{-\\pi}^\\pi e^{inx}e^{-inx}\\mathrm{d} x=\\int_{-\\pi}^\\pi 1\\ \\mathrm{d}x=2\\pi\\tag{8}于是统合起来就得到我们想要的函数系正交关系: \\langle e^{imx}|e^{inx}\\rangle=2\\pi\\delta_{mn}\\tag{9}值得注意的是: 这里的$mn$是任意整数, 不需要是正数;这比三角函数系更为推广. 这里的模长是$2\\pi$而不是三角函数的$\\pi$, 这是很关键的 事实上, 这是由于$e^{inx}e^{-imx}=(\\cos nx+i\\sin nx)(\\cos mx-i\\sin mx)=\\cos nx\\cos mx+\\sin nx\\sin mx$造成的(里面有三角函数的内积);”共轭”这一关键因素保证了另两项是相消的. 于是我们可以写出复数形式的、函数傅里叶级数展开: f(x)=\\sum^\\infty_{n=-\\infty}e_ne^{inx}\\tag{10}其中 e_n=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi f(x)(e^{inx})^*\\mathrm{d}x=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi f(x)e^{-inx}\\mathrm{d}x=\\frac{\\langle f(x)|e^{inx}\\rangle}{\\langle e^{inx}|e^{inx}\\rangle}\\tag{11}一般来说, $e_n$可以是复数. 为了加深对复数形式和三角形式的级数之间的关系的理解, 我们再做一讨论. 还记得前面那个被展开的三角形式傅里叶级数吗?我们换一种形式向负数展开: f(x)=\\sum_{n=-\\infty}^\\infty(c_n\\cos nx+s_n\\sin nx)\\\\=\\sum_{n=-\\infty}^\\infty(e_n\\cos nx+ie_n\\sin nx)\\label{Fourier_series_complex_form}\\tag{12}于是, 我们得到了傅里叶级数展开的两种系数关系. 在傅里叶级数的实形式$\\eqref{Fourier_series}$和复形式$\\eqref{Fourier_series_complex_form}$之间，我们有三套系数:$\\{a_0, (a_n)_{n=1}^{+\\infty}, (b_n)_{n=1}^{+\\infty}\\}, $ $\\{(c_n)_{n=-\\infty}^{+\\infty}, (s_n)_{n=-\\infty}^{+\\infty}\\}$和$(e_n)_{n=-\\infty}^{+\\infty}$. 由于傅里叶级数展开唯一，我们可以比较系数，从而给出它们之间的关系： \\left\\{\\begin{array}{l} c_{-n}+c_n=a_n,c_0=a_0\\\\-s_{-n}+s_n=b_n \\end{array}\\right., \\left\\{\\begin{array}{l} c_n=e_n\\\\s_n=ie_n \\end{array}\\right.\\tag{13}由右边可以得到$s_n=ic_n$, 带入左边的下面一式, 就可以得到$c_n$的方程组: \\left\\{\\begin{array}{l}\\label{LEQG_between_coef} c_{n}+c_{-n}=a_n,c_0=a_0\\\\ c_n-c_{-n}=-ib_n \\end{array}\\right., s_n=ic_n\\tag{14}由这一式, 我们就可以由三角形式的傅里叶级数解出复指数形式的傅里叶级数(的系数), 从而建立起了二者之间的联系. _这里是对前面的那个坑的交代_ 作为特例, 当函数为偶函数时, 正弦项$b_n$全为零, 有$c_n=c_{-n}$, 于是就可以得到之前所说的$c_n=\\frac{a_n}{2}$的形式, 通过将正数那边的级数翻转一半到负数上, 并使得形式统一(没错, 指的就是$a_0/2$你这个兔崽子). 这时的$s_n=ic_n=ia_n/2$, 正数和负数上的部分相互抵消. 可以看到, 从实到复、指标从正数(或者说自然数)推广到整数的过程是并不trivial的. 两种形式下的系数关系略显复杂(由线性方程组$\\eqref{LEQG_between_coef}$确定), 在偶函数这个特例里有一个比较简单的形式. 很巧地，指标从正数推广到整数(后面就会看到, 这是推广到傅里叶变换的不可或缺的一步)随着从实到复的推广自动完成了. 这是我始料未及的. 这在一定程度上源自于指数函数系$(e^{inx})_{n=-\\infty}^\\infty$在整数域$\\mathbb{Z}$(而不仅仅是正数域$\\mathbb{Z^+}$)上的正交性. 另一方面, 总体来说, 复指数形式的一切都比较简单, 更具有数学美和简洁性. 这表面上源自于指数含数系更好(更统一、更扁平)的正交性, 根本上则来源于 一个复数天然地包括了两个实数, 从而能携带比单个实数更多的信息 这一性质. 指数函数通过欧拉公式统括了正弦和余弦两个函数, 并使得最终的公式更为简洁. 从复傅里叶级数到傅里叶变换从三角形式到复指数形式, 我们已经向前迈进了一大步;但能处理的函数仍然仅限于周期为$2\\pi$的函数. 事实上, 对于具有任意周期$2T$的函数, 我们只要进行变换$\\hat{x}=\\frac \\pi T x\\leftrightarrow x=\\frac{T}{\\pi}\\hat{x}$ , 就可以很方便的构造出以$\\hat{x}$为自变量、以$2\\pi$为周期的函数:$g(\\hat{x})=f(\\frac{T}{\\pi}\\hat{x})=f(x)$. 相应地, 复指数傅里叶级数及其系数的生成公式为: g(\\hat{x})=\\sum^\\infty_{n=-\\infty}e_ne^{in\\hat{x}},\\quad e_n=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi g(\\hat{x})e^{-in\\hat{x}}\\mathrm{d}\\hat{x}\\tag{15}变换回$f(x)$的结果是: f(x)=\\sum^\\infty_{n=-\\infty}e_ne^{i\\frac{n\\pi}{T}x}\\\\ e_n=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi f(x)e^{-i\\frac{n\\pi}{T}x}\\mathrm{d}(\\frac{\\pi}{T}x)=\\frac{1}{2T}\\int_{-T}^T f(x)e^{-i\\frac{n\\pi}{T}x}\\mathrm{d}x\\tag{16}若令$k=\\frac{n\\pi}{T}$, 我们可以得到另一种等价的形式. 到这里, 我们完成了从定长周期到一般周期的推广.从针对周期函数的傅里叶级数到针对任意函数的傅里叶变换, 一个常用的想法是设想$T\\to\\infty$;所幸在我们的充分的前期铺垫下, 这一步会是很容易完成的. 令$T\\to\\infty$, 则周期函数$f(x)$就愈发接近任意函数;随着$T$作为分母愈发增大, $\\frac{n\\pi}{T}$就愈发稠密、愈发接近一个连续的谱. 将前述和式过渡到连续的积分形式, 就有: f(x)=\\sum^\\infty_{n=-\\infty}e_ne^{i\\frac{n\\pi}{T}x}\\to \\int_{-\\infty}^\\infty F(n)e^{i\\frac{n\\pi}{T}x}\\mathrm{d}n\\\\F(n)=\\frac{1}{2T}\\int_{T}^T f(x)e^{-i\\frac{n\\pi}{T}x}\\mathrm{d}x\\to\\frac{1}{2T}\\int_{-\\infty}^\\infty f(x)e^{-i\\frac{n\\pi}{T}x}\\mathrm{d}x\\tag{17}式中$F(n)\\in\\mathbb{C}$是$e_n$连续化的结果;其自变量$n$与$e_n$的下标是一致的, 函数的意义是在”$n$空间”中的”模式密度”. 实际情况中, 我们常常再进行一次变换, 将变量$n$替换为$k$, 以图令变量更为简洁: f(x)\\to\\int_{-\\infty}^\\infty F(k)e^{ikx}\\mathrm{d}k\\tag{18}这对$F(k), F(n)$间提出了约束关系(注意, 这说明了为什么二者会差一个系数):$F(n)\\mathrm{d}n=F(k)\\mathrm{d}k$ 考虑到$k=\\frac{\\pi}{T}x\\Leftrightarrow \\mathrm{d}k=\\frac{\\pi}{T}\\mathrm{d}n$, 带入上式我们就有$F(k)=F(n)\\frac{\\mathrm{d}n}{\\mathrm{d}k}=F(n)\\frac T\\pi$, 再带回傅里叶展开式就有: F(k)=\\frac T\\pi F(n)=\\frac1{2\\pi}\\int_{-\\infty}^\\infty f(x)e^{-ikx}\\mathrm{d}k\\\\f(x)=\\int_{-\\infty}^\\infty F(k)e^{ikx}\\mathrm{d}k\\tag{19}这就是大名鼎鼎的傅里叶变换. -OHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH!至此, 我们已经完整地推出了/过渡到了傅里叶变换的公式. 值得注意的几点包括: 这里的波数$k=\\frac{n\\pi}T$作为数学定义出现, 但仍然是与物理定义一致的. 随着$T$趋于无穷, 作为波数的$k=\\frac{n\\pi}{T}$的取值点也愈发稠密;只要考虑$F(k)$是连续函数, 我们总可以在那些无理点和没有取值的有理点补充定义, 将值补充定义为附近的有取值的$\\frac{n\\pi}{T}$点, 获得一个完整的连续函数. 这样一来, 说明$F(k)$”定义是合理的”. 通过这样推导得出的傅里叶变换, 我们自然而然地解决了正向变换中那个奇怪的负号问题($e^{-ikx}$)——它来自于复函数空间上的酉内积. 此外, 经有这一推导, 我们还自然地得出了傅里叶逆变换的公式. 它与正向变换的公式差了一个负号. (表面看上去是这样. ) 傅里叶变换有许多形式和许多种定义, 这里为了完整性列举如下： 一些书中为了对称性(说的就是你, 《数学物理方法》), 会采用另一种写法, 将正逆傅里叶变换中前面的系数统一写为$1/\\sqrt{2\\pi}$: \\mathcal{F}[f(x)]\\equiv F(k)=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}f(x)e^{-ikx}\\mathrm{d}x\\\\ \\mathcal{F}^{-1}[F(k)]\\equiv f(t)=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}F(k)e^{+ikx}\\mathrm{d}k\\\\\\tag{20} 摘自吴崇试《数学物理方法》 量子力学中， 由于宗量不同，傅里叶变换会有稍稍不同的形式: \\Phi(p)=\\frac{1}{\\sqrt{2\\pi\\hbar}}\\int_{-\\infty}^{+\\infty}\\Psi(x)e^{-ipx/\\hbar}\\mathrm{d}x\\\\ \\Psi(x)=\\frac{1}{\\sqrt{2\\pi\\hbar}}\\int_{-\\infty}^{+\\infty}\\Phi(x)e^{+ipx/\\hbar}\\mathrm{d}p\\\\\\tag{21} 定义在$n$空间上的傅里叶变换，好处是可以去掉前面的$2\\pi$系数. 一般形式为： F(n)=\\frac 1 T\\int_{-T/2}^{+T/2}f(t)e^{-i2\\pi nt/T}\\mathrm{d}t\\\\ f(t)=\\frac 1 T\\int_{-T/2}^{+T/2}F(n)e^{+i2\\pi nt/T}\\mathrm{d}n\\\\\\tag{22} 傅里叶分解可以推广到二维和三维.规律是宗量化为矢量、积分区域化为$\\mathbb{R^2},\\mathbb{R^3}$,前面的系数相应地乘以维数.例如，对于二维傅里叶变换，前述$n$空间形式化为： F(n_x,n_y)=\\frac 1 {W}\\frac 1 {H}\\int_{-W/2}^{+W/2}\\int_{-H/2}^{+H/2}f(x,y)e^{-i2\\pi nx/W}e^{-i2\\pi ny/H}\\mathrm{d}x\\mathrm{d}y\\tag{23}注意上式中我已经修改了一些变量的名字.这在图像处理中有很重要的应用. 又如, 对于量子力学中三维傅里叶变换的形式为: \\Phi(\\boldsymbol{p})=\\frac{1}{(2\\pi\\hbar)^{3/2}}\\int\\Psi(\\boldsymbol{x})e^{-i\\boldsymbol{p}\\cdot\\boldsymbol{x}/\\hbar}\\mathrm{d}\\tau\\\\ \\qquad:=\\frac{1}{(2\\pi\\hbar)^{3/2}}\\int_\\mathbb{R^3}\\Psi(\\boldsymbol{x})e^{-i\\boldsymbol{p}\\cdot\\boldsymbol{x}/\\hbar}\\mathrm{d}^3\\boldsymbol{x}\\\\\\tag{24} 总结总结一下. 以上3000字, 我们完成了这么几件事:** 将三角形式傅里叶级数拓展为复指数形式傅里叶级数 从实到复的拓展$\\mathbb{R}\\to\\mathbb{C}$ 求和指标从自然数向整数的拓展$n\\in\\mathbb{N}\\to n\\in\\mathbb{Z}$ 将固定周期函数的傅里叶级数拓展为任意周期函数的傅里叶级数 $(-\\pi, \\pi)\\to(-T, T)$ 将离散的傅里叶级数拓展为连续的傅里叶变换(及其逆变换) 从属于离散整数集的求和指标, 拓展为属于连续的实数集的积分变量:$n\\in \\mathbb{Z}\\to k\\in \\mathbb{R}$ 通过极限过程$T\\to+\\infty$完成 因而, 这一步拓展中包含了许多不严谨的部分;为$f, F$预设了许多美好的前提. 详细严谨的分析还是请参考数学分析. 傅里叶变换应用、形式繁多; 因此在最后列举了几种常用的傅里叶变换形式以供查阅. 李辰剑 2021-4-3修改","link":"/2021/04/03/Fourier%E6%96%B9%E6%B3%95%E4%B8%93%E6%A0%8F-%E4%BA%8C-%E4%BB%8E%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0%E5%88%B0%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"},{"title":"Notes: A Link Layer Protocol for Quantum Networks","text":"论文作者：Axel Dahlberg, Matthew Skrzypczyk, Tim Coopmans 等 12 人Notes by 李辰剑 2022-12-14 Contents 作者背景 论文背景 核心内容 实证评估 对工作的评价 作者背景这是一篇 2019 年发表在计算机网络顶级期刊 SIGCOMM 上的论文，方向为量子网络。近年来，量子计算和量子通信一直是研究的热点方向，而量子网络正是量子通信中的一个概念。 虽然量子网络离大规模实现还很远，但是远在荷兰的 Delft 大学的 QuTech 研究组却选择将其作为主攻方向，几乎将全部的资源押注在量子网络上，近年来也确实取得了许多前沿成果，本篇论文就是其中之一。 我观察了这篇论文的一作二作，发现他们在近五年才有了引用量，且近几年引用量快速上升。可以推测，他们是 QuTech 研究组（Delft 大学研究量子计算和量子信息的课提组）的博士生，是学术界的下一代。这篇论文目前已经获得120的引用量（数据来自 Google Scholar），得到了学界的广泛关注。这篇文章，再加上几位博士生快速上升的引用量，说明他们可能是正在升起的学术新星。 QuTech研究组官方网站链接：https://qutech.nl/ 论文背景近年来，量子计算和量子信息一直是研究的热点方向之一。量子通信是量子信息的主要部分，其目标是利用量子力学的特性（例如量子纠缠）做到超越经典通信的能力。例如，由于无法被完整克隆，量子态无法像经典信息一样被复制并发送，但利用一对提前共享的纠缠对，便可以将一个量子态从一处传送到另一处。又如，利用一对提前共享的纠缠对，只发送一个经典 bit 便可在通信双方之间传送 2 bit 信息——这又被称为“超密编码” (superdense coding)。 由此可见，纠缠对在量子通信中起着重要的作用，大多数的量子通信方案都直接依赖于它。然而，在现实世界中真正产生纠缠对并非一件容易的事，想让远距离的通信双方长时间持有纠缠对更是难上加难。困难主要包括如下几项： 单次脉冲（可以理解为硬件设备的输入）不一定能触发纠缠产生过程，往往需要重复多次。 纠缠对的一部分（纠缠光子）需要沿光纤传播，过程中会有噪声和损耗；而量子态类似模拟信息，无法像数字信息一样中继放大，因此真正通信双方获得的纠缠对总是带噪声的。 量子态极脆弱、易受环境噪声影响，因而量子态只能存储很短的时间。目前主流的技术方案可以将量子态存储数十毫秒到数秒时间——取决于不同的物理实现。如此之短的存储时间给纠缠对的产生与分发和随后的量子通信带来了极大的挑战。 面对如此多的挑战，近年来学界给出的答案是：借鉴经典计算机网络的体系结构，通过分层逐步解决问题。 经典计算机网络是一个通过分层逐步解决问题、逐步实现复杂功能的典型例子。物理层负责基本通信、链路层负责建立点对点连接、网络层负责路由和建立跨结点连接、传输层负责可靠通信，不同协议层各司其职、层层抽象，最终才将狂野的物理介质驯化为温柔可靠的计算机网络，可以在任意点对点之间进行高效、可靠的信息传输。 类比经典计算机网络的结构，研究人员设想量子通信也可以分为四个协议层：物理层负责基本的纠缠产生、屏蔽物理细节，链路层负责在光纤直接相连的节点间可靠地产生和分发纠缠对，网络层负责在任意两个节点（可能没有直接相连的链路）建立纠缠对，而最后由传输层负责利用纠缠对传送量子态，进行 quantum teleportation 等高级操作。 这篇论文的工作，便是基于现有的物理实现提出了基本的链路层协议，并对该协议进行了初步的性能分析。 我们前面提到，真实世界中的量子态是极其脆弱的。为了抑制噪声，目前量子计算的主流物理实现方案往往都需要苛刻的物理条件。超导量子比特体系结构会将整个体系冷却到 10mK 以下，远远低于液氮温度；离子阱体系则需要高真空环境，二者成本都非常高昂。然而在量子通信中，往往只需要一到二个量子比特参与纠缠，因此可以选择 量子比特数较少的 NV 色心作为物理实现方案。NV 色心是金刚石晶格中的一种缺陷结构，由于金刚石结构极其稳定，因此在室温常压条件下也能维持量子态相干。在这篇文章中，便采用了 NV 色心作为物理实验平台。 核心内容论文首先讨论了上层对链路层可能的需求，然后设计了一套链路层和物理层之间的接口，最后给出了物理层和链路层的实现。 上层需求为了定义好协议，首先需要探讨上层（网络层，或应用层）对链路层有哪些可能的需求。论文中将应用归为四类： 直接测量 (Measure Directly, MD)。纠缠对产生之后由双方节点直接测量。这种需求往往来自物理实验：例如验证贝尔不等式（今年的诺贝尔物理奖）、光子的符合测量（即测量双端同时测出光子的概率，英文为 coincidence measurement）等等。由于纠缠对产生后直接测量、不需要转移到量子存储单元中，因此这一类需求对硬件的要求较低，产生的结果质量相对较好。 生成纠缠并保持 (Create and Keep, CK)。在这种情况中，纠缠对产生并被分发到双方节点，但不直接测量，而是保存在量子存储单元中以备日后使用。随后，双方节点可以在自己的量子比特上进行量子门电路操作（即进行酉变换），从而完成量子态传送、超密编码等各式各样的任务。大部分的量子通信技术都可以归为这类需求。 发送量子比特，或量子传态 (Send Qubit, SQ)。顾名思义，生成用于发送量子比特的纠缠对。对链路层而言，链路层只负责生成纠缠而不负责随后的传态，因此这一需求和生成纠缠并保持其实是一样的。但由于量子传态这一应用意义重大，作者将其归为单独一类需求。 供网络层使用 (Network Layer, NL)。顾名思义，在相邻（有量子链路直接连接）的节点间生成纠缠对，供网络层生成距离更远的纠缠对。值得一提的是，如果 AB 节点和 BC 节点间都有共享纠缠对，那么 B 节点可以通过“纠缠交换” (entanglement swapping[3]) 将 AB 和 BC 之间的纠缠消耗掉，生成 AC 之间的共享纠缠对。这样一来，网络层便可以在没有直接链路的节点之间生成纠缠。这便是链路层生成纠缠供网络层使用的主要目的。 层间接口为了让设计协议具体实现时可以有的放矢，首先要定义好链路层协议和上层应用间的接口。 在论文中提出的接口中，上层协议在向链路层请求纠缠资源时可以给定以下参数： 对端节点。 请求类型：直接测量 (M, Create and Measure) 或生成纠缠并保持 (K, Create and Keep)。 需要的纠缠对数量。允许上层协议一次性请求多个纠缠对有利于降低请求本身的开销，从而提升吞吐量。 原子性：若请求了多对纠缠对，是否要求同时生成所有纠缠对（原子性标志设为真），或是允许逐个生成（标志设为假）。注意，由于量子存储器容量非常有限，同时请求（将原子性设为真）多个纠缠对可能会导致硬件无法实现，从而报错返回。 连续返回 (Consecutive)：若请求了多个纠缠对并允许逐个生成，是否要在每个纠缠对生成时立刻通知上层（连续返回标志设为真），或只需要在所有纠缠对生成之后统一通知上层（标志设为假）。 等待时间 $t_{\\max}$：请求纠缠的上层协议愿意等待的最大时间。 目的 ID (Purpose ID)：一个数字 ID，用来帮助上层或链路层标识每一条流。既可以帮助链路层识别上层的意图，也可以帮助上层标识某一条流，也可以起到类似端口的作用，在一条链路上帮助链路层实现多个上层应用的多路复用。 优先级：帮助链路层中的调度器 (Scheduler) 进行调度。论文中，作者将 NL 的优先级设为最高，CK 次之，MD最后。 最低保真度 (Desired Mininum Fidelity, $F_{\\min}$)：这是一个纯量子的参数，也是唯一一个量子参数。由于可以处在任意叠加态，量子比特更像模拟信息，而非数字信息。不像数字信息比特在传输中只有两种可能（正确传输或翻转出错），量子态的失真是一个连续变化的量。业界常用保真度 (Fidelity) $F\\in[0,1]$来度量。这个最低保真度便是要求链路层产生的纠缠对（两个量子比特构成的量子态）的最低质量要求。 随后，链路层向上层请求的返回会包含以下信息： 纠缠对 ID $Ent_{\\mathrm{ID}}$：用于标识每一对生成的纠缠对，便于通信双方标识纠缠对资源。在每个时刻，每个仍然存活的纠缠对的 ID 全局唯一。 量子比特 ID（只对 K 类请求有效）：类似一个指针，标识纠缠对中位于本地的量子比特在量子存储单元中的位置。 纠缠优度 (Goodness) $G$：对生成的纠缠对的保真度的估计。应有$G\\ge F_{\\min}$。由链路层中的保真度估计单元估计得到。（对 M 类请求的定义稍有不同，详见论文） 测量结果（仅对 M 类请求有效）。 生成纠缠对所花时间。 保真度估计单元估计纠缠优度所花费的时间。 当链路层无法顺利完成请求时，也可能返回以下报错信息： 若无法在请求的时间内完成任务（$t_{\\max}$太小），返回 TIMEOUT。 若要求的保真度太高，现有硬件无法完成（$F_{\\min}$太高），返回 UNSUPP。 量子存储单元全部清空也不足以存放要求的同时生成的纠缠对数量，返回 MEMEXCEEDED。 量子存储单元目前的剩余容量不足以存放要求的同时生成的纠缠对数量，返回 OUTOFMEM。 若对端节点拒绝参与，返回 DENIED。 最后，由于已经生成的纠缠对可能随着时间推移而退相干（失效），链接层也可能为此发送 EXPIRE 消息，通知上层该纠缠对已失效。 物理平台在最后进入协议实现之前，我们还要考虑一下具体的物理实现平台。事实上，物理实现的限制对随后的协议实现有着不可忽视的影响。 我们前面已经讨论过，在量子通信和量子网络中 NV 色心是一个比较经济的物理实现方案，不需要超导平台的超低温和离子阱平台的高真空。事实上，在 Delft 大学的论文作者们能接触到的也只有 NV 色心平台。下面我们简要介绍一下 NV 色心平台，重点关注这一物理平台对协议设计产生的影响。 NV 色心是金刚石晶格中的一种缺陷结构，由一个替换了碳原子的氮原子和一个相邻的碳原子空缺组成（图a），结构的英文名 Nitrogen-Vacancy Center 也由此而来。在 NV 色心中，由电子的自旋量子态构成直接通信的量子比特，由邻近的碳原子核自旋量子态构成存储用的量子态。量子态通过外加电磁波进行控制。对 NV 色心感兴趣的读者可以进一步参考[4]。 我们更关心的是 NV 色心平台上的纠缠产生过程（见图c）。NV 色心的纠缠生成可以抽象为如下过程：首先，发射一束微波脉冲，触发 NV 色心中的量子跃迁过程，生成一个纠缠态。这一过程并非百分之百成功，而是以一定概率发生，概率约在千分之一量级（这是一个极小的概率！）。纠缠态由 NV 色心中的电子和一个光子构成，电子留在 NV 色心中，而光子则沿光纤传输，负责随后与 B 生成纠缠。 通信双方（A 与 B）同时进行这一过程，生成的光子沿光纤分别传播，来到连接了 A 与 B 的中继器 H。H 在收到来自 A 与 B 的光子之后进行纠缠交换（对纠缠交换的定义见前），从而废弃两个光子，在 A 处电子和 B 处电子之间建立量子纠缠，并通知 AB 双方纠缠已经成功建立。 由于 H 没有量子存储单元可以暂存光子，双方光子必须同时到达。这要求 A 和 B 之间必须建立非常精确的时间同步——精确到纳秒。这给物理层硬件的设计带来了很大挑战。 协议实现物理层 为了让链路层可以建立在坚实的基础上，作者为链路层设计一个假象的物理层协议 MHP (Midpoint Heralding Protocal)，负责对物理设备进行基本的抽象，随后让链路层协议建立在 MHP 之上。作者设想 MHP 由专用硬件完成，类似经典计算机网络中网卡扮演的角色。为了满足精确的时间控制，MHP 有自己的时间周期，在每个周期中询问(polling)上层是否有纠缠生成需求，而不是被动等待中断。此外，由于苛刻的时间控制要求，MHP 也被设计得尽可能简化，不保存任何状态。 链路层 每个节点的链路层由协议（双方的约定）和一些其它组件构成。 一个同步的队列。一个容纳了所有来自上层的请求的队列，类似路由器中的出端队列。由前述讨论可知，链路双端必须同时触发量子过程才能生成纠缠对。因此，链路两端的节点必须持有一个内容相同的队列用于同步双方行为。这个分布式队列由经典通信进行传输和同步，且必须是确定性的，以保证双端的行为同步。 量子存储管理器。帮助链路层存储已经生成的纠缠对（中的量子比特）。 保真度估计装置。利用当前的物理参数和来自量子存储单元的信息，估计生成的纠缠对的保真度。 调度器。调度器负责为队列中的请求规划先后顺序，负责选出接下来将要完成的请求项。规划器必须是确定性的、不能依赖于概率，这是为了保证链路两端节点的行为一致。 EGP 协议。作者设计的链路层协议名为 EGP，即纠缠生成协议 (Engantlement Generation Protocol)。有了前面这么多内容的铺垫，协议的运作其实已经呼之欲出了，只需要把前面介绍的单元顺势组合即可。 EGP 的工作从收到上层的 CREATE 请求开始。首先，EGP 利用保真度估计装置估计硬件性能，并基于估计结果拒绝掉硬件无法完成的请求参数。然后，EGP 将请求加入队列并同步至对端节点。随后，调度器抽调出队列中的下一个可用请求项，指示 MHP 在下一个周期中生成纠缠，直到 MHP 成功返回。如果是 K 类（Keep，保持纠缠）请求，在这一步中还将使用量子存储管理器为生成的纠缠对规划量子存储空间。最后，EGP 得到 MHP 的「纠缠生成成功」返回后找到对应的请求项 ID（MHP的返回是异步的，类似磁盘控制器的异步返回）并向上层返回。最后返回的结果对不同的请求类型（直接测量还是保持纠缠）会稍有不同，返回参数中的拟合优度由保真度估计装置估计得到。 实证评估有了纸面上的协议之后，还需要将协议真正实现、进行实验验证，才能证明协议 1)是否能正常工作 2)是否具有优秀的性能。 测试环境论文作者采用了两种方式进行实证评估 (Evaluation)：在经典计算机上模拟量子网络，和在真正的 NV 色心物理平台上实验。首先，论文作者们在超算 Cartesius 上用量子网络模拟程序对他们提出的协议进行了模拟，得到了各种结果。随后，他们又在手头可用的 NV 色心硬件上进行了实验，与模拟数据进行了对比。模拟和实验的数据吻合地很好，共同印证数据的正确性。 值得一提的是，在 2022 年（论文实际上发表于 2019 年，但也没差几年:-）的今天，量子网络已经基本有了硬件实现，不再是只停留在纸面上的理论。作者们将他们可以使用的 NV 色心量子网络硬件称为”LAB”，即“实验室”用例。在 LAB 环境中，基于 NV 色心的节点 A 和 B 相距 2 米，分别用光纤与位于 AB 中间的中继站相连。实验环境的几个基本参数如下：俩节点间的传播时延为 9.7ns，而测量所需时间为 3.7 μs；每次触发保真度为$F=1-\\alpha$纠缠态（物理层的一次微波脉冲触发纠缠态生成的过程）的成功率约为 $p_{\\mathrm{succ}}=\\alpha\\cdot 10^{-3}$——其中 $\\alpha$ 为可调参数。$\\alpha$ 也展现了「纠缠生成成功率」和「生成纠缠态质量」之间的 tradeoff。 论文中提到的另一个量子网络用例是所谓的 QL2020。QL2020 中，计划将距离 25km 的两个欧洲城市用电信光缆建立连接，组成一个量子网络。由于距离较远，传播时延将达到 145μs。同时，由于光纤较长，光子在光纤中的损耗也将更大，为量子通讯带来更大的挑战。由于论文发表时 QL2020 尚未建成，论文作者只能基于基本参数在超算中对其进行模拟。作者也在超算中模拟了 LAB 的用例。 评估方法作者在每个 MHP 周期以如下概率向 MHP 发送纠缠生成请求，请求$k$个纠缠对： \\text{Prob}=\\frac{f_P\\cdot p_{\\mathrm{succ}}}{E\\cdot k}其中，$p_{\\mathrm{succ}}$ 是每次微波脉冲能成功生成纠缠对的概率（见前）；$E$ 是 MHP 完成某类请求需要的周期数的期望，如下表所示；$k$是请求的纠缠对数量，在小于给定参数 $k_\\max$ 的区间内随机选取；$f_P$ 是负载因子，用于研究不同负载下协议的性能表现。不同情况的具体参数见下表。 实验环境: 请求类型 LAB: MD LAB: CK/NL QL2020 MHP完成请求花费的周期数期望 1 1.1 ~16 不同的负载测试情形 LOW HIGH ULTRA 对应的负载因子数值$f_P$ 0.7 0.99 1.5 请求中，作者将最低保真度要求 $F_{\\min}$ 设为0.64。 评估结果论文中首先测试了仅有单类纠缠生成请求的情况。最终得到的各类结果中，生成纠缠对的质量（保真度）大约在0.7​上下，吞吐量大约在 6 对纠缠对/秒左右。与此相对，等待时间则糟糕得多：每一个生成纠缠对的请求至少要等待数秒才能被完成，在负载较重的情况下则可能要等待数十秒甚至上百秒才能被完成。具体数据我总结在如下表格中： 实验环境: 请求类型 LAB: MD LAB: CK/NL QL2020: MD QL2020: CK/NL 平均保真度$F_{\\mathrm{avg}}$ 0.707~0.779 0.745~0.757 0.723~0.767 0.626~0.653 实验环境: 请求类型: 负载 LAB: CK/NL: HIGH/ULTRA LAB: MD: HIGH/ULTRA LAB: NL/CK: LOW LAB: MD: LOW QL2020: *:* 平均吞吐量$th_{\\mathrm{avg}}$（纠缠对/秒） 6.05~6.47 6.51~7.094 4.44~4.72 4.86~5.22 约为LAB对应项的1/14 实验环境: 请求类型: 负载 QL2020: NL: LOW QL2020: NL: HIGH QL2020: NL: ULTRA 平均时延 10.97s 142.9s 521.5 实验环境: 请求类型: 负载 QL2020: MD: LOW QL2020: MD: HIGH QL2020: MD: ULTRA 平均时延 0.544s 3.318s 32.34s 可以看到，1)不同的情况下平均保真度基本不变，没有明显的规律 2)更高的负载带来了更高的吞吐量，但也使时延明显上升。 随后，作者又将多类纠缠生成请求 (NL/CK/MD) 混合起来，测量不同调度策略对延时的影响。结果如下图所示： 作者研究了两种不同的排队策略对延迟的影响：一种是简单的先入先出（First Come First Server, FCFS, 见上），另一种是加权队列（Weighted Fiar Queue, WFQ, 见下），NL 型请求优先级最高，CK 次之，NL 最次。可见，先入先出时不同类型的请求的延迟几乎一样。而采用加权队列时，虽然 NL 型请求的服务质量得到了保障，但 MD 类请求的延时却突破了天际，数次达到 100 秒以上。 在这一部分，我略去了很多具体的参数和结果的具体细节。如有问题，请参考原文。 对工作的评价这篇论文给出了一个量子网络的链路层模型/协议，填补了学界目前研究的空白。虽然受限于量子硬件，对协议的验证二号分析还很初步，但仍然是一篇有价值的工作。 我认为论文的闪光点有如下几个方面： 首先，论文作者在设计链路层协议的时候充分考虑了量子网络硬件的局限性，例如量子态能被存储的时间很短、双方物理硬件需要很精确的时间对齐等等。这直接导致了同步队列等设计，也让协议对未来量子网络可能的硬件更有针对性。 然后，作者还在真正的量子网络硬件（NV 色心）上进行了实验，让整个工作建立在真实的物理实现和实验数据之上，而不仅仅是通过超算模拟。物理实验的结果与超算模拟的结果吻合地很好，这又反过来印证了超算的模拟结果，让超算的其它模拟结果也更可信。由于量子计算和通信的硬件并未成熟，许多领域内的论文偏向于采用超算模拟；而能采用真实的物理平台进行实验而不仅仅用超算模拟，无疑是一个加分项。 最后，论文的结构安排非常棒。先给出物理层概述，然后基于物理层限制提出协议设计的方向和限制，再到层间接口设计、链路层组件介绍，最后引入协议，逻辑非常流畅。有了前面的铺垫，在最后给出核心内容的时候我感到非常自然，几乎没有跳跃。 在优点之外，论文的研究结果也有一些不足，还有未来研究的空间。首先，受限于研究时有限的硬件条件，论文只考虑了 NV 色心平台上的一个真实量子链路，实验验证显得有些单薄。可以想见，待未来量子网络的技术更为成熟后，会有更多的论文研究这一链路层协议在不同硬件上（距离更长的链路、更复杂的量子网络拓扑、不同的硬件平台）上的表现。 其次，从实验数据上来看，这一链路层协议的时延较高。自向链路层请求纠缠对到链路层返回，少则数秒，多则上百秒；这一时间不论是对于计算机程序还是对于用户来说都有些太长了。观察分析结果可以发现极高的时延来自于排队，类似经典网络中的 Buffer Bloat 现象。也许后续的研究可以优化协议，缓解这一问题。 参考文献此处参考文献是为了便于读者寻找资源和表明图品出处，格式并不标准，请见谅。 由于是论文笔记，因此引用原论文的地方在笔记中都没有标，只有引用其它论文会标注。 [1] 原论文 A Link Layer Protocol for Quantum Networks, Axel Dahlberg, Matthew Skrzypczyk, Tim Coopmans et. al., QuTech of Delft Univ. of Science and Technology, SIGCOMM‘19. [2] 引用图片 Concurrent Entanglement Routing for Quantum Networks: Model and Designs, Shouqian Shi, Chen Qian, SIGCOMM‘20 [3] 提出纠缠交换的论文 Experimental entanglement swapping: entangling photons that never interacted, Jian-Wei Pan（潘建伟！）, Dik Bouwmeester, Harald Weinfurter, and Anton Zeilinger, Physical Review Letters (1998). [4] NV色心综述 Diamond NV centers for quantum computing and quantum networks, Lilian Childress and Ronald Hanson, MRS Bulletin 38, 2 (2013), 134–138.","link":"/2022/12/19/Notes-A-Link-Layer-Protocol-for-Quantum-Networks/"},{"title":"S&#x3D;1&#x2F;p+1&#x2F;p^2+...的各种求法","text":"S=1/p+1/p^2+…的各种求法StarSky 2021-9-1 这是我的一个B站视频的补充材料，不过您愿意的话，直接读文章也可以。 B站视频传送门：1/3+1/9+…=1/2 ？？【manim练习作|一定要看到6分10以后】 初中时，有一天早上我坐在马桶上考虑起了这样一个问题： \\label{prob_3_series} \\frac13+\\frac19+\\cdots=?\\tag{1}在脑海中一通想象猜出答案$1/2$之后，我也不知道怎么证明，便没了主意。 进一步地，由于： \\frac12+\\frac14+\\cdots+\\frac1{2^n}=1-\\frac1{2^n}\\\\ \\Rightarrow\\frac12+\\frac14+\\cdots=1-\\frac1{2^\\infty}=1=\\frac11\\tag{2}我猜想，会不会有 \\frac1p+\\frac1{p^2}+\\cdots=\\frac1{p-1},\\forall (p\\in\\mathbb{Z})\\land (p>1)\\tag{3}呢？ 后来我去找初中数学老师，可她告诉我： “很多年没有处理极限了，我也不记得怎么做了。” 于是只好作罢。不过她当时在草稿纸上龙飞凤舞的极限符号，倒是对我产生了很深的影响——我如今还在用她的花体写极限符号。 近日为了这个问题做视频，结果除了了高中数列的标准做法，还发现了好多不同的解法。由于并不是每个解法都适合做成动画，因此多余的解法我就写到这篇博文里了。在视频中出境的是前两个解法。 I.标准解法高中数列中的标准解法。 结论（等比数列的求和公式） 对于等比数列$a_n=a_1q^{n-1}(n\\in\\mathbb N)$,前$n$项和为 \\begin{align*} S_n&=a_1+a_2+\\cdots+a_n\\\\ &= \\left\\{\\begin{array}{ll} a_1\\frac{1-q^n}{1-q} &q\\neq1\\\\ na_1 &q=1. \\end{array}\\right. \\end{align*}\\tag{4}证明$ q=1$的情况是显然的。下面考虑$q\\neq1$的情况： \\begin{align*} S_n&=a_1+a_2+\\cdots+a_n\\\\ &=a_1+a_1q+\\cdots+a_1q^{n-1}\\\\ &=a_1(1+q+\\cdots+q^{n-1}) \\end{align*}\\label{S_def}\\tag{5}于是我们需要对后面括号中的因子$(1+q+\\cdots+q^{n-1})$求和。 错位相减后，可以消除当中大多数的项，只留下一头一尾两项，于是便“完成了求和”（实质是简化了公式）： \\begin{array}{l} 1+q+\\cdots +q^{n-1}\\\\ \\phantom{1}-q-\\cdots-q^{n-1}-q^n \\end{array}=1-q^n \\\\ \\Rightarrow(1-q)(1+q+\\cdots+q^{n-1})=1-q^n\\tag{6}\\\\ \\Rightarrow1+q+\\cdots q^{n-1}=\\frac{1-q^n}{1-q}带回$\\eqref{S_def}$，就得到$S=a_1\\frac{1-q^n}{1-q}$.就求出了等比数列求和公式。上面的$(1-q)(1+q+\\cdots q^{n-1})=1-q^n=1^n-q^n$也叫$n$次方差公式——准确来说是一个变种。但这里的具体名字并不重要，关键在于通过错项相减把当中的大多数项消掉了。 进一步地，可以得到等比数列的所有项和： \\begin{align*} S:&=\\lim_{n\\to\\infty}S_n\\\\ &=\\lim_{n\\to\\infty}a_1\\frac{1-q^n}{1-q}\\\\ &= \\left\\{\\begin{array}{ll} \\frac{a_1}{1-q} & |q|","link":"/2021/09/03/S-1-p-1-p-2-%E7%9A%84%E5%90%84%E7%A7%8D%E6%B1%82%E6%B3%95/"},{"title":"Notes: Probabilistic Cloning and Identification of Linearly Inpendent Quantum States","text":"论文作者：段路明老师，郭光灿院士Notes by 李辰剑 2021-8-18 Overview一般的幺正操作不能克隆未知的量子态，除非量子态只能从一组正交的态中挑选 但这不代表加上测量之后不行！ 作为代价的是： 1.不能可靠地克隆，而受限于成功概率$\\gamma_i$; 论文作者还给出了$\\gamma_i$的理论上界 2.仍然要求量子态从一个已知的态的集合$\\{|\\Psi_1\\rangle,|\\Psi_2\\rangle,\\cdots,|\\Psi_n\\rangle\\}$中选取，并且要求这些态线性无关；不过这已经从 $\\{相互正交的态\\}$扩展到了$\\{线性无关的态\\}$ Contents No-cloning Theorem 克隆一份量子态：将测量作为投影算子使用 成功克隆的概率$\\gamma_i$的上界 克隆多份量子态 从量子态克隆到量子态分辨 Recall: Basic No-cloning TheoremNo-cloning Theorem: 不能可靠地克隆一个未知的量子态 准确来说，不存在幺正操作$U$，使得$|\\Psi_i\\rangle|\\Sigma\\rangle\\xrightarrow{U}|\\Psi_i\\rangle|\\Psi_i\\rangle,\\ \\forall|{\\Psi_i}\\rangle\\in\\mathcal{H}$ 将测量作为投影算子使用考虑幺正算符： \\newcommand\\a{\\alpha} \\newcommand\\b{\\beta} \\newcommand\\g{\\gamma} \\newcommand\\bra[1]{\\left\\langle#1\\right|} \\newcommand\\ket[1]{\\left|#1\\right\\rangle} \\newcommand\\qinner[2]{\\left\\langle#1\\right.\\left|#2\\right\\rangle} \\newcommand\\qouter[2]{\\left|#1\\right\\rangle\\left\\langle#2\\right|} \\newcommand\\state[1]{\\left|#1\\right\\rangle} \\newcommand\\diag{\\mathrm{diag}} U\\big[\\ket{\\Psi_i}\\ket{\\Sigma}\\ket{P_0}\\big]=\\sqrt{\\g_i}\\ket{\\Psi_i}\\ket{\\Psi_i}\\ket{P_0}+\\sum_jc_{ij}\\ket{\\Phi_{AB}^{(j)}}\\ket{P_j}\\label{prob_clone_proc_EASY}\\tag{1}其中$\\g_i\\in(0,1]\\subset\\mathbb{R}$,$\\ket{\\Phi_{AB}^{(j)}}$表示系统AB的不论什么奇奇怪怪的态——我们无所谓。 如果存在这样的算符$U$，在作用到系统AB上之后再对P进行测量， 测量得到$\\ket{P_0}$说明量子态克隆成功，保留AB 测量得到$\\ket{P_{j\\neq i}}$说明克隆失败，得到了一坨不想要的态，丢弃 那么我们就有$\\gamma_i$的概率能够成功克隆$\\ket{\\Psi_i}$. 问题：理论上这样的幺正算符和大于零的$\\g_i$是否存在？ 先考虑一个引理. 引理2 形如$X=[\\qinner{\\psi_i}{\\psi_j}]$的矩阵是正定的，当且仅当向量集$\\{\\ket{\\psi_i}\\}$是线性无关的；否则，就只是半正定矩阵. 引理的证明 考虑任意向量$\\alpha=[\\alpha_1,\\alpha_2,\\cdots,\\alpha_n]^T$，则 \\alpha^\\dagger X\\alpha=\\sum_{ij}\\alpha_i^*\\qinner{\\psi_i}{\\psi_j}a_j\\\\ =\\qinner{\\Psi}{\\Psi}=||\\ket{\\Psi}||^2\\ge0\\notag其中$\\ket{\\Psi}=\\sum_i\\alpha_i\\ket{\\psi_i}.$ 从而，如果$\\ket{\\psi_i}$线性相关，$\\ket{\\Psi}$可以是零向量，上式可以取到等号——矩阵$X$就只能是半正定矩阵； 反之，如果$\\ket{\\psi_i}$线性无关，上式就永远取不到等号，$X$就是彻底的正定矩阵. 前面问题的证明：（1）考虑$\\langle\\eqref{prob_clone_proc_EASY}_i|\\eqref{prob_clone_proc_EASY}_j\\rangle$拼起来构成的矩}阵方程 X^{(1)}=\\sqrt\\Gamma X^{(2)}\\sqrt\\Gamma^\\dagger+CC^\\dagger\\tag{2}其中$X^{(1)}=[\\qinner{\\Psi_i}{\\Psi_j}]$为正定矩阵，$\\sqrt\\Gamma=\\diag\\{\\sqrt{\\g_1},\\sqrt{\\g_2},\\cdots,\\sqrt{\\g_n}\\}=\\sqrt\\Gamma^\\dagger$,$X^{(2)}=\\left[\\qinner{\\Psi_i}{\\Psi_j}^2\\right]$ （2）出于连续性的考虑，只要$X^{(1)}$是正定的，那么总存在充分小的$\\{\\g_i\\}$使得$X^{(1)}-\\sqrt\\Gamma X^{(2)}\\sqrt\\Gamma^\\dagger$也是正定的 （3）于是等式可以写成$[一个厄密正定矩阵]=CC^\\dagger$，而这正是Cholesky分解，因此$C$总是有解；从而，这个矩阵方程对于$\\Gamma$是有解的。 关键：如果$\\{\\Psi_i\\}$线性无关，那$X^{(1)}$刚好是正定矩阵；如果是线性相关的话，$X^{(1)}$就只能是半正定矩阵，那么$X^{(1)}-\\sqrt\\Gamma X^{(2)}\\sqrt\\Gamma^\\dagger$就有可能不是半正定矩阵了。 （4）但是这里只说明了存在$\\Gamma$，我们需要的幺正操作$U$是否存在呢？作者给出了这样的证明： 引理1 如果有两套$\\{\\ket{\\phi_i}\\}$和$\\{\\ket{\\widetilde\\phi_i}\\}$满足 \\left\\langle\\phi_{i} \\mid \\phi_{j}\\right\\rangle=\\left\\langle\\widetilde{\\phi}_{i} \\mid \\widetilde{\\phi}_{j}\\right\\rangle, \\quad(i=1,2, \\cdots, n ; j=1,2, \\cdots, n)\\notag那么就存在幺正算符$U$使得$U\\big[\\ket{\\phi_i}\\big]=\\ket{\\widetilde{\\phi}_i}$. 引理1的证明： \\newcommand\\tphi{\\widetilde{\\phi}} \\text{let}\\; U:=\\sum_i\\qouter{\\tphi_i}{\\phi_i}.\\\\ \\Rightarrow UU^\\dagger=\\left(\\sum_i\\qouter{\\tphi_i}{\\phi_i}\\right)\\left(\\sum_j\\qouter{\\tphi_j}{\\phi_j}\\right)^\\dagger\\\\ =\\sum_{ij}\\qouter{\\tphi_i}{\\phi_i}\\qouter{\\phi_i}{\\tphi_i}\\\\ =\\sum_{ij}\\qouter{\\tphi_i}{\\tphi_i}\\qouter{\\tphi_i}{\\tphi_i}\\\\ =\\left(\\sum_i\\qouter{\\tphi_i}{\\tphi_i}\\right)^2=I^2=I.\\square\\notag根据引理，只要矩阵方程被满足了，矩阵方程左右的态构成了这两组态就满足了引理的条件，从而存在符合我们要求的幺正操作。 展望：这里的论述可以抽象为：$\\{\\ket{\\Psi_i}\\}$线性无关$\\Rightarrow$可以概率克隆。即，$\\{\\ket{\\Psi_i}\\}$线性无关是可以概率克隆的必要条件。论文中认为是充要条件；那充分性是怎么证明的呢？ 推广事实上，$\\eqref{prob_clone_proc_EASY}$可generalize为： U\\big[\\ket{\\Psi_i}\\ket{\\Sigma}\\ket{P_0}\\big]=\\sqrt{\\g_i}\\ket{\\Psi_i}\\ket{\\Psi_i}\\ket{P^{(i)}}+\\sqrt{1-\\g_i}\\ket{\\Phi_{ABP}^{(i)}}\\tag{3}其中，为了测量投影之后能得到我们想要的态，要求$\\ket{\\Phi_{ABP}^{(i)}}$与$\\ket{\\Psi_i}\\ket{\\Psi_i}\\ket{P^{(i)}}$正交；或，写成投影算子的形式： \\sum_i\\qouter{P^{(i)}}{P^{(i)}}\\ket{\\Phi_{ABP}^{(j)}}=0,\\quad\\forall j\\notag Remark 注意，这里只要求$\\ket{\\Phi_{ABP}^{(i)}}$与$\\ket{P^{(j)}}$间正交，而不需要$\\{\\ket{P^{(i)}}\\}$内部相互正交。这是因为我们只要能分辨”克隆成功”和”克隆失败“这两种情况就够了。见最后的”identification“部分。 而前述的矩阵方程相应地变为： X^{(1)}=\\sqrt\\Gamma X_P^{(2)}\\sqrt\\Gamma^\\dagger+\\sqrt{I-\\Gamma}Y\\sqrt{I-\\Gamma}^\\dagger\\tag{4}其中$Y=\\left[\\qinner{\\Psi_{ABP}^{(i)}}{\\Psi_{ABP}^{(j)}}\\right],\\ X_P^{(2)}=\\left[\\qinner{\\Psi_i}{\\Psi_j}^2\\qinner{P^{(i)}}{P^{(j)}}\\right]$ 同样可以说明，可以概率克隆，亦即存在$\\Gamma$的条件是，矩阵$X^{(1)}-\\sqrt\\Gamma X_P^{(2)}\\sqrt\\Gamma^\\dagger$半正定。 $\\gamma_i$的上界值得注意的是，条件： X^{(1)}-\\sqrt\\Gamma X_P^{(2)}\\sqrt\\Gamma^\\dagger是半正定矩阵\\label{eq:g_sup_constraint}\\tag{5}给出了对$\\Gamma$的限制，解这个不等式组就能获得一个$\\gamma_i$的上界——这个上界往往是对$\\qinner{P^{(i)}}{P^{(j)}}$依赖的。再对所有$\\ket{P^{(i)}}$求上界，就能获得一个不依赖P的上界。 例如，对$n=2$的情形，作者给出了公式： \\frac{\\gamma_{1}+\\gamma_{2}}{2} \\leq \\max _{\\left|P^{(i)}\\right\\rangle} \\frac{1-\\left|\\qinner{\\Psi_i}{\\Psi_j}\\right|}{1-\\left|\\qinner{\\Psi_i}{\\Psi_j}\\right|^2\\left|\\left\\langle P^{(1)} \\mid P^{(2)}\\right\\rangle\\right|}=\\frac{1}{1+\\left|\\qinner{\\Psi_i}{\\Psi_j}\\right|}\\label{eq:n2_g_sup}\\tag{6}其中，当且仅当$\\g_1=\\g_2$且$\\qinner{P^{(1)}}{P^{(2)}}=1$时取到等号。 引理3 二阶厄密矩阵$\\begin{pmatrix}a_{11} &amp; a_{12} \\\\a_{12}^* &amp; a_{22} \\\\\\end{pmatrix}$是半正（负）定的，当且仅当$a_{11,22}&gt;0(&lt;0)$且$|a_{12}|^2-a_{11}a_{22}\\leq0$. 将这个条件带入$n=2$时的$\\eqref{eq:g_sup_constraint}$式，再令$\\g_1=\\g_2$就能得到上式的结果。 Remark 上面的不等式是要求了$\\g_1=\\g_2$的结果，否则的话，不等式中会比较复杂，完整上界应该是$(\\g_1,\\g_2)$平面上的一条曲线（而且应该是凸的）。 展望 从前面的计算可以看到，$\\g_n$的上界的具体计算并不trivial。 给定$\\qinner{\\Psi_i}{\\Psi_j}$,如何快速有效地具体对$\\g_n$地上界进行数值计算？ 如Remark中所说，$\\g_n$的上界并不独立，而是$(\\g_1,\\g_2,…,\\g_n)$上的一个凸的超曲面——是否有进一步研究的空间？不同的$\\g_i$之间，是不是可以进行tradeoff? 这是一个非常松的上界；有没有更tight的上界估计？ 这些都是可以进行进一步研究的问题和方向。 Remark 如果有$\\{\\ket{\\Psi_i}\\}正交\\Leftrightarrow \\qinner{\\Psi_i}{\\Psi_j}=\\delta_{ij}$,那么$X^{(1)},X_P^{(2)}$退化为对角矩阵，前述的正定矩阵条件简化为： \\qinner{\\Psi_i}{\\Psi_i}-\\gamma_i\\qinner{\\Psi_i}{\\Psi_i}^2\\qinner{P^{(i)}}{P^{(i)}}\\ge0\\\\ \\Rightarrow1-\\g_i\\ge0\\tag{7}于是$\\g_i$的上界就是$100\\%$,概率克隆成为确定克隆。这说明当$\\{\\ket{\\Psi_i}\\}$正交时，$\\text{Probabilistic Cloning}$会回到$\\text{Deterministic Cloning}$的情形。 克隆一份$\\Rightarrow$克隆多份 注：前面的问题我记为【克隆一份=克隆出两份】量子态，下同。 以上的讨论针对的是【给定一份量子态、克隆出两份量子态】的问题。(A-&gt;AB)论文中称为$1\\to2$。那克隆多份——$1\\to3,1\\to m(m\\in\\mathbb{N}),甚至1\\to\\infty$有没有可能呢？ 值得注意的是，概率克隆并非是”没有风险的买卖”。以克隆如果(1-&gt;2的)概率克隆一旦失败，整个系统的态落至$\\ket{\\Phi_{ABP}^{(i)}}$,那么原来的A的状态也毁了。如果还想克隆一个态出来： 要么重新制备一个A的态$\\ket{\\Psi_i}$ 要么，如果不能制备/A的态只有一个，那就克隆不了了。 也就是说，$1\\to m+1$克隆势必比$1\\to m$克隆更困难，总体成功概率也更小$(\\g_i^{(m+1)}&lt;\\g_i^{(m)})$，或根本不能概率克隆。 作者在论文中提出，$\\{\\ket{\\Psi_i}\\}$能被克隆出$m$份的充要条件是 X^{(1)}-\\sqrt\\Gamma X_P^{(m)}\\sqrt\\Gamma^\\dagger是半正定矩阵\\tag{8}其中$X_P^{(m)}=\\left[\\qinner{\\Psi_i}{\\Psi_j}^m\\qinner{P^{(i)}}{P^{(j)}}\\right]$. 证明： 记$\\overbrace{\\ket{\\Psi}\\otimes\\ket{\\Psi}\\otimes\\cdots\\otimes\\ket{\\Psi}}^{k个}=\\ket{\\Psi}^k$. 记A为态给定的系统，$B=(B_1,\\cdots,B_{m-1})$为要克隆的系统。 扩展$1\\to2$的证明，我们考虑的幺正算符变为: U\\big[\\ket{\\Psi_i}\\ket{\\Sigma}^{m-1}\\ket{P_0}\\big]=\\sqrt{\\g_i}\\ket{\\Psi_i}^m\\ket{P^{(i)}}+\\sqrt{1-\\g_i}\\ket{\\Phi_{ABP}^{(i)}}\\tag{9}从而，对应的矩阵方程变为： X^{(1)}=\\sqrt\\Gamma X_P^{(m)}\\sqrt\\Gamma^\\dagger+\\sqrt{I-\\Gamma}Y\\sqrt{I-\\Gamma}^\\dagger\\tag{10}随后同理可证。 Remark/展望：通过公式可以发现，这里论文考虑的，是由一份量子态同时克隆出剩余$m-1$个态，即一步到位。 另一种很自然的想法是，如果克隆第二份成功，再拿这两份量子态去试图克隆第三份、第四份…乃至更多的量子态。这种克隆方案有没有进一步探究的价值呢？ 这里稍微多分析一下。假设目标设为克隆出三份量子态（即克隆两份），那么两种失败可能： 第一次克隆就失败了，原本和副本都没有了 第一次克隆成功了。这时候有两次失败的机会可以用来挥霍。如果这次克隆失败了，手头还有一份量子态；如果成功了，就成功克隆出了三份量子态 抽象一下，很容易发现这是一个经典的随机过程问题：初始在第一级楼梯，每步分别有$\\g_i$和$1-\\g_i$概率向上和向下走一级楼梯；走到第零级楼梯就宣告失败，走到$m$级楼梯就算成功。求 游戏失败&amp;成功的概率分别是多少？ 成功时花费的步数的分布列是多少？期望和方差是多少？ 再进一步的，如果想克隆出$M$个态，而手头的的设备能一次性以成功概率$\\g_i^{(m)}$克隆出$m$个量子态，那这个问题的答案又是多少？如果手头的设备克隆失败会一次性摧毁$m_d&lt;m$(而不是摧毁所有态)，那问题的答案又是多少？如果可选一次性克隆$m’\\leq m$个态，那最佳的总体克隆策略是什么？——这么奇怪的情形，不知道是不是只存在于我的胡思乱想之中。 克隆无穷份前面考虑了$\\qinner{\\Psi_i}{\\Psi_j}=\\delta_{ij}$的极限情况，下面来考虑另一个极限：$m\\to\\infty$. 如果我们可以从一个系综中获得无数份相同的量子态进行充分多次测量，那么根据概率极限定律，总是可以以任意精度确定这个量子态的具体成分，例如$\\ket{\\Psi}=\\a\\ket{0}+\\beta\\ket{1}$中的$|\\a|^2$和$|\\b|^2$.进而，对量子态的分辨、重新制备，也就变得很trivial了。——克隆出的无穷份量子态恰好能满足这个要求，因此克隆出无穷份量子态有着独特的意义。 论文中具体指出，一些量子态$\\{\\ket{\\Psi_i}\\}$是可分辨的当且仅当$X^{(1)}-\\Gamma$是半正定的；可行的$\\Gamma$矩阵构成了可能的成功分辨概率$\\{\\g_i\\}$。具体的方案是： 考虑幺正操作 U\\left[\\left|\\Psi_{i}\\right\\rangle\\left|\\Psi_{B P}^{(0)}\\right\\rangle\\right]=\\sqrt{\\gamma_{i}}\\left|\\Psi_{A B}^{(i)}\\right\\rangle\\left|P_{i}\\right\\rangle+\\sqrt{1-\\gamma_{i}}\\left|\\Phi_{A B}^{(i)}\\right\\rangle\\left|P_{n+1}\\right\\rangle, \\quad(i=1,2, \\cdots, n)\\tag{11}——其中$\\{\\ket{P_i}\\}$是正交基。 在幺正操作之后，再测量探针P，有两种结果： 得到第$i$个结果，得出结论：原来的量子态是$\\ket{\\Psi_i}$ 得到第$n+1$个结果，测量失败，原来的量子态可能也保不住 前面的系数告诉我们，成功概率是$\\g_i$. 值得注意的是，这是一个”概率测量“方案，即有可能测量失败，什么信息都得不到；但即使失败，我们也不会得到错误的结果。这里有一种在态的相似性与成功概率之间的trade-off. 对应的矩阵方程为： X^{(1)}=\\Gamma+\\sqrt{I_{n}-\\Gamma}\\left[\\qinner{\\Phi_{A B}^{(i)}}{\\Phi_{A B}^{(j)}}\\right] \\sqrt{I_{n}-\\Gamma}^{\\dagger}\\tag{12}类似前面的推理，我们可以得到结论： 这些态可以分辨\\Leftrightarrow存在幺正操作U\\Leftrightarrow X^{(1)}-\\Gamma是半正定矩阵\\tag{13}当然，也给出了$\\Gamma$需要满足的条件，从而给出了$\\g_i$的上界。 作者给出了一个例子： $\\ket{\\Psi_1}$和$\\ket{\\Psi_{2,3}}$都正交，而$\\ket{\\Psi_2},\\ket{\\Psi_3}$不正交。此时的$X^{(1)}-\\Gamma$是分块对角矩阵，那么最优的分辨概率是$\\g_1=1$，而$\\frac{\\g_2+\\g_3}{2}\\leq1-|\\qinner{\\Psi_2}{\\Psi_3}|$，当且仅当$\\g_2=\\g_3$取等。 Remark 这是做了$\\g_2=\\g_3$简化后的结果。事实上，根据引理2，可以推出更一般情况下满足的不等式是：$(1-\\g_1)(1-\\g_2)\\leq|\\qinner{\\Psi_2}{\\Psi_3}|^2$ 这再次表示，$\\g_i$的上界形式可能是比较复杂的，也许是值得进一步研究的。 另一个推论是，如果量子态都相互正交，那$\\g_i$都可以取到一，退化为确定性的分辨问题。 Remark 在分辨过程(21)中，我们要求$P_i$相互正交，但是在之前的克隆中，并不需要$P^{(i)}$内部正交，只要求$P^{(i)}\\leftrightarrow\\Phi_{ABP}{(i)}$正交。为什么可以这么做呢？背后的原因是，克隆时我们只需要分辨克隆成功、克隆失败两种情况，因此只要求成功和失败时ABP量子态所处的子空间正交即可。而在分辨问题上，我们需要分辨每一种量子态，因此需要每一个$\\left|\\Psi_{A B}^{(i)}\\right\\rangle\\left|P_{i}\\right\\rangle$都相互正交，从而对$P$测量后可以分离开来。 这个更强的正交性的结果是，矩阵$\\left[\\qinner{\\Phi_{A B}^{(i)}}{\\Phi_{A B}^{(j)}}\\qinner{P_i}{P_j}\\right]$的非对角元消失了，最后在矩阵方程中就退化为了$\\Gamma$.这是一个很有意思的结果：我们之前是假想无穷多次克隆，在$X_P^{(m)}$中令$m\\to\\infty$后非对角元$\\to0$，使得$\\sqrt\\Gamma X_P^{(m)}\\sqrt\\Gamma^\\dagger$退化为了$\\Gamma$.这里则是为了分辨，令$P_i$正交，直接得到了对角阵$\\Gamma$，有些殊途同归的意思。不过我设想的分辨和作者给出的分辨方案并不完全等价。 问题：这里的系统B是不是必须的呢？只有A和P可以吗？还是说，加入B只是为了和前面的记号保持一致呢？ 展望：作者只从理论上预言了概率克隆和概率分辨的可能性并给出了基础理论，并没有说明如何实现。具体实现这一技术，是一个很显然的后续研究方向。搜索可以发现，作者郭院士已经在实验上研制成功了”概率量子克隆机和普适量子克隆机“。 总结虽然量子信息中通过确定性演化（幺正演化）来克隆系统量子态是不可能的，但这不意味着概率克隆（引入测量）是不可能的。本文exploit了”测量后可以产生投影算符作用“这一特点，先引入探针P，幺正演化后再试图投影到克隆态。 然而测量作为投影算符这一功能，是有代价的——不确定，有失败概率。作者给出，克隆成功概率$\\g_i$的上界由如下条件确定： X^{(1)}-\\sqrt\\Gamma X_P^{(m)}\\sqrt\\Gamma^\\dagger半正定\\tag{14}作者还推广到了一组量子态可概率分辨的问题，分辨成功概率的上界由这一条件确定： X^{(1)}-\\Gamma半正定\\tag{15}注意，一个前提条件是，需要克隆/分辨的未知量子态从某个已知的有限集合中选取。而只有当这个集合中的态线性无关时，最后的这两个矩阵方程才是有解的。","link":"/2022/01/14/Notes-Probabilistic-Cloning-and-Identification-of-Linearly-Inpendent-Quantum-States/"},{"title":"Hello World","text":"这是一篇Hello World 文章! 因为有一些文章内容公式太多，不太适合放在微信公众号，于是就花了点时间，不务正业地部署了一个个人博客。既是一种新的分享自己的想法的渠道，也是微信公众号的一种延伸。 近几天应该会把这学期写的一篇关于傅里叶变换的文章和一篇关于放大电路的文章放上来，hope you enjoy reading XD. 另：既然文章名字叫Hello world，还是来喊几声hello world吧: bash:1$ printf &quot;Hello world!&quot; Python:1&gt;&gt;&gt;print(&quot;Hello world!&quot;) C++:1234567#include&lt;iostream&gt;using namespace std;int main(){ cout&lt;&lt;&quot;Hello world!&quot;&lt;&lt;endl; return 0;}","link":"/2021/04/03/hello-world/"},{"title":"从二极管到放大器-手把手教你理解放大电路","text":"李辰剑/IcyChlorine 2021-3-22 引言大二上时上了《现代电子线路及实验(上)》, 从一开始就被三极管打懵了, 自己的“电路观”被崩塌了. 但不幸的是, 打破之后, 新的电路观却并没有建立起来(至少没有建立完整), 只得懵懵懂懂地被拖着学完了放大电路. 如今时隔一年半, 我在大三下又选上了电线实验, 倒也又给我一个机会接触并了解电子电路. 于是我便打算借着这个机会, 把之前没搞清楚的一些模拟电路概念、以及难点重新梳理一下, 一来完善自己的知识结构, 二来也是为后来者铺路. 对于只学过中学电路的同学而言, 从“学前电路”(大学前电路)到大学的电子电路, 当中有着巨大的鸿沟, 学习曲线相当陡峭——因为有些概念和电路观念的转变老师不说, 教材也不写, 初来乍到很难理解. 注意: 这篇文章与物理学院选修《现代电子线路及实验(上)》的同学是最契合的; 如果你是EE专业的, 这篇文章可能对于你来说太trivial、或者太简单了, 还请选择性阅读. XD 1 晶体管这一部分主要是二极管和三极管；二者的基础知识我就不赘述了, 各个教材上汗牛充栋, 网上也有许多资料. 这里贴两个知乎的教程： 知乎：仅此一文, 看懂二极管的所有基础知识点 知乎：三极管的原理书上都讲不清楚, 为什么能被制造出来? 二极管的文章较为平庸, 是非常平常的讲解方式；三极管的文章却是非常优秀的, 提到了许多教科书都不会讲的观点. 为了进行接下来我们的讨论, 我先放几张图： PN结 这是前述知乎教程中的二极管示意图. 看似简单, 仔细想想却有着许多问题： 当中的耗尽区, 电子和空穴相互抵消=&gt;载流子耗尽形成短路. 但是同样在好进去, 有没有可能新的电子从离子实周围被电离出来, 形成电子和空穴分别向N区和P区移动, 形成电流？ 在P型半导体和N型半导体间形成了单向导通的PN结；但是我们知道, 二极管两侧相连的是金属导线(至少, 有可能是), 而金属导线的主要载流子是电子, 是一种”N型导体“. 那在金属导线与P区接触的地方, 会不会形成PN结呢？或者说, 为什么没有形成PN结呢？ NPN型三极管 上面这副图是教程中的NPN三极管示意图. 在大多数基础电子教程中, 三极管的原理是BE间加偏压(&gt;0)形成电流(从而电子运动方向E-&gt;B), 但是让C区N型半导体“兜”住大多数跑过来的电子. 这在任何一个学过中学电路——乃至电磁学电路——的人看来, 都有些奇怪, 甚至不可理喻. 向来, 在认知中, 电子运动的模型是电路, 是由电压决定了电流的大小；电子被限制在电路当中, 电压在哪里, 电子就沿着哪条路走. 然而, 在上图中, BE间加了偏压以生成电子流, 大多数电子却走了CE的通路；远离电压电阻和导纳, 却去直接操控电子的运动——这便是三极管的原理显得奇怪的地方了. 它在许多地方都与我们传统的电路观相抵触. 为了解决上述的这些问题, 或者说, 至少, 打消这些疑问以使我们能愉快地学习放大电路, 我们需要一些额外的知识, 还需要改变一下思维方式. 历史上, 最早的二极管是所谓的电子二极管(1904), 基于阴极射线原理： 电子二极管 其原理非常简单粗暴, 灯丝受热, 发出电子；但是只有一端灯丝加热, 是的这一过程只能单向进行, 从而形成单向导通的“二极管”. 灯丝加热电子逸出的图像, 虽然不在传统的电路范畴内, 但物理图像过于简单粗暴, 因此也还算能让人接受. 这种二极管体积大、加热灯丝功耗大, 还要预热…缺点非常多. 于是到了1947年, 美国人发明了如今常见的半导体二极管. 而历史上, 三极管的加工工艺也是通过不断改进, 才达到了如今的水平. NPN三极管加工工艺中, 要求中心P区“尽可能薄而面积大”, 就是通过工艺水平逆天改命. 具体来说, 就是让P区充分狭长, 从而使得运动极慢的电子可以打破简单的欧姆定律和电路规律；通过让路转得“充分急“, 让电子“开车开到路外边去”, 实现电流重定向功能. 事实上, 如果简单地将两个PN结二极管并联, 是绝对达不到NPN型三极管的效果的. 我做近物实验时, 有幸选了一项与二极管有关的实验, 需要测量二极管的各种参数；我当时想借着这个机会进一步了解一下二极管, 也顺便解决上述提到的两个问题, 于是便去下载了一本《半导体物理》电子书. 谁想, 厚厚的一本电子书从头推到尾, 从各种载流子一步一步建立理论、向前推演, 花了不知道多少时间、写了不知道多少公式、画了不知道多少图, 才得到一些简单有益的结论. 整本书建立在量子力学、固体物理和统计物理的基础上, 采用着这些前沿、精微而复杂的理论, 而远远不是各种电子教科书上采用的简单的二极管图像. 狄拉克梳、能带、载流子多子少子的连续变化……只有用这些概念, 才能真正了解PN结当中到底发生了什么. 原则 1 以上的林林总总告诉我们, 晶体管的特性并不平凡(trivial), 是因为它们不是一簇而就的, 而是许多代人慢慢改良原理、改良工艺的结果. 许多奇怪的特性看上去不太可能, 是因为它们真的不太可能. 它们今天能被放在这里供所有人使用, 本身就是人类科技进步发展的奇迹. 对此, 你： 要么——基于前述认识接受它 要么——如果想要具体了解”不可能“是怎么变成“可能”的, 想要具体了解其中的动力学, 需要花费大量的时间和心力仔细研读《半导体物理学》, 在量子力学和固体物理的基础上把事情弄清楚. 对此, 我建议的选择是： 不管你信不信, 反正我是信了. 这种信任不是盲目的相信, 不是“接触的多了”之后形成的麻木的相信；而是对前人改进了无数次的工艺的信任, 是对前人投入了心血才实现的事物的信任, 是基于科学的相信. 这里再多嘴一句. 前述的NPN型三极管中, 虽然大部分电流都能被C极收集, 但仍有小部分电流会走过BE间的通路. 那工艺能不能进一步改进, 让BE间电流更小, 或者干脆没有, 实现完全理想的电操控开关呢？答案是肯定的——这就是场效应管, 在物院的电线理论中不教. (虽然教科书上有) 2 放大电路接下来, 我们就要从晶体管出发, 一步步探寻前方未知的道路, 最终形成人类智慧的结晶——放大电路. 放大电路有什么用？我想, 这是每一个学模拟电路、放大电路的同学都会问的问题. 事实上, 我觉得现在回答这个问题为时过早；我们将会在合适的时候回顾这个问题. 事实上的事实上——我们现在连”放大”具体的含义都不清楚. 让我们从三极管开始. 三极管的输出特性曲线 这是一张晶体三极管的输出特性曲线图. 我们前面说过, 三极管是一种让电子“走歪路”的器件, 在BE-PN结间加电压, 却让集电极C收走了绝大多数电子；简而言之, 就是让$u_{BE}$打工产生电流, 却在BC间的PN结截留、让C收走绝大多数电子. 正是这种BE打工拿小头、CE集电赚大头的工作方式, 让BE-CE间的放大成为可能. 根据这个模型, 我们可以得到一个粗略的公式： i_{CE}=\\beta i_{BE}\\label{tri-coarse1:ampl}\\tag{1}其中$\\beta$表示三极管的放大系数, 往往在$10^2$量级. 这个公式当然是非常粗略的, 与上图也符合得不好；后面还将在许多地方完善, 但这是描述我们模型的第一步. 值得注意的是, 在这个模型中, 关键是电流间的控制和放大. 我们这里提前给出原则2： 原则 2(原型) 在放大电路中, 三极管是一种电流控制原件, 即, $i_{CE}$强烈的依赖于$i_{BE}$, 而非由电压决定. 这与传统的电压*决定电流、 **电压**决定电路状况*的电路范式是不同的. 为了更好地抢夺$i_{BE}$,CE间往往会加上正向电压$u_{CE}$以促使电子在电场的作用下涌向集电极C. 不难理解, 抢夺到的$i_{CE}$将会随着$u_{CE}$的增大而增大. 但事实上, 当$u_{CE}$增大到一定程度以后, 再增大, $i_{CE}$的增大就会变得非常缓慢, 仿佛遇到了一个天花板, 就好像饱和了似的. 但tricky的是, 这对应了上图中的放大区, 而饱和区却对应了曲线陡峭上升的阶段. 这是因为, 在放大区, C极对$u_{CE}$的剥削达到了极限, 也只有在这里才能稳定获得前述$i_{CE}=\\beta i_{BE}$的关系, 实现电流放大功能. 从饱和区来到放大区的临界电压成为饱和电压, 典型的数据是$u_{CE}^S=0.3V$,其中上标$S$代表饱和(Saturated).而至于饱和区的功能, 则在放大电路中一般不用, 在数字电路中较为常用. 我们发现, 实现$\\eqref{tri-coarse1:ampl}$式所描述的剥削放大并不是无条件的, 而是需要一定的$u_{CE}$条件. 这就好像资本家想要剥削工人, 完全不给工资肯定是不行的, 至少要给一些基本的足够生存的工资, 工人们才愿意为之卖命. 这一$u_{CE}$的条件, 是一个工作点, 描述了三极管实现某一功能的额外条件. 类似$u_{CE}$, 工作在放大区对$u_{BE}$也有要求. 非常简单, 要有足够的电压保证BE间的PN结能够打开——否则整个三极管都是堵住的. 这个开门电压与二极管是一致的, 一般是$u_{BE}^Q=0.7V$,其中$Q$表示工作点. 如果说前面$u_{BE}$的工作点条件是剥削条件的话, 那么这里的这个工作点条件, 我会称之为劳动力条件, 代表三极管工作的基础电压条件. 接地的NPN型三极管 到了这里, 我们已经可以设计出以三极管为核心的放大电路原型：BE间(左下两极)提供微小电流源$i_{BE}=i_{in}$, 并提供足够的开门电压$u_{BE}$,CE间提供足够的抢电子电压, 从而, CE间的电流就是被放大的电流$i_{CE}=\\beta i_{in}=i_{ampl}=i_{out}$. 但问题在于, 一般的原件要么提供电压决定电流, 要么提供电流决定电压, 哪有同时提供电压和电流的？如何同时在BE间提供/控制工作点电压和待放大的微小电流源？这是我们遇到的第一个技术难点, 为了解决这个问题, 我们需要稍微研究一下BE间的伏安特性. 三极管的输入特性曲线 我们首先简化一下记号. 由于前述的BE间电流$i_{BE}$最终从B端流出, 可以简记为$i_B$; 而同理$i_{CE}$可以简记为$i_C$. 类似地, 我们还可以定义从发射极流过的电流$i_E$——根据电流守恒定律, $i_E=i_{BE}+i_{CE}=i_B+i_C$. 上面是三极管的伏安特性曲线图, 也叫输入特性曲线图, 描述了BE间的伏安特性. 之所以叫输入特性, 是因为BE二极往往是需要放大的微小电流的输入端. 可以看到, 由于BE间是二极管结构, 伏安曲线与二极管类似, 开门后呈指数上升的态势. 同时, BE间的伏安特性并不是与集电极完全无关的, 集电极的剥削也会对输入特性有影响. 当剥削电压增大, 开门电压便会变高, 开门变得更困难, 这是不难理解的；但$u_{CE}$对输入特性的影响总体有限, 尤其是在饱和(进入放大区)之后影响更小；因此, 输入特性和输出特性是可以大致脱耦的, 即, 可近似认为放大区中输入特性曲线与$u_{CE}$无关. 有了输入特性曲线, 我们就可以确定工作点电压和输入小电流间的关系了. 这里产生了两个问题： 工作点电压和输入电流之间是有一一对应的关系的；当电压确定, 电流就无法变化；当电流变化, 电压就会不确定. 如何同时满足二者？ 曲线是非线性的, 不利于控制. 到了这里, 我们仿佛走入了死胡同. 但天才的工程师们还是想出了办法：直流偏置, 微变放大. 为了说明个中的思想, 我们先借鉴一下另一个概念. 在生物学中, 人体的内环境被总结为四个字：相对稳定, 动态平衡；具体来说, 人体的体温总体稳定在37度上下, 便于各个生物组件发挥正常作用, 但这并不妨碍人体体温会在时间跨度上有着微小变化. 例如, 睡眠时体温相对较低, 剧烈运动后体温较高而使人感到非常热. 动态的小变化并不妨碍整体处在工作点附近, 相反, 还帮助适应环境. 我们来看看这一思想是怎么被运用到三极管放大电路中的. 三极管的输入特性曲线 当$u_{BE}$大体在$0.7V+$时, 在其上叠加一个小电压信号$\\delta u_{BE}(t)\\sim mV$,那将会导致$i_{B}$的微小变化$\\delta i_B(t)$. 我们可以写出： \\delta i_B=\\left.\\frac{\\mathrm di_B(u_{BE})}{\\mathrm d u_{BE}}\\right|_{u_{BE}=u_{BE}^Q}\\cdot\\delta u_{BE}\\label{delta_ib}\\tag{2}进一步地, 三极管对电流的放大作用可以表示为： i_B=i_B^Q+\\delta i_B,i_C=i_C^Q+\\delta i_C\\\\ i_C=\\beta i_B\\\\ \\Rightarrow\\delta i_C=\\beta\\delta i_B\\label{delta_ib_ampl}\\tag{3}我们稍稍分析一下这两个公式： $\\eqref{delta_ib}$告诉我们, 我们需要操控电压$u_{BE}$来控制电流$i_B$;事实上, 这反而更方便, 因为需要被放大的往往是电压信号而非电流信号 $\\eqref{delta_ib}$还意味着, 当三极管工作在工作点$u_{BE}^Q$附近, 导数项近似为不变, 微变电压$\\delta u_{BE}$和微变电流$\\delta i_B$之间又恢复了线性关系, 这会给我们后续工作带来许多便利. 这也启发我们, 可以把这个不变的导数项等效为一个“微变电阻”$r_{BE}$, 于是我们得到： r_{BE}:=\\left(\\left.\\frac{\\mathrm di_B(u_{BE})}{\\mathrm d u_{BE}}\\right|_{u_{BE}=u_{BE}^Q}\\right)^{-1}\\\\ \\Rightarrow\\delta i_B=\\frac{\\delta u_{BE}}{r_{BE}}\\tag{4} 事实上, 工程中将直流量记为大写, 交变、微变量记为小写. 我们需要将前面的公式稍作改变以符合惯例, 只需要做替换： u_{BE}^Q\\rightarrow U_{BE}^Q,\\quad i_B^Q\\rightarrow I_B^Q\\\\ \\delta u_{BE}\\rightarrow u_{BE},\\quad \\delta i_B\\rightarrow i_B\\tag{5}即可. 其余变量类似. 我们总结一下, 可以得出原则3： 原则 3 三极管中的直流偏置和被放大的微变信号是分离的. 直流偏置提供工作点, 微变信号才是被放大的那个. 二者可以通过电压叠加“耦合”, 放大后再通过通交流的电容将交变信号提取出来. 一言以蔽之, 直流偏置, 交变放大. 到这里, 我们已经从原理上完成了三极管放大电路的构思, 剩下的问题就是如何将构思变化为实际可用的电路. 我们有两个问题： 如何提供工作点？ 如何在工作点$U_{BE}^Q$上叠加$u_{BE}(t)$？ 目前, 就被放大的微变信号而言, 仍然是电压输入-&gt;电流输出. 能否转化为电压输入-&gt;电压输出？ 第一个问题, 最简单的解决方案莫过于直接在BE间和CE间分别连两个$0.7V$和$0.5V$的电源. 但是这比较麻烦, 我们希望最好是可以通过一个$5V$或者$12V$电源, 通过分压等方法解决问题. 第二个问题也挺简单, 根据电压叠加原理, 直接在$U_{BE}^Q$上串联我们的微小信号源$u_{BE}(t)$即可. 但考虑到第一个问题的后一个要求…可能会使问题复杂化. 第三个问题, 有一个巧妙的解决方案, 所幸这里也写得下——在$i_C$流经的地方串联一个电阻$R_C$, 根据$u_R=i_CR_C$即可获得一个与$i_C$正比的电压, 再将这个电压引出来作为输出电压, 就得到了电压输出. 这个电压是否被放大了, 则取决于$R_C$等参数——希望不要得到一个更小的电压, 否则这个解决方案就破产了. 一个进一步的问题是, 电阻与CE串联时, 电阻会有分压, 随着电流变化分压也会变化, 这会不会影响到三极管？我们会不会需要解一个复杂的非线性方程？幸运的是, 由于微变电压很小, 三极管在放大区的输出电流又与$U_{CE}$关系很小(曲线很平), 因此可以近似认为三极管的输出电流不随电阻的分压变化而变化. 写了这么多文字分析, 是时候上电路图了： 提供三极管工作点的直流偏置电路分量 这只是完整电路图的一部分, 负责提供工作点条件, 亦即放大电路的“直流分量”. 下面接地是为了方便提供一个参考点, $V_{CC}$是电源, 往往是$5V$或者$12V$.$R_C$与CE端串联, 如前所述；而$R_B$则是为了通过分压提供$U_{BE}^Q$.显然, 只有通过仔细选择电阻大小才能满足工作点条件. 许多同学到了这里可能就犯了难：这既非串联, 亦非并联；而且三极管还是非线性原件, 如何分析？这里我们给出原则4： 原则 4a 不是吧阿sir, 到了大学还只会用欧姆定律求解电路？面对复杂电路, 往往无法直接整个求解；思路要开阔一些, 要善用电压压降条件列方程. 为了具体地分析这个直流分量(“分量”一词来自图论中的“强连通分量”, 本意是一个网络的子网络)电路, 我们先假定一些数据：$V_{CC}=5V,U_{CE}^S=0.5V,U_{BE}^Q=0.7V$. 有了这些还不够. 我们还需要引入三极管的两个非常奇异的特性才能方便地求解这个电路： $U_{CE}&gt;U_{CE}^Q$时, $I_C$几乎不变. 如果作近似, 那就是近似不变. BE间的伏安特性类似二极管；当$U_{BE}$增加至$U_{BE}^Q$以上时, 电流迅速增加；这个区域倒过来看, 就是电压随电流变化很小. 也就是说, 在开门后区域, BE端有稳压的功能, 可以在相当大的电流区间内强行把压降维持在$0.7V$左右. 可以看到, 这是三极管同电阻不同的地方. 进一步地, 这同小电珠等非线性伏安元件也不一样. 为了能愉快地分析这个电路, 我们还有最后一条原则要说： 原则 4b 先假设三极管工作在工作点, 然后再去解为了满足这个条件需要的电路参数；不要试图根据电源电压和电阻等参量去解三极管——由于三极管的非线性是非常不实际的. 事实上, 即使解出来了不在工作点的解, 也没有什么用, 因为并不能用来放大. 工程师们对于解决这一问题的办法可以称为鸵鸟算法——把头埋低, 不去管那些非工作点解. 做了这么多铺垫, 我们终于可以正式开始解工作点了. 根据压降条件, 我们列出方程组： \\left\\{\\begin{aligned} V_{CC}&=I_BR_B+U_{BE}\\\\ V_{CC}&=I_CR_C+U_{CE}\\\\ I_C&=\\beta I_B \\end{aligned}\\right.\\tag{6}式中, 由于三极管的第二个奇异特性, $U_{BE}$总是在$U_{BE}^Q=0.7V$左右, 因此应带入$0.7V$;而$U_{CE}$只需大于$U_{CE}^S$即可, 可以取相当大的范围, 因此数学上反而会由$V_{CC}$和$I_C$确定： U_{CE}=V_{CC}-I_CR_C=V_{CC}-\\beta I_BR_C\\tag{7}在这里, 有意思的事情在于, $U_{CE}$并没有被提供(通过电源或合适的电路设计设置合适的工作点), 而是被$I_B$所决定. 这种奇怪的感觉背后, 反映的是不同原件对于电压电流的不同弹性(Elasticity,这里借鉴了经济学中的概念). 电阻的弹性关系总是线性的, 要让多少电流通过它, 就得提供成比例的电压；但CE端间的弹性, 反映在输出特性曲线上是非常佛系的, 只要电压不要太小(即要求$U_{CE}&gt;U_{CE}^S$), 通过这点电流, 多少电压都可以. 当$I_B$增大、需要输出的$I_C$也成比例增大时, 电阻$R_C$非常强硬, 多抢走了许多电压；而三极管CE端则非常佛系, 就如同一个老实人一般, 于是分压就被抢走. 这是对$R_C$-CE这一串联线路上分压的“动力学分析”, 亦即大家中学所熟悉的电压决定电流的模式. 我进行这部分分析的原因是, 想向大家展示三极管也可以进行“动力学分析”；从电阻电路的分析方式出发分析模拟电路, 构建一个电阻电路-&gt;模拟电路的理解桥梁, 让大家不至于完全另起炉灶构建电路观, 认识到二者是可以统一的. 但如果对每个三极管电路中的地方都这样分析, 未免太过复杂. 因此, 我建议大家接受方程解, 莫问为什么. 进一步, 我们可以将交流信号源叠加上, 得到一个虽简单, 却完整的放大电路： 简单但完整的放大电路 这一电路中, 采取了两电源供电的形式, 因此方程更简单： \\left\\{\\begin{aligned} I_B^Q&=\\frac{V_{BB}-U_{BE}^Q}{R_B}\\\\ I_C^{(Q)}&=\\beta I_B^{(Q)}\\\\ U_{CE}^Q&=V_{CC}-I_C^QR_C \\end{aligned}\\right.\\tag{8}这组方程稍微变换了一下, 写成了更利于分析的形式. 激动人心的时刻到了——接下来考虑微变信号： \\begin{align} u_i=u_i(t)\\Rightarrow i_B(t)&=\\frac{u_i(t)}{R_B+r_{BE}}\\tag{9}\\\\ \\Rightarrow i_C(t)&=\\beta i_B(t)=\\frac{\\beta u_i}{R_B+r_{BE}}\\tag{10}\\\\ \\Rightarrow \\quad U_{C}&=V_{CC}-I_CR_C\\nonumber\\\\ &=V_{CC}-(I_C^Q+i_C)R_C\\tag{11}\\\\ &=V_{CC}-I_C^QR_C-\\frac{\\beta R_C}{R_B+r_{BE}}u_i\\nonumber \\end{align}这里还差一步. 我们需要将微变的小信号取出, 还需要在上图中$u_o$的“+”和三极管的C极之间接一个大电容；这样一来就可以将直流电压去除, 而取出交变电压： u_o(t)=-\\frac{\\beta R_C}{R_B+r_{BE}}u_i(t)\\tag{12}考虑三极管的$\\beta\\sim100$, 只要适当地选区电阻就可以获得$u_o&gt;&gt;u_i$.我们可以很方便地读出放大系数(没错, 它确实小于零, 这意味着反向)： \\dot{A_u}=-\\frac{\\beta R_C}{R_B+r_{BE}}\\tag{13}OHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH！到这里, 我们一步一步, 从三极管、到放大工作点、直流交流分离…一步步分析下来, 终于设计出了一个完整的放大电路. 这其中克服了许多困难, 但这都没有阻拦住我们(事实上是人类历史上电子工程师)的脚步. 这里, 还有几个地方要remark： 上文中, 我常常把“微变”和“交变”混为一谈. 这从概念上来讲当然是不对的微小的电压不一定就是交流电. 但实际上在放大电路中, 往往确实既是“微变”又是“交变”. 在本文中, 在最后加入电容之前, 放大电路只需要“微变”条件即可；但在加入电容后, 为了利用电容“通交流”的特性, 信号就必须是交变的了——不一定要是正弦交流电, 但至少相比电容要变化得足够快, 否则电容无法正常工作. 上面的放大电路, 由于$u_i$和$u_o$的“-”端都与发射极相连(一般来说$V_{BB}$会翻上去和$V_{CC}$合一, 因此$u_i,u_o$确实会共发射极), 因此又叫共射放大电路. 除了共射放大电路之外, 还有共基、共集放大电路, 这里都没有涉及. 频率特性由于本文一开始是为了电线实验而写,所以我也想写一下实验课中做的”放大器频率特性实验”的理论.但已经写了7k+字,太累了,这部分就以后再说吧. TODO","link":"/2021/04/04/%E4%BB%8E%E4%BA%8C%E6%9E%81%E7%AE%A1%E5%88%B0%E6%94%BE%E5%A4%A7%E5%99%A8-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%90%86%E8%A7%A3%E6%94%BE%E5%A4%A7%E7%94%B5%E8%B7%AF/"},{"title":"从电子双缝干涉到超导干涉(SQUID)","text":"MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: \"all\" } } }); 作者 软件所 李辰剑审核 物理所 丁兆晴发布 2024-3-25 难度 大学理科水平 ★★★★ 在超导量子计算的技术栈中，常常会出现一个名词：SQUID（超导干涉装置）。SQUID 非常重要，在量子计算、高精度磁场探测中都有应用，但原理乍一看又颇为复杂，使读者觉得食之无味、弃之可惜。于是，在这篇文章中，我将试图从电子双缝衍射和 AB 效应出发，以一种比较自然的方式引入 SQUID 的结构。 目录一 SQUID 简介 二 电子双缝衍射实验 三 Aharanov-Bohm 效应 四 超导量子干涉 (SQUID) 一 SQUID 简介SQUID 的全称是 Superconducting QUantum Interference Device, 即超导量子干涉装置。SQUID 的结构很简单，在一块复联通的（即一块挖了洞的超导体）上加上两个约瑟夫森结，便得到了最基本的 SQUID。由于电子波函数的相位会受到周遭磁场（准确来说是磁矢势）的影响，因此在当中那个洞被磁场穿过时，旁边超导体内电子对波函数的相位便会发生变化。这种变化在超导体被断开的约瑟夫森结处造成了相位差，通过约瑟夫森结的电流便会相应地发生变化，产生宏观可观测的效应。量子力学告诉我们，通过当中洞孔的磁通仅仅变化一个磁通量子 $\\Phi_0=\\frac{h}{2e}$ 时，电子波函数的相位就会变化 $2\\pi$，也就是转过”一整圈“。磁通量子的数值正比于普朗克常数、是一个非常小的物理量，这使得 SQUID 对中磁场的变化极为敏感。在普通导体中，晶格碰撞太厉害、耗散非常严重，电子波函数的相位会收到强烈的干扰，难以形成稳定干涉；因此，只有在无耗散的超导材料中，电子波函数的干涉才能稳定进行。由于最终是相位差造成了可观测效应，因此这一装置又被称为“干涉装置”。 SQUID 示意图 二 电子双缝衍射实验电子双缝衍射实验大家也许并不陌生，这可能是量子力学的科普中被出现频率最高的一个实验了。再电子双缝干涉中，单个电子的波函数同时经过双缝，在自由空间中传播、最终到达到观察平面，形成命案相间的干涉条纹。为了简化问题，不妨假设在自由空间中传播的电子是平面波（略去归一化常数），即可以写成如下的形式： \\newcommand\\vec[1]{\\boldsymbol{ #1}} \\psi(\\vec r)=e^{i\\vec p\\cdot\\vec r/\\hbar} 电子双缝干涉实验示意图 那么沿两条不同路径来到观察平面上的某一点 $x$ 时，两臂的波函数就会产生相位差： \\renewcommand\\dd{\\mathrm{d}} \\Delta\\phi_0=\\frac{1}{\\hbar}\\int_{C_1}\\vec p\\cdot\\dd\\vec l-\\frac{1}{\\hbar}\\int_{C_2}\\vec p\\cdot\\dd\\vec l = \\frac{1}{\\hbar}p\\Delta l其中 $\\Delta l$ 表示路径 $C_1$ 和 $C_2$ 的长度之差。由于相位会随着空间位置的变化而变化，因此观察平面上不同位置的波函数便会干涉相长或者相消，形成类似正弦函数的震荡变化趋势。（见左图的观察平面） 注意，电子双缝衍射和光的双缝衍射实验非常相似，只是把电磁学中双缝衍射实验的对象从光换成了电子。但关键之处在于，我们将电子看成了(i)有相位且(ii)有空间弥散的波函数，这是经典电磁学所没有考虑过的。在经典电磁学中，电子只是一个没有体积、完全聚集的点粒子，相位就更无从谈起了。 三 Aharanov-Bohm 效应在有磁场的情况下，上述实验会发生怎样的变化呢？理论物理诉我们，当电磁场存在的时候，电子的“动量”会变成 $\\vec p=m\\vec v\\to\\vec P=m\\vec v+q\\vec A$，需要带上电磁场的动量。这里的 $\\vec A$ 是一个被称为“磁矢势”的物理量。满足 \\oint_{\\partial S} \\vec A\\cdot \\dd \\vec l=\\iint_S \\vec B\\cdot\\dd \\vec S=\\Phi_S即，绕着一个曲面的磁矢势积分等于磁场在这个曲面上的面积分，也就等于这个曲面的磁通量。对磁矢势 $\\vec A$ 的详细论述我们暂且按下不表，这里我们只需要知道它和电场磁场一样是一种描述电磁场的方式，只不过略微高级一些。 如果你对技术细节感兴趣的话，在电磁场中电子波函数的薛定谔方程会相应地变为： i\\hbar\\frac{\\partial}{\\partial t}\\psi(\\vec r,t)=\\left[\\frac{(- i\\hbar\\nabla{\\color{crimson}-q\\vec A})^2}{2m}+V(\\vec r, t)\\right]\\psi(\\vec r, t)注意，红色项是新加入的。这从原理上解释了下面波函数的变化。 此时，平面波自由电子，的波函数描述也需要相应地把动量 $\\vec p$ 替换成「正则动量」$\\vec P$： \\psi(\\vec r)=e^{i\\vec{\\color{crimson}P}\\cdot\\vec r/\\hbar}这告诉我们，当空间中存在磁场时，磁场（或对应的磁矢势 $\\vec A$）也会影响电子波函数的相位。 由于 $ \\vec A(\\vec r)$ 的存在，如果 $\\vec P$ 在空间中有变化、不是常数，怎么办呢？这时只需要把空间拆成很多份，分开计算电子走过每一段路程时 $\\vec P$ 的贡献即可。反映到波函数上，就是指数上的常值矢量变成了沿空间路径的积分（和前面一样，忽略振幅的变化）： \\psi(\\vec r)/\\psi(\\vec r_0)=\\exp\\left\\{\\frac{i}{\\hbar}\\int_{\\vec r_0\\to\\vec r}\\vec P(\\vec r)\\cdot\\dd\\vec l\\right\\}假设我们在电子从小孔走向观察平面的路径之间插入一些磁场——例如，插入一根纵向的通电螺线管——那么沿两条路径到达 $x$ 的电子波函数的相位差就变为： AB 效应示意图 \\begin{align} \\Delta\\phi&=\\frac{1}{\\hbar}\\left(\\int_{C_1}\\vec P\\cdot \\dd\\vec l-\\int_{C_2}\\vec P\\cdot \\dd\\vec l\\right)\\\\ &=\\frac{1}{\\hbar}\\left(\\int_{C_1}\\vec p\\cdot \\dd\\vec l-\\int_{C_2}\\vec p\\cdot \\dd\\vec l\\right) -\\frac{q}{\\hbar}\\left(\\int_{C_1}\\vec A\\cdot \\dd\\vec l-\\int_{C_2}\\vec A\\cdot \\dd\\vec l\\right) \\end{align}注意，第一项就是我们前面计算得到的无磁场时的相位差，而第二项刚好就是沿着 ($C_1-C_2$) 闭合回路的积分 \\begin{align} &=\\Delta \\phi_0-\\frac{q}{\\hbar}\\oint \\vec A\\cdot\\dd\\vec l\\\\ &=\\Delta\\phi_0-\\frac{q}{\\hbar}\\iint \\vec B\\cdot\\dd\\vec l\\\\ &=\\Delta\\phi_0-\\frac{q}{\\hbar}\\Phi \\end{align}利用前面提到的磁矢势满足的关系，就可以把第二部分写成穿过 ($C_1-C_2$) 回路的磁通。这个式子告诉我们，如果在电子双缝干涉实验中加入磁场，那么磁场就会在原有的空间相位差之外额外引入一项相差，相差的大小取决于穿过回路的磁通。反映到干涉条纹上，便是干涉图案左右平移。Aharanov 和 Bohm 在 1959 年预言了这一现象，在 1960 年便在实验中得到证实。这一现象也因此被命名为 Aharanov-Bohm 效应，或简称 AB 效应。 AB 效应原论文，目前谷歌学术引用量已接近 1 万 顺带一提，Aharanov 在量子力学的研究中做出了许多贡献，量子计算中著名的量子随机游走也是这位大佬提出的（准确来说是提出者之一）。 Aharanov 的谷歌学术主页，提出 AB 效应的论文（第一篇）和提出量子随机游走的论文（第四篇）赫然在列 回顾整个 AB 效应，不难发现其中的关键物理效应在于磁场会影响周围电子的波函数，而且是影响相位。由于影响的方式是相位，这使得 干涉条纹对磁场的变化极为敏感。相位和一般物理量不同：一般物理量的很小的相对变化很难被检测到，例如，一根棍子的长度从 4 单位变成 4.001 单位，相对变化只有 0.25‰，很难检测。但是相位不同，不论是从 $2\\pi$ 变成 $3\\pi$ 还是从 $114514\\pi$ 变成 $114515\\pi$，反映在振幅上都是一次彻底的翻转。因此，基于相差的各种仪器往往能感受到极为灵敏的物理量变化，例如曾经用来探测以太的迈克耳孙-莫雷干涉仪、光学实验中用于高精度分光的马赫曾德尔干涉仪等等。 相位是一种很“敏感”的物理量 前文中对 AB 效应可观测现象的描述是“干涉条纹的平移”；但是稍加思考就能发现，这一实验也可以反过来用来测量磁场，而且是高精度的测量。如果我们固定地关注观察平面上某一点的相差，便会发现它只依赖于磁场，准确来说，只依赖于穿过电子波函数回路的磁通： \\Delta \\phi({\\color{crimson} \\Phi})=\\Delta\\phi_0+\\color{crimson}{\\frac{e}{\\hbar}\\Phi}相差每变化 $\\sim\\pi$，就能产生明显的宏观可观测效应。在电子双缝干涉实验中，便是使干涉条纹发生变化。注意上式中的普朗克常数 $h$：这是一个极小的物理常数，常常和世界上各种最小的量子极限联系在一起。它出现在磁通的分母上，意味着即使磁通量只变化一点点，也能让相位差产生很大的变化。经过简单的计算可以得到，基于上式原理能探测的最小磁通变化为 $\\sim 10^{-15}\\ \\mathrm{Wb}$。根据 $\\Phi=BS$ 简单估计，如果能构成一个面积为 $1\\ \\mathrm{cm}^2$ 的电子波函数回环，那么对其中磁场强度的测量灵敏度可以达到 $\\Delta B\\sim 10^{-9} \\mathrm{T}$，远超任何常规（不涉及量子效应的）磁场探测器的灵敏度！ 四 超导量子干涉 (SQUID)AB 效应——或者说带磁场的电子双缝干涉——的设计固然巧妙，但如果直接用来测量磁场，还是有着种种不便之处。电子源、双缝屏，使用起来都有些麻烦。这时，如果把 AB 效应中电子波函数的通路固定在超导环中，就得到了超导量子干涉装置(Superconducting QUantum Interference Device)，一种前者的改良版本。 双缝干涉到 SQUID 在 SQUID（的原型）中，电子干涉的上下两条路径被固定在了一个超导环中，电子的波函数沿超导环绕一圈，刚好对应了双缝干涉中电子两臂构成的闭合环路。为了让电子波函数能产生相位差，我们还需要在超导环的某处挖出一个缺口（右图的绿色部分）。如果把这个缺口连上，量子力学的基本原理会强制令两端的相位相等，相位差和干涉也就无从谈起了。 有的读者可能会好奇，如果不留缺口、两端的相位会被强制相等；但如果在环中通入磁场，又会产生相位差。这两个结论看似矛盾，究竟是怎么回事呢？ 事实上，如果把缺口连上、考虑一个完整的超导环，那么波函数连续条件会强制将环内的磁通钳制在某些特定的值上。环内的磁通量只能取磁通量子 $\\Phi_0=\\frac{h}{2e}$ 的整数倍，这种情况下波函数的相位刚好处于连续状态。这一现象被称为「磁通量子化」。 换句话说，波函数的连续性干过了磁场，电子的波函数会把磁场（准确来说是磁通）强行钳制在某些合适的值上。 如果把波函数的相位比作河流中的水位，这就好像运河中两处高低不同的水面被闸门隔断。如果把闸门打开，水就会一泻千里，直至两边的水面持平；如果想维持水位留作他用，就必须造一道闸门隔断两端的水面。 把干涉路径固定到超导环上之后，我们面临着一个新的问题：怎么观测相位差？在干涉实验中，我们有干涉条纹可以观测，但在超导环中并没有“干涉条纹”这样的东西。 在 1962 年，Josephson 预言了一种超导材料的隧穿效应：如果在两块超导材料之间夹一块足够薄的非超导材料（其实空气也算”非超导材料“），那么超导体中的电子就会在两极之间发生隧穿，隧穿产生的电流与两端的相位差有关： I=I_c\\sin\\Delta\\phi这里，$I_c$ 表示超导体的临界电流，是一个不随时空变化的常量。话句话说，如果薄层两侧的波函数没有相差，那就和两端的超导材料碰在一起的情况是相同的、什么事都不会发生；但如果在薄层的阻隔下两侧的波函数有相位差，就会产生电流，来试图平抑掉结两端的相差。整个约瑟夫森结总是倾向于回到最自然的状态，也即，波函数的相位连续、两端没有相差的状态。 这种效应被称为约瑟夫森效应，约瑟夫森也因为预言了该效应而获得了 1973 年的诺贝尔物理学奖。这种超导体-非超导体薄层-超导体的三明治一样的结构则被称为约瑟夫森结（Josephson juntcion），日后在超导量子计算机中发挥了重要的作用。 实际的 SQUID 设计。右下是约瑟夫森结和隧穿电流的示意图。 回到 SQUID。不难发现，约瑟夫森效应为 SQUID 提供了一种简单有效的观测相位差的方式：直接测电流就行了！ 测量一个闭合回路中的电流未免有些麻烦；实际上的 SQUID 设计比我们刚刚提到的原型要更复杂一些：在超导环的两端连接有额外的电极，在两个电极之间有持续不断的电流通过；而且超导环上的约瑟夫森结也从一个变成了两个。借由两端电极之间的电流和电压，SQUID 便能将磁通转化为波函数的相差，再将相差转化为电流和电压的变化，从而以接近量子极限的极高灵敏度探测周遭的磁场。 用 SQUID 探测磁场的等效电路图。其中“X”表示约瑟夫森结。图来自 wikipedia[wiki] 当 SQUID 中没有磁场穿过时，约瑟夫森结两端没有相差，外加的电流均等地穿过 SQUID 两桥上的两个约瑟夫森结，就好像什么都没发生一样。如果假设外加的电流是 $2I_0$，那么两个约瑟夫森结上的电流就分别是 $I_0$。而当磁场穿过 SQUID 中央的时候，磁场干扰电子波函数，波函数产生相差，最终相差积累在约瑟夫森结两端。还记得吗？整个约瑟夫森结总是倾向于回到最自然的状态，也即，波函数的相位连续的状态。我们先考虑两种特殊情况： 如果穿过 SQUID 的磁通足够小，那么就会产生反向的（感应）电流来抵消磁通，这和经典中的楞次定律是一致的； 如果穿过 SQUID 的磁通刚好是磁通量子 $\\Phi_0$ 的整数倍，那么就对应了相位差是 $2\\pi$ 的整数倍，这就等于没有相位差，不会有电流；看明白了吗？相位差是一个周期性的东西，约瑟夫森结只需要让两端的相差来到 $2\\pi$ 的整数倍，就能让两端的相位差连续，回到它最喜欢的状态。 明白了这一点，我们便可以考虑更一般的情况了： 如果穿过 SQUID 的磁通小于半个磁通量子，即 $\\Phi&lt;\\Phi_0/2$，那么约瑟夫森结更倾向于让磁通回到 $0$，即产生反向的感应电流 如果穿过 SQUID 的磁通小于半个磁通量子，即 $\\Phi_0/2&lt;\\Phi&lt;3\\Phi_0/2$，那么约瑟夫森结更倾向于让磁通来到$\\Phi_0$——此时对应约瑟夫森结上的相差刚好为 $2\\pi$——即产生正向的感应电流——这和经典中的电磁感应定律是相反的。 加以推广，如果穿过 SQUID 的磁通满足 $n\\Phi_0&lt;\\Phi&lt;(n+1/2)\\Phi_0$，那么会产生反向的感应电流、驱使磁通回到 $n\\Phi_0$；如果穿过 SQUID 的磁通满足 $(n+1/2)\\Phi_0&lt;\\Phi&lt;(n+1)\\Phi_0$，那么会产生正向的感应电流、驱使磁通来到 $(n+1)\\Phi_0$。这里我们还差最后一点魔法：两边都是超导电流，怎么探测电流的变化呢？解决方案也很简单：加大电流，让一部分电流变成非超导电流，这样就会在 SQUID 两端产生可探测的电压。当相位变化时，约瑟夫森结上能通过的超导电流也会相应地发生变化（即前面的“感应电流”）。当电流足够大时，就可能会超出超导材料的临界电流，产生一部分受电阻影响的普通电流 $I_{ns}$。最后，根据大家熟悉的 $V=I_{ns}R$，SQUID 两端的电压也随之发生变化，从而产生可以由电压计测量到的电压变化。不难发现，电压随磁通的变化是周期性的。这样，我们就完成了对磁通的超敏感测量。 磁通变化时 SQUID 两端电压的变化。图来自 wikipedia[wiki] 由于对磁场非常敏感，SQUID 最大的应用便是用来测量磁场。更有意思的是，什么地方会需要测量那么微弱的磁场呢？有一条令人意想不到的答案：生物。生物体内没有特别强烈的电磁活动，因此各种生物活动只能引发极微弱的磁场；但这些磁场在医学、生物学中又有着重要的应用。因此，SQUID 在测量生物磁场中得到了大量应用。早在 1970 年，便有科学家用 SQUID 测量了心脏在跳动时产生的磁场[6]。在神经科学中，SQUID 更是大显身手，成为了测量脑磁的尖端技术。 使用 SQUID 的脑磁图（MEG）设备。图片来自[5]. 准商用的 SQUID。图片来自 wiki[wiki] 除了在测量磁场方面的有应用外，SQUID 还在量子计算中找到了自己的一席之地。在上世纪末，科学家们发现一小块孤立的超导金属可以处在“里面有 $n$ 个电子对”和“里面有 $n+1$ 个电子对”的叠加态上，于是便可以用来设计量子比特。但是这样的量子比特太死板，不容易调节和控制，于是科学家们将 SQUID 和它结合起来，这样一来便可以调节穿过 SQUID 的磁通来调节量子比特的性质，从而进行量子计算。 在下图中，上面的横杆是“孤立的超导金属”，下面的大块块是电子源（和环境连通的一块很大的超导金属），二者之间的两条竖杠便是两个约瑟夫森结。约瑟夫森结、电荷孤岛、电子源构成了一个空间上的闭合环路，从而构成了 SQUID。调节磁通 $\\Phi$，便可以调节超导量子比特的性质。 电荷量子比特的显微照片。上面的横杆是“孤立的超导金属”，下面的大块块是电子源（和环境连通的一块很大的超导金属），二者之间的两条竖杠便是两个约瑟夫森结。约瑟夫森结、电荷孤岛、电子源构成了一个空间上的闭合环路，从而构成了 SQUID。通过调节中间穿过的磁通 $\\Phi$，便可以调节超导量子比特的性质，从而帮助进行量子计算。 参考文献[1, 主要参考 1] Quantum Information &amp; Quantum Optics with Superconducting Circuits, by Juan Jose Garcia Ripoll, 2022. [2, 主要参考 2] 《电动力学》（第三版），郭宏硕 著，2008. [3, wiki] Wikipedia of SQUID, https://en.wikipedia.org/wiki/SQUID. [4, AB 效应原论文] Significance of electromagnetic potentials in the quantum theory, by Y Aharonov and D Bohm, on Physical Review, in 1959. [5, SQUID 在生物磁场测量中的应用] SQUIDs in biomagnetism: a roadmap towards improved healthcare， by Rainer Körber and many other authors, on Superconductor Science and Technology, in 2016. [6] Magnetocardiograms taken inside a shielded room with a superconducting point-contact magnetometer, by David Cohen and Edgar A. Edelsack and James E. Zimmerman, on Applied Physics Letters, in 1970.","link":"/2024/03/25/%E4%BB%8E%E7%94%B5%E5%AD%90%E5%8F%8C%E7%BC%9D%E5%B9%B2%E6%B6%89%E5%88%B0%E8%B6%85%E5%AF%BC%E5%B9%B2%E6%B6%89(SQUID)/"},{"title":"Linux-0.11 源码解析与思考题","text":"拟题 杨力祥老师初稿 李效宇同学整理&amp;终稿 李辰剑 2022-12-31 写在前面写作背景这篇笔记来源于这学期的操作系统课程。课程上，杨老师带同学们一起手撕早期版本的 Linux 源代码，非常刺激。 杨老师在期末前出了很多思考题，供同学们参考、复习。李效宇同学则花了不少功夫，结合上课内容和网上资料，整理了所有思考题的答案，分享给同学。 李效宇同学的原文链接：https://lixiexie.notion.site/dbfc366cee8f4931bfa33d414b1132f9 我看到了这篇长文之后觉得内容很棒，便决定转载到自己的博客上。于是我对内容进行了全面的修订，最终得到了这篇文章。 修订内容本以为只是修改一些错别字和优化排版，没有想到最后却成为了大工程，花费了我小半个学期。对文本的修订和优化包括： 修订了一些错别字、并对文字进行了润色，让文字更书面化。 对代码使用了程序环境进行排版，优化了总体排版。 修改了一些错误答案，例如“25. 为什么 static inline _syscall0(type,name) 中需要加上关键字 inline？”——实际原因不是优化性能，而是与写时复制 (CoW, Copy on Write) 机制有关。 重写/扩充了一些问题的答案。 对思考题顺序进行了调整，让问题之间的逻辑更紧密连贯。想按寻找某道特定思考题答案的同学，可以参考文末附录：「思考题调整前后编号对照表」。 将许多图片替换为了高清版本，增加了一些示意图。 添加了参考文献。 阅读指南文中有许多内容是对 Linux-0.11 源代码的解析，还有一部分是对 Intel IA-32 体系结构的分析。对于没有阅读过 Linux 源代码的读者来说可能有些难懂。我建议读者的阅读方法有如下几种： 对计算机感兴趣但不熟悉 Linux 源码也不愿意花费太多时间的读者，可以不求甚解地阅读。文中有一些 IA-32 体系结构相关的内容，也许能拓宽你的知识面，帮助你理解计算机体系结构。文中有一些关于 Linux 操作系统设计思路的内容，也许能向你展现操作系统的具体实现，帮你把抽象的操作系统概念落到具体的实现上。 了解 Linux 源码，或者准备认真研读的读者，可以配合文末给出的参考资料（即参考文献）阅读。赵炯博士的《Linux内核完全注释》是一本功力极为深厚的 Linux 源码解析专著，我强力推荐。杨力祥老师的《Linux内核设计的艺术》则与文中的思考题思路最为契合。最后，解析 Linux 源码最少不了的便是 Linux 源码本身和 Intel IA-32 芯片手册——后者是当时乃至当今绝大多数操作系统的体系结构基础。源码和《完全注释》可以在 www.oldlinux.org 获得，其余资料也大都可以从网上获得。如果你想偷懒，也可以向我发邮件要资料。我的邮箱是 icy_chlorine@pku.edu.cn。 对于正在上/上过杨老师操作系统课的同学，你阅读整篇文章应该没有太大的障碍。根据杨老师上课的思路或者《Linux内核设计的艺术》书中的思路走即可。 记号约定： 寄存器用带百分号的代码环境表示，如 %eip, %eax。 函数、变量、标识符、内存地址用程序环境排版，如 main(), dir, 0x7c00。 体系结构中的专有概念（如全局描述符表 GDT、基本输入输出系统 BIOS）用一般环境排版。 Linus 时代多使用 8 空格长的 tab 缩进，而如今的编辑器大都默认使用 4 个空格缩进，并将 tab 页渲染为四个空格长的空白。为了让代码和注释能正常对齐，将代码中的缩进全部替换为了与当时等长的空格。 引用代码中，用 C++ style 注释（//...）表示我们添加的注解，以和 Linux 源代码中的 C style 注释（/*...*/）区分。 Part I 启动与 Intel IA-32 体系结构1. 为什么开始启动计算机的时候，执行的是 BIOS 代码而不是操作系统自身的代码？计算机只能从内存中运行程序，而无法直接从软盘或者硬盘中运行程序。不幸的是，计算机刚启动的时候，内存中空空如也、没有任何程序，需要将程序本身先加载进内存当中。这部分操作就由 BIOS(Basic Input/Output System) 完成。加电后， BIOS 完成一些硬件检测工作，设置实模式下的中断向量表和服务程序，并将操作系统的引导扇区加载至内存地址 0x7C00 处，然后将跳转至 0x7C00 运行操作系统的代码。 “实模式”是对 Intel x86 体系结构而言的 BIOS 程序存放在只读存储器 ROM(Read Only Memory) 中。ROM 断电后也能保持信息，但不能改变数据（或修改数据很困难），适合存放 BIOS 这种不需要修改的例行工作。通过内存映射，可以让处理器在上电后最先执行 ROM 中的程序，所以计算机启动最开始运行的是 BIOS 代码。BIOS 在计算机上电启动和操作系统代码之间增加了一层 indirection，使得同样的硬件上可以运行不同的操作系统。 2. 为什么 BIOS 只加载了一个扇区，后续扇区却是由 bootsect 代码加载？为什么 BIOS 没有直接把所有需要加载的扇区都加载？ bootsect, setup, head 指 bootsect.s, setup.s, head.s 编译以后形成的二进制可执行文件。 BIOS 和操作系统的通常由不同团队开发，按固定的规则约定，可以灵活的设计各自相应的部分。而“BIOS 运行后，只从启动扇区将代码加载至 0x7c00 位置”，便是 BIOS 和操作系统之间相互接洽的约定。以 Linux0.11 为例，后续的扇区由 bootsect 代码加载，这些代码由编写系统的用户负责，与 BIOS 无关。 这样构建的好处是站在整个体系的高度，统一设计和统一安排，简单而有效。BIOS 和操作系统的开发都可以遵循这一约定，灵活地进行各自的设计。例如，BIOS 可以不用知道内核镜像的大小以及其在软盘的分布等等信息，减小了 BIOS 程序的复杂度，降低了硬件上的开销。而操作系统的开发者也可以按照自己的意愿，内存的规划等等都更为灵活。另外，如果要使用 BIOS 进行加载，而且加载完成之后再执行，则需要很长的时间，此外，对于不同的操作系统，其代码长度不一样，可能导致操作系统加载不完全。因此 Linux 采用的是边执行边加载的方法。 3. 为什么 BIOS 把 bootsect 加载到 0x07c00，而不是 0x00000？加载后又马上挪到 0x90000 处，是何道理？为什么不一次加载到位？ 若未加说明，十六进制地址默认为内存中地址。 加载到 0x07c00 是 BIOS 提前约定设置的。 BIOS 把 bootsect.s 加载到 0x07c00 而不是 0x00000，是因为 0x00000 处存放着 BIOS 构建的 1k 大小的中断向量表和 256B 的 BIOS 数据区，这些数据还有用处，不能覆盖。 BIOS把 bootsect.s 加载到 0x07c00 而不是内存高地址处，是因为早期的计算机（IBM兼容机）只有64KB 内存，高地址端为0x7fff。为了把尽量多的连续内存留给操作系统，BIOS 就将读取的数据放到了当时内存地址的尾部。随着计算机的发展，这一约定被保留了下来，于是 BIOS 便一直约定将引导扇区加载到 0x7c00 处[6]。 加载后又挪到 0x90000，是因为操作系统规划在内存 0x90000 处存放 bootsect，然后 bootsect 执行结束之后，立即将系统机器数据存放在此处，这样就可以及时回收寿命结束的程序占据的内存空间。而且后续会把120K的系统模块存放到 0x00000 处，这会覆盖 0x07c00 处的代码和数据。 不一次加载到位的原因是由于“两头约定”和“定位识别”，所以在开始时 bootsect “被迫”加载到 0x07c00 位置。随后将自身移至 0x90000 处，说明操作系统开始根据自己的需要安排内存了。 4. bootsect、setup、head程序之间是怎么衔接的？给出代码证据。 bootsect→setup 程序：jmpi 0,SETUPSEG bootsect 首先利用 int 0x13 中断分别加载 setup 程序及 system 模块，待 bootsect 程序的任务完成之后，执行代码 jmpi 0,SETUPSEG。由于 bootsect 将 setup 段加载到了 SETUPSEG:0 （即0x90200），在实模式下，CS:IP 指向 setup 程序的第一条指令，此时 setup 开始执行。 setup→head 程序：jmpi 0,8 执行 setup 后，内核被移到了 0x00000 处，系统进入了保护模式，执行 jmpi 0,8 并加载了中断描述符表和全局描述符表 lidt idt_48; 1gdt gdt_48。在保护模式下，一个重要的特征就是根据 GDT 决定后续执行哪里的程序。该指令执行后跳转到以 GDT 第 2 项中的 base_addr 为基地址，以 0 为偏移量的位置，其中 base_addr 为 0。由于 head 放置在内核的头部，因此程序跳转到 head 中执行。 5. setup 程序的最后是jmpi 0,8 ，为什么这个8不能简单的当作阿拉伯数字 8 看待，有什么内涵？此时为 32 位保护模式，0 表示段内偏移，8 表示段选择符。这里8要转化为二进制：1000，最后两位00表示内核特权级（若是 11 则表示用户），第三位 0 表示 GDT 表（若是 1 则表示 LDT 表），第四位 1 表示根据 GDT 中的第2项来确定代码段的段基址和段限长等信息。可以得到代码是从 head 的开始位置，段基址 0x00000000、偏移为 0 处开始执行的，即 head 的开始位置。 6. 保护模式在“保护”什么？它的“保护”体现在哪里？特权级的目的和意义是什么？分页有“保护”作用吗？ 保护模式在“保护”什么？它的“保护”体现在哪里？ 保护操作系统的安全，不受到恶意攻击。保护进程地址空间相互不干扰。早期的操作系统没有指令集的保护，只是运行在计算机上的一个普通服务程序而已。应用程序甚至可以“干掉”操作系统，释放 OS 占用的内存，来满足自身的需求[7]。 打开保护模式后，CPU 的寻址模式发生了变化，基于全局描述符表 GDT 去获取代码或数据段的基址限长，不同段不能被随意访问。这防止了对代码或数据段的覆盖以及代码段自身的访问超限，明显增强了保护作用。保护模式下的处理器对描述符所描述的对象进行保护：在 GDT、 LDT 及 IDT 中，均有对应界限、特权级等概念，这是对描述符所描述的对象的保护。在不同特权级间访问时，系统会对 CPL、 RPL、 DPL、 IOPL 等进行检验，特权级不够的代码无法访问高权限的段。同时，处理器页会限制某些特殊指令如 lgdt, lidt, cli 等的使用；分页机制中， PDE 和 PTE 中的 R/W 和 U/S 等位提供了页级保护，分页机制通过将线性地址与物理地址的映射，提供了对物理地址的保护。 特权级的目的和意义是什么？ 特权级机制目的是为了进行合理的管理资源，保护高特权级的段。其中操作系统的内核处于最高的特权级。 特权级机制对系统进行了保护，对操作系统的“主奴机制”影响深远。Intel 从硬件上禁止低特权级代码段使用部分关键性指令，例如禁止用户进程使用 cli、 sti 等对掌控局面至关重要的指令。这使得操作系统有可能真正成为计算机上超越用户进程的存在，而不仅仅是一个服务性程序。有了这些基础，操作系统可以把内核设计成最高特权级，把用户进程设计成最低特权级。这样，操作系统可以访问 GDT、 LDT、 TR，而 GDT、 LDT 是逻辑地址变换至线性地址的关键，因此操作系统可以掌控线性地址。物理地址是由内核将线性地址转换而成的，所以操作系统可以访问任何物理地址，而用户进程只能使用逻辑地址。总之，特权级的引入对操作系统内核进行保护。 「分页」有“保护”作用吗？ 分页机制有保护作用，使得用户进程不能直接访问内核地址，进程间也不能相互访问。用户进程只能使用逻辑地址，而逻辑地址通过内核转化为线性地址，根据内核提供的专门为进程设计的分页方案，由 MMU 直接映射转化为实际物理地址形成保护。此外，通过分页机制，每个进程都有自己的专属页表，有利于更安全、高效的使用内存，保护每个进程的地址空间。 事实上，在较新版本的 Linux 中，内存保护已经改由分页机制实现，不再使用段机制实现了。这是因为分页的控制更扁平化，更灵活，且在不同体系结构上的可移植性更好。 为什么特权级是基于段的？ 在操作系统设计中，一个段一般实现的功能相对完整，可以把代码放在一个段，数据放在一个段，并通过段选择符（包括 CS、SS、DS、ES、FS 和 GS 寄存器）获取段的基址和特权级等信息。通过段，系统划分了内核代码段、内核数据段、用户代码段和用户数据段等不同的数据段，有些段是系统专享的，有些是和用户程序共享的，因此就有特权级的概念。特权级基于段，这样当段选择子具有不匹配的特权级时，按照特权级规则评判是否可以访问。特权级基于段，是结合了程序的特点和硬件实现的一种考虑。 7. 打开 A20 和打开 PE 究竟是什么关系，保护模式不就是 32 位的吗？为什么还要打开 A20？有必要吗？PE(Protection Enabled) 是 %eflags 中的重要一位，用于设置保护模式，在置位时开启。而 A20(Address 20) 是另一个控制位，用于让 x86 芯片接受高于 20 位的地址，而不是进行地址环绕。二者都是 x86 系列芯片为了兼容性而设计，但却相互独立，打开一者并不意味着打开另一者。 打开 A20 仅仅意味着 CPU 可以进行 32 位寻址，且最大寻址空间是 4GB。打开 PE 是进入保护模式，从而可能进行安全的系统编程，此时物理地址和线性地址一 一对应。A20 会控制 CPU 的第 21 位~第 32 位地址线，A20 未打开的时候，第 21 根及以上地址线被强制置为为 0，所以相当于 CPU “回滚”到内存地址起始处寻址。这是为了完全兼容以前在「只有 20 位寻址空间的 CPU 」上写的程序所设计的。 寻址情况 不打开 A20（上电默认状态） 打开 A20 实模式 cs:ip 最大寻址为 (0xFFFFF:0xFFFFF)%0x100000=0xFFEF 可以寻址到 1MB 以上的高地址内存区 保护模式 只能访问奇数 1M 段，即 0-1M，2M-3M，4-5M 等 可以访问的内存是连续的 打开 A20 是打开 PE 的必要条件；而打开 A20 不一定非得打开 PE。显然，A20 和 PE 必须分别打开，否则保护模式将无法正常工作。 8. 在 setup 程序里曾经设置过 GDT，为什么在 head 程序中又将其废弃，重新设置了一个？为什么设置两次，而不是一次搞好？第一次设置 GDT 所在的位置是在 setup.s 中，然而将来 setup 所在的内存位置会被缓冲区覆盖，如果不改变位置，GDT 的内容将被缓冲区覆盖掉，从而影响系统的运行。这样一来，将来整个内存中唯一安全的地方就是现在 head.s 所在的位置了。 那么有没有可能在执行 setup 程序时直接把 GDT 的内容复制到 head.s 所在的位置呢？答案是否定的。如果先复制 GDT 的内容、后移动 system 模块，GDT 会被后者覆盖；如果先移动 system 模块，后复制 GDT 的内容，它又会把 head.s 对应的程序覆盖，而这时 head 还没有执行。所以，无论如何，都要重新建立 GDT。 system 模块是指内核在内存中的映像。 9. 用户进程自己设计一套 LDT 表，并与 GDT 挂接，是否可行，为什么？不可行。 首先，用户进程不可以设置 GDT、LDT，因为 Linux-0.11 将 GDT、LDT 这两个数据结构设置在内核数据区，是 0 特权级的，只有 0 特权级的代码才能修改设置 GDT、LDT。因此，用户进程不能直接修改已存在的 GDT、LDT。 而且，用户也不可以在自己的数据段按照自己的意愿重新做一套 GDT、LDT。如果仅仅是形式上做一套和GDT、LDT一样的数据结构是可以的，但是真正起作用的 GDT、LDT 是 CPU 硬件认定的，这两个数据结构的首地址必须挂载在 CPU 的 %GDTR、%LDTR 寄存器上，运行时 CPU 只认 %GDTR 和 %LDTR 指向的数据结构，其他数据结构就算起名字叫 GDT、LDT，CPU 也一概不认；另外，用户进程也不能将自己制作的 GDT、LDT 挂接到 GDRT、LDRT 上，因为对 %GDTR 和 %LDTR 的设置（lgdt等指令）只能在 0 特权级别下执行，3 特权级别下无法把这套结构挂接到 %GDTR 和 %LDTR 上。 10. setup.s 程序里的 cli 是为了什么？cli 是关中断指令，意味着程序在接下来的执行过程中，系统不会对中断进行响应。原因很简单：在 setup 程序中，操作系统将要重新设置中断向量表和中断服务程序，在这个过程中是无法进行正常中断的。因此，操作系统先将中断关闭，直到中断重新设置完成后再打开中断，即运行 sti 指令。 在 setup 中，需要将位于 0x10000 的内核程序复制到 0x00000 处，BIOS 创建的原生中断向量表覆盖掉了。若此时产生中断，将产生不可预知的错误，所以要禁止中断。此外，此时也是由 16 位实模式向 32 位保护模式转变的时候，需要在保护模式下重新建立中断描述符表的交接工作，正是实模式的中断机制向保护模式的中断机制交接的时候。在保护模式的中断机制尚未完成时不允许响应中断，以免发生未知的错误。 11. 进程 0 的 task_struct 在哪？具体内容是什么？进程 0 的 task_struct 位于内核数据区，因为在进程 0 未激活之前，使用的是 boot 阶段的 user_stack，因此存储在 user_stack 中。 具体内容：包含了进程 0 的进程状态、进程 0 的 LDT、进程 0 的 TSS 等等。其中 LDT 设置了代码段和堆栈段的基址和限长(640KB)，而 TSS 则保存了各种寄存器的值，包括各个段选择符。 代码如下： 1234567891011121314151617181920212223242526272829// 代码路径：include/linux/sched.h// 赋给进程0的task_struct值/* * INIT_TASK is used to set up the first task table, touch at * your own risk!. Base=0, limit=0x9ffff (=640kB) */#define INIT_TASK \\\\/* state etc */ { 0,15,15, \\\\/* signals */ 0,{{},},0, \\\\/* ec,brk... */ 0,0,0,0,0,0, \\\\/* pid etc.. */ 0,-1,0,0,0, \\\\/* uid etc */ 0,0,0,0,0,0, \\\\/* alarm */ 0,0,0,0,0,0, \\\\/* math */ 0, \\\\/* fs info */ -1,0022,NULL,NULL,NULL,0, \\\\/* filp */ {NULL,}, \\\\ { \\\\ {0,0}, \\\\/* ldt */ {0x9f,0xc0fa00}, \\\\ {0x9f,0xc0f200}, \\\\ }, \\\\/*tss*/ {0,PAGE_SIZE+(long)&amp;init_task,0x10,0,0,0,0,(long)&amp;pg_dir,\\\\ 0,0,0,0,0,0,0,0, \\\\ 0,0,0x17,0x17,0x17,0x17,0x17,0x17, \\\\ _LDT(0),0x80000000, \\\\ {} \\\\ }, \\\\} 12. 内核的线性地址空间是如何分页的？画出从 0x000000 开始的7个页（包括页目录表、页表所在页）的挂接关系图。页目录表的前四个页目录项、第一个页表的前7个页表项指向什么位置？给出代码证据。如何分页：head.s 在 setup_paging 开始创建分页机制。将页目录表和4个页表放到物理内存的起始位置，从内存起始位置开始的5个页空间内容全部清零（每页4KB），然后设置页目录表的前4项，使之分别指向4个页表。然后开始从高地址向低地址方向填写4个页表，依次指向内存从高地址向低地址方向的各个页面。即将第4个页表的最后一项指向寻址范围的最后一个页面。即从 0xfff000 开始的 4KB 大小的内存空间。将第4个页表的倒数第二个页表项指向倒数第二个页面，即 0xfff000-0x1000000 开始的4KB字节的内存空间，依此类推。 挂接关系图： 代码证据： 注意，页目录表需指向所有页表；页表须要指向所有页；页目录表、页表自己也是页。 1234567891011121314151617181920212223// 代码路径：boot/head.s.align 2setup_paging: movl $1024*5,%ecx /* 5 pages - pg_dir+4 page tables */ xorl %eax,%eax xorl %edi,%edi /* pg_dir is at 0x000 */ cld;rep;stosl movl $pg0+7,_pg_dir /* set present bit/user r/w */ movl $pg1+7,_pg_dir+4 /* --------- &quot; &quot; --------- */ movl $pg2+7,_pg_dir+8 /* --------- &quot; &quot; --------- */ movl $pg3+7,_pg_dir+12 /* --------- &quot; &quot; --------- */ movl $pg3+4092,%edi movl $0xfff007,%eax /* 16Mb - 4096 + 7 (r/w user,p) */ std1: stosl /* fill pages backwards - more efficient :-) */ subl $0x1000,%eax jge 1b xorl %eax,%eax /* pg_dir is at 0x0000 */ movl %eax,%cr3 /* cr3 - page directory start */ movl %cr0,%eax orl $0x80000000,%eax movl %eax,%cr0 /* set paging (PG) bit */ ret /* this also flushes prefetch-queue */ 13. 在 head 程序执行结束的时候，在 IDT 的前面有 184 个字节的 head 程序的剩余代码，剩余了什么？为什么要剩余？在 IDT 前面有 184 个字节的剩余代码，剩余内容在 0x054b8~0x05400处，包含了 after_page_tables、ignore_int 中断服务程序和 setup_paging 设置分页的代码。其中 after_page_tables 往栈中压入了些参数，ignore_int 用做初始化中断时的中断处理函数，setup_paging则用于初始化分页。 剩余的原因：after_page_tables 中压入了一些参数，为内核进入 main() 函数跳转做准备，为了谨慎起见，设计者在栈中压入了 L6，以使得系统可能出错时，返回 L6 处执行。这部分代码可能返回，因此要放在页表后面。 ignore_int为中断处理函数，因此如果中断开启后，可能使用了未设置的中断向量，那么将默认跳转到ignore_int 处执行。因此不能被覆盖。 setup_paging 部分用于设置页表，在分页完成前不能被覆盖，因此放在页表的后面。 14. 为什么不用 call，而是用 ret “调用” main 函数？画出调用路线图，给出代码证据。call 指令会将 %eip 的值自动压栈，保护返回现场，然后执行被调函数的程序，等到执行被调函数的 ret 指令时，自动出栈给 %eip 并还原现场，继续执行原来 call 后的下一条指令。然而对操作系统的 main() 来说，如果由 call 调用 main() 函数，那么函数最后返回给谁呢？在由 head 程序向 main 函数跳转时，是不需要 main 函数返回的；从逻辑上来说，main 作为任何 C 程序的主入口，也不应该返回到其它位置的——它本身就是最“基本”的函数。因此代码中没有使用 call 调用 main，而是手动压栈（模仿了 call 的全部动作），并“返回”至 main 函数。 具体来说，操作系统先通过手动压栈调用 setup_paging 函数，压栈的 %eip 值不是调用 setup_paging 函数的下一行指令的地址，而是 main() 的入口地址。当 setup_paging 函数执行到 ret 时，从栈中将 main() 的入口地址 _main 自动出栈给 %eip，%eip 指向 main 函数的入口地址，便实现了用返回指令调用 main 函数。这样以来，就通过 ret ——而不是 call 指令——将逻辑控制流转交给了 main 函数，在方法论上确保了 main 在整个操作系统中的核心地位。 代码参考： 1234567891011# 代码路径：boot/head.safter_page_tables: pushl $0 # These are the parameters to main :-) pushl $0 pushl $0 pushl $L6 # return address for main, if it decides to. pushl $_main jmp setup_pagingL6: jmp L6 # main should never return here, but # just in case, we know what happens. 15. Linux 是用 C 语言写的，为什么没有从 main 开始，而是先运行3 个汇编程序，道理何在？通常用 C 语言编写的程序都是用户应用程序，这类程序的执行必须在操作系统上执行，也就是说要由操作系统为应用程序创建进程，并把应用程序的可执行代码从硬盘加载到内存。 然而，对于操作系统而言，在 BIOS 之后就要开始运行。但 CPU 启动时默认为16位的实模式（BIOS加载完之后仍然在实模式），开机时的 16 位实模式与 main 函数执行需要的 32 位保护模式之间有很大的差距。此时内存中没有操作系统程序，只有 BIOS 程序。操作系统需要借助 BIOS 分别加载 bootsect 、setup 及 system 模块，然后利用这 3 个程序来完成内存规划、建立 IDT 和 GDT、设置分页机制等等。其中 bootsect 负责加载，setup 与 head 则负责获取硬件参数，准备 IDT、GDT，开启 A20, PE, PG, 废弃旧的 16 位中断响应机制，建立新的 32 为 IDT，设置分页机制等，实现从开机时的 16 位实模式到 main 函数执行需要的 32 位保护模式之间的转换。当计算机处在 32 位的保护模式状态下时，调用 main 的条件才算准备完毕。 由此可见，在真正能调用一个 C 程序之前，还有大量的更为基本的准备工作要做，而这些准备工作往往需要更为底层的汇编语言来完成。因此，启动时需要先调用少量汇编程序，做好体系结构层级的基本准备之后再转入 C 语言编写的程序。 16. 用文字和图说明一个中断描述符表是如何初始化的，可以举例说明（比如：set_trap_gate(0,&amp;divide_error)），并给出代码证据。对中断描述符表的初始化，就是将中断、异常处理的服务程序与 IDT 进行挂接，逐步重建中断服务体系。 以 set_trap_gate(0,&amp;divide_error) 为例，函数的原型为： 123// 代码路径：include/asm/system.h#define set_trap_gate(n,addr) \\\\ _set_gate(&amp;idt[n],15,0,addr) 这是一个宏函数，展开到一般的门设置函数 _set_gate。其中，n 是 0，最终会指向 &amp;idt[0]，也就是 IDT 第一项中断描述符的地址；type 是 15（32位门，陷进门），dpl（描述符特权级）是 0；addr 是中断服务程序 divide_error(void) 的入口地址。 最终真正进行 IDT 设置的代码是一段内嵌汇编代码，见下： 1234567891011// 代码路径：include/asm/system.h#define _set_gate(gate_addr,type,dpl,addr) \\\\__asm__ (&quot;movw %%dx,%%ax\\\\n\\\\t&quot; \\\\ &quot;movw %0,%%dx\\\\n\\\\t&quot; \\\\ &quot;movl %%eax,%1\\\\n\\\\t&quot; \\\\ &quot;movl %%edx,%2&quot; \\\\ : \\\\ : &quot;i&quot; ((short) (0x8000+(dpl&lt;&lt;13)+(type&lt;&lt;8))), \\\\ &quot;o&quot; (*((char *) (gate_addr))), \\\\ &quot;o&quot; (*(4+(char *) (gate_addr))), \\\\ &quot;d&quot; ((char *) (addr)),&quot;a&quot; (0x00080000)) 刚开始中断服务程序地址 &amp;divide_error 存储在 %edx 中，段选择子 0008 存储在 %eax 的高字，将 %edx 低字赋给 %eax 的低字组成中断描述符表的低 32 位，0x8000+ (dpl&lt;&lt;13) + (type&lt;&lt;8) 即二进制1000111100000000是对 p 位、type 位、dpl 位的设置，然后赋给 %edx 的低位组成中断描述符表的高32位，最后将 %edx、%eax 分别写入中断描述符表的高32位和低32位。 17. 分析初始化IDT、GDT、LDT的代码。IDT: 初始化各种异常处理服务程序的中断描述符，例如除零错误(divide_error)、保护错误(general_protection)、页故障(page_fault)等等。 将剩余的中断处理程序都都初始化为默认项，即将 int 0x11~0x2F 的中断服务程序的指针设置为 reserved。 设置协处理器 x387 的 IDT 项。 允许主8259A中断控制器的 IRQ2、IRQ13 的中断请求。 设置并口（可连接接打印机）的 IDT 项。 代码如下： 1234567891011121314151617181920212223242526272829// 代码路径：kernel/traps.cvoid trap_init(void){ int i; set_trap_gate(0,&amp;divide_error); // 设置各类处理器异常的处理程序 set_trap_gate(1,&amp;debug); set_trap_gate(2,&amp;nmi); set_system_gate(3,&amp;int3); /* int3-5 can be called from all */ set_system_gate(4,&amp;overflow); set_system_gate(5,&amp;bounds); set_trap_gate(6,&amp;invalid_op); set_trap_gate(7,&amp;device_not_available); set_trap_gate(8,&amp;double_fault); set_trap_gate(9,&amp;coprocessor_segment_overrun); set_trap_gate(10,&amp;invalid_TSS); set_trap_gate(11,&amp;segment_not_present); set_trap_gate(12,&amp;stack_segment); set_trap_gate(13,&amp;general_protection); set_trap_gate(14,&amp;page_fault); set_trap_gate(15,&amp;reserved); set_trap_gate(16,&amp;coprocessor_error); // 协处理器中断 for (i=17;i&lt;48;i++) set_trap_gate(i,&amp;reserved); set_trap_gate(45,&amp;irq13); outb_p(inb_p(0x21)&amp;0xfb,0x21); // 允许主8259A芯片的IRQ2中断请求 outb(inb_p(0xA1)&amp;0xdf,0xA1); // 允许从8259A芯片的IRQ13中断请求 set_trap_gate(39,&amp;parallel_interrupt); // 并口的中断项} GDT： 在系统启动的过程中，GDT 被初始化了不止一次。GDT 最后一次在 head.s 中被设置，随后便在系统运行中被一直沿用。 在 head.s 中，采用 lgdt 指令加载预设好的 GDT 表内容。在这里，内核只设置了 GDT 中内核数据段和内核代码段的段描述符，而各个任务的 LDT 和 TSS 段在以后设置。 代码如下： 1234567891011121314# 代码路径：boot/head.ssetup_gdt: lgdt gdt_descr ret......gdt_descr: .word 256*8-1 # so does gdt (not that that's any .long _gdt # magic number, but it works for me :^)......_gdt: .quad 0x0000000000000000 /* NULL descriptor */ .quad 0x00c09a0000000fff /* 16Mb */ .quad 0x00c0920000000fff /* 16Mb */ .quad 0x0000000000000000 /* TEMPORARY - don't use */ .fill 252,8,0 /* space for LDT's and TSS's etc */ 最后，在 sched_init 中设置进程 0 的 LDT 段和 TSS 段。注意，进程 0 的 LDT 和 TSS 段的内容是在 sched.h 中预设的固定值。 123456789// 代码路径：kernel/sched.cvoid sched_init(void){ ...... set_tss_desc(gdt+FIRST_TSS_ENTRY,&amp;(init_task.task.tss)); set_ldt_desc(gdt+FIRST_LDT_ENTRY,&amp;(init_task.task.ldt)); ......} LDT： 对进程 0 来说，LDT 的值是预设的（见下），在 sched_init 中被挂接到 GDT 上（见上）。 12345678910// 代码路径：include/linux/sched.h#define INIT_TASK \\ // 进程0的ldt和tss预设值...... { \\ {0,0}, \\/* ldt */ {0x9f,0xc0fa00}, \\ // 代码长 640K，基址 0x0，G=1，D=1，DPL=3，P=1 TYPE=0x0a {0x9f,0xc0f200}, \\ // 数据长 640K，基址 0x0，G=1，D=1，DPL=3，P=1 TYPE=0x02 }, \\/*tss*/ {...}} 对随后的进程来说，进程的 LDT 是在 fork 的过程中建立的。具体来说，在 copy_process 中内核为每一个新进程建立一套新的 LDT 和 TSS，内容与原进程一样： 123456789// 代码路径：kernel/fork.cint copy_process(...){ ...... p-&gt;tss.ldt = _LDT(nr); // LDT内容与被复制进程一致，但在GDT中占用一个新的entry set_tss_desc(gdt+(nr&lt;&lt;1)+FIRST_TSS_ENTRY,&amp;(p-&gt;tss)); set_ldt_desc(gdt+(nr&lt;&lt;1)+FIRST_LDT_ENTRY,&amp;(p-&gt;ldt)); ......} 随后如果有新的进程加载新的可执行程序（例如，开始执行 bash），那么 do_execve 会在加载新程序的同时写入新的 LDT 的内容。 18. CPL、RPL、DPL分别是什么意思？记录在什么位置？CPL(Current Privilege Level) 指明当前执行程序/例程的特权级，是当前正在执行的代码所在的段的特权级。术语「当前特权级」就是指这个域的值。存在于 %cs 寄存器的低两位（%cs 段寄存器的第 0 和第 1 位）。 RPL(Request Privilege Level) 确定段选择子的请求特权级，是进程对段访问时的请求权限。RPL 是对于段选择子而言的，每个段选择子有自己的 RPL，它说明的是进程对段访问的请求权限，有点像函数参数。而且RPL对每个段来说不是固定的，两次访问同一段时的RPL可以不同。RPL可能会削弱CPL的作用，例如当前CPL=0的进程要访问一个数据段，它把段选择符中的RPL设为3，这样虽然它对该段仍然只有特权为3的访问权限。存在于段选择子的第 0 和第 1 位 DPL(Descriptor Privilege Level) 确定描述符的特权级，规定访问该描述符需要的权限级别。对段描述符，是访问这个段需要的特权级；对陷阱们和中断门，就是访问这些门、触发中断需要的特权级。当进程访问一个描述符时，需要进程特权级检查，一般要求 DPL &gt;= max{CPL, RPL}。DPL 存在于段描述符的第二个双字的第 13 和第 14 位。 每个描述符的 DPL 固定，而请求时的 RPL 是可变的。只有当 RPL 比 DPL 相同或更高（数值上小于等于）时才能正常访问对应的段。 CPL, RPL, DPL 都是特权级。特权级数值越小，对应的特权越大；反之，数值越大，对应的特权越小。x86 体系结构中共设计了 4 级特权级，其中 0 特权级级别最高，意味着对芯片有着完全的掌控，一般由操作系统使用；3 特权级特权最低，只能执行简单的计算而无权染指系统指令，一般被赋予给应用程序使用。在 Linux-0.11 中，只使用了 0 特权级（作为内核特权级）和 3 特权级（供应用程序使用）。 19. 在IA-32中，有大约20多个指令只能在 0 特权级下使用，其他的指令，比如 cli，并没有这个约定。奇怪的是，在 Linux-0.11 中，3 特权级的进程代码并不能使用 cli 指令，这是为什么？请解释并给出代码证据。根据 Intel IA-32 Manual，cli 和 sti 指令与 CPL 和 %eflags[IOPL]（Input/Outpu Previledge Level, 进行IO操作需要的特权级）有关。通过 IOPL 来加以保护 in, ins, out, outs, cli, sti等 I/O 敏感指令，只有 CPL(当前特权级)&lt;=IOPL 才能执行，低特权级访问这些指令将会产生一个一般性保护异常。IOPL 位于 %eflags 的12-13位，仅可通过 iret 和 lmsw 来改变。 操作系统上运行的第一个进程是进程 0，进程 0 的 IOPL 在 TSS 中初始化。INIT_TASK 中指定 %eflags[IOPL] 为0： 123456789// 代码路径：include/linux/sched.h// 赋给进程0的task_struct值#define INIT_TASK \\\\....../*tss*/ {0,PAGE_SIZE+(long)&amp;init_task,0x10,0,0,0,0,(long)&amp;pg_dir,\\\\ 0,0,0,0,0,0,0,0, \\\\ //^ tss.eflags的值，=0 ......}} 从此之后，所有进程都直接或间接地由内核进程 fork 而来，IOPL 的值仍然为 0 没有改变，也不会改变。所以用户进程无法调用 cli 指令。因此，通过设置 IOPL，3 特权级的进程代码不能使用 cli 等I/O敏感指令。 12345678910111213//代码路径：kernel\\\\fork.cint copy_process(int nr,long ebp,long edi,long esi,long gs,long none, long ebx,long ecx,long edx, long fs,long es,long ds, long eip,long cs,long eflags,long esp,long ss){ ...... p-&gt;tss.eip = eip; p-&gt;tss.eflags = eflags; p-&gt;tss.eax = 0; ...... return last_pid;} 20. 进程 0 的 task_struct 在哪？具体内容是什么？给出代码证据。这一数据结构在代码上定义于 include/linux/sched.h，而运行时位于内核数据段。具体内容包括状态、信号、pid、alarm、ldt、tss 等管理该进程所需的数据。具体代码见问题 19。 21. 在 sched_init(void) 函数中有这样的代码，对 task 数组进行了初始化：12345678// 代码路径：kernel/sched.cfor(i=1;i&lt;NR_TASKS;i++) { task[i] = NULL; p-&gt;a=p-&gt;b=0; p++; p-&gt;a=p-&gt;b=0; p++;} 代码并未涉及 task[0]，但从后续代码能感觉到进程 0 的任务结构已被设置，请给出代码证据。 上面的代码将 task[64] 除进程 0 占用的 0 项外的其余 63 项清空，等待随后被设置。其余进程的 task 数据结果都是在 fork 时被拷贝产生的，唯独进程 0 是个例外，它的 task 数据结构是在启动时手动设置的： 12// 代码路径：kernel/sched.cstruct task_struct * task[NR_TASKS] = {&amp;(init_task.task), }; 其中 init_task 是手动设置的进程 0 task 数据结构的值，见 include/linux/sched.h。 22. 在 system.h 里读懂代码。这里中断门、陷阱门、系统调用都是通过 _set_gate 设置的，用的是同一个嵌入汇编代码，比较明显的差别是 dpl 一个是3，另外两个是0，这是为什么？说明理由。12345678910111213141516#define _set_gate(gate_addr,type,dpl,addr) \\\\__asm__ (&quot;movw %%dx,%%ax\\\\n\\\\t&quot; \\\\ &quot;movw %0,%%dx\\\\n\\\\t&quot; \\\\ &quot;movl %%eax,%1\\\\n\\\\t&quot; \\\\ &quot;movl %%edx,%2&quot; \\\\ : \\\\ : &quot;i&quot; ((short) (0x8000+(dpl&lt;&lt;13)+(type&lt;&lt;8))), \\\\ &quot;o&quot; (*((char *) (gate_addr))), \\\\ &quot;o&quot; (*(4+(char *) (gate_addr))), \\\\ &quot;d&quot; ((char *) (addr)),&quot;a&quot; (0x00080000))#define set_intr_gate(n,addr) \\\\ _set_gate(&amp;idt[n],14,0,addr)#define set_trap_gate(n,addr) \\\\ _set_gate(&amp;idt[n],15,0,addr)#define set_system_gate(n,addr) \\\\ _set_gate(&amp;idt[n],15,3,addr) set_trap_gate 和 set_intr_gate 参数中的 dpl 是 3，set_system_gate的 dpl 是 0。dpl 为 0 表示只能在内核态下允许，dpl 为 3 表示系统调用可以由 3 特权级调用。 当用户程序产生系统调用软中断后， 系统都通过 system_call 总入口找到具体的系统调用函数。 set_system_gate 设置系统调用，须将 DPL 设置为 3，允许在用户特权级(=3)的进程调用，否则会引发保护异常。set_trap_gate 及 set_intr_gate 设置陷阱和中断为内核使用，需禁止用户进程调用，所以 DPL 为 0。 23. 在 Linux 操作系统中大量使用了中断、异常类的处理，究竟有什么好处？在未引入中断、异常处理理念以前，CPU 采用轮询 (polling) 的方法处理外部信号：CPU 每隔一段时间就要对全部硬件进行轮询，以检测它的工做是否完成，若是没有完成就继续轮询。这样消耗了CPU处理用户程序的时间，下降了系统的综合效率。CPU以“主动轮询”的方式来处理信号是很不划算的。 自 IBM 兼容机以后，系统以“被动模式”代替“主动轮询”来处理终端问题。进程在主机中运算需用到 CPU，其中可能进行“异常处理”，此时需要具体的服务程序来执行。这种中断服务体系的建立是为了被动响应中断信号。因此，CPU 就可以更高效的处理用户程序服务，不用考虑随机可能产生的中断信号，从而提高了操作系统的综合效率。 24. 进程 0 fork 进程 1 之前，为什么先调用 move_to_user_mode()？用的是什么方法？解释其中的道理。Linux 规定，除了进程 0 外，所有进程都要由一个已有的进程在 3 特权级下创建，进程 0 此时处于 0 特权级。按照规定，在创建进程 1 之前要将进程 0 转变为 3 特权级。方法是调用 move_to_user_mode() 函数，模仿中断返回动作，实现进程 0 的特权级从内核态转化为用户态。又因为在 Linux-0.11 中，转换特权级时采用中断和中断返回的方式，调用系统中断实现从 3 到 0 的特权级转换，中断返回时转换为 3 特权级。因此，进程 0 从 0 特权级到 3 特权级转换时采用的是模仿中断返回。设计者首先手工写压栈代码模拟 int（中断）压栈，当执行 iret 指令时，CPU 自动将这 5 个寄存器的值 (%ss, %esp, %eflags, %cs, %eip) 按序恢复给 CPU，CPU 就会翻转到 3 特权级去执行代码。 25. 为什么 static inline _syscall0(type,name) 中需要加上关键字 inline？这一问题的答案藏在写时复制 (CoW, Copy on Write) 机制中。 fork 函数会复制进程的页表，并将父进程和子进程的页表项都标记为只读，从而便于随后实现写时复制功能。具体来说，进程试图读取只读页的时候会产生保护异常，操作系统便在处理异常时拷贝一份新的物理页供进程修改。但 CoW 机制有一个例外：当页在内核空间（1M以下的地址）时，不会进行写时复制，而是允许内核之间共享内存叶。导致这一行为的代码见 copy_page_tables(...) 函数： 1234567891011121314151617181920// 代码路径 mm/memory.c/copy_page_tables(...)......// 对所有（要被拷贝的）页表项：for ( ; nr-- &gt; 0 ; from_page_table++,to_page_table++) { this_page = *from_page_table; // this_page 指向一个页表项，而非物理页 if (!(1 &amp; this_page)) continue; this_page &amp;= ~2; // 将页表项 R/W 位复位（置0，只读） *to_page_table = this_page; // 写到目的页表项 if (this_page &gt; LOW_MEM) { // !!仅当该页高于 1M 时触发如下代码!! // 将 R/W 复位的（只读的）页表项覆盖原页表项 // 即将父进程的页表项也设为只读 *from_page_table = this_page; this_page -= LOW_MEM; this_page &gt;&gt;= 12; // 并标记该页被共享了（为写时复制准备） mem_map[this_page]++; }}...... 进程 0 创建进程 1 后，二者共享物理页；然而由于栈和数据段位于内核区，如果进程 0 修改栈和数据段，不会触发写时复制，而是会在原有物理页上直接修改，这将破坏进程 1 的内存空间。为此，Linus 给出了解决方案：让进程 0 在 fork() 之后不修改任何数据和栈。 _syscall0(int, fork) 展开之后是一个真正的 C 函数声明。如果进程 0 直接调用这样的函数，那么势必会使用栈，从而破坏进程 1 的栈。为此，Linus Torvalds 在声明中加入了 inline 关键字，让编译器在 main 中原地展开函数声明。这样一来，运行时中就不会进行函数调用，也不会改变栈的内容，从而避免了破坏进程 1 的栈。 “函数调用”意味着什么呢？在汇编层次上，函数调用意味着 call 和 ret 指令。普通函数调用时需要使用 call 将 %eip 入栈（并跳转），返回时需要使用 ret 将 %eip 出栈，这都会修改栈的内容。inline 意味着内联函数，它将标明为 inline 的函数代码放在符号表中；此处的 fork 函数加上 inline 后先进行词法分析、语法分析后在编译时就地展开函数，不需要普通函数的 call\\ret 指令，也不需要保持栈的 %eip。 若不加上 inline，（进程 0 中）第一次返回 fork 结束时会将 %eip 出栈，在 pause 时又将新的返回地址压入栈中。经过 pause 之后进程 1 才被调度执行，而此时的栈段已经被进程 0 修改过了，（进程 1 中）第二次 fork() 返回时 %eip 的出栈值将是一个错误值。 26. 缺页中断是如何产生的，页写保护中断是如何产生的，操作系统是如何处理的？在 Intel x86 体系结果中，严格来说没有“缺页中断”，只有“页故障”(#PF, page fault)，和页故障导致的软中断。缺页故障和页写保护故障分别是页故障的两种不同情况，由故障产生时的 error code 区分。 Linux-0.11 中，#PF 由 page.s 中的 _page_fault 进行初步处理，根据不同 error code 分别转交给 do_no_page （缺页故障）和 do_wp_page （页写保护故障）作进一步处理。 ① 缺页故障 每一个页目录项或页表项的低 3 位，U/S, R/W, P，记录着所管理的页面的属性。如果页目录项或页表项指向的页存在于物理内存中，则 P 标志就设置为 1，反之则为 0。进程执行时，线性地址由 MMU 负责解析，如果解析发现某个表项的 P 位为 0，则说明没有对应页面，便会产生缺页中断。操作系统会调用 do_no_page 处理缺页故障：为进程申请空闲物理页，将程序加载到新分配的物理页中，并更新对应的页目录项和页表项。 ② 页写保护故障 若某个进程试图访问一个只读页面（R/W 为 0），便会产生一个页写保护故障。这种情况往往是由于采用了 CoW（写时复制，Copy on Write）策略、两个（或多个）进程共享一个页面导致的。在 copy_page_tables 函数中，操作系统会将被两个进程共享的页面标记为只读。任何一个进程试图修改只读页时，便会触发页写保护故障，这便是两个（或多个）进程共享一个页面的具体原理。检测到页写保护故障后，操作系统会调用 do_wp_page 实现写时复制策略：为当前进程申请空闲物理页，将将原页面的数据复制到新页面中，然后将该进程的页表项指向新申请的页面，同时将原页面的引用计数减 1。当前进程得到自己的页面，就可以执行写操作。 Part II 多任务与进程调度27. copy_process 函数的参数最后五项是：long eip,long cs, long eflags, long esp, long ss。查看栈结构确实有这五个参数，奇怪的是其他参数的压栈代码都能找得到，确找不到这五个参数的压栈代码，反汇编代码中也查不到，请解释原因。copy_process 执行是因为进程调用了 fork 函数创建进程，会执行 int 0x80 产生一个软中断。参考 Intel IA-32 手册可知，中断使 CPU 硬件自动将 %ss, %esp, %eflags, %cs, %eip 这5个寄存器的值按顺序压入进程0的内核栈。又因为函数传递参数是使用栈的，所以刚好可以作为 copy_process的 最后五个参数。 28. 根据代码详细说明 copy_process 函数的所有参数是如何形成的？copy_process 函数原型为： 1234int copy_process(int nr,long ebp,long edi,long esi,long gs,long none, long ebx,long ecx,long edx, long fs,long es,long ds, long eip,long cs,long eflags,long esp,long ss) 与一般的函数不同，copy_process 的参数不是由 C 语言中的传参机制传递的，而是由汇编代码“做”出来的。函数参数的本质是调用子程序时的栈上数据，而 copy_process 函数的所有参数正是通过汇编代码压栈形成的。 参数有很多，我们将其分为几组，分组进行讨论。 ① long eip, long cs, long eflags, long esp, long ss 这五个参数是中断使 CPU 自动压栈的。参考 x86 手册 (Intel IA-32 Manual) 可知，在中断时芯片会自动将当前的 %eip, %cs, %eflags 压入栈中，便于从中断处理程序返回到原来执行处。如果中断时切换了特权级，还会将 %esp 和%ss 压入栈中，并切换栈。 系统调用是从 3 特权级的用户态向 0 特权级的内核态的切换，因此会触发后一种压栈，形成了 copy_process 的后五个参数。 ② long ebx, long ecx, long edx, long fs, long es, long ds 是在汇编代码中压进栈的参数。 ③ long none 是一个无用参数，起占位符作用。 为 _system_call 调用 _sys_fork 时压进栈的 %eip 值。 ④ int nr 是 _system_fork 压入栈的值，也是 find_empty_process 函数的返回值。这个值是 task 数组中下一个空槽位的索引。 ⑤ long ebp, long edi, long esi, long gs 是 _system_fork 压入栈的参数。 不难发现，除了 int nr 和 int none 之外，其余的参数都对应了用户态程序调用 fork 之前的寄存器值。这些寄存器值被传递给 copy_process，是为了被拷贝到新进程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445// 代码路径：kernel/system_call.s......_system_call: // 此时 %eip 等五个寄存器已经在栈上（第一组参数） cmpl $nr_system_calls-1,%eax ja bad_sys_call // 将第二组六个参数压入栈 push %ds push %es push %fs pushl %edx pushl %ecx # push %ebx,%ecx,%edx as parameters pushl %ebx # to the system call movl $0x10,%edx # set up ds,es to kernel space mov %dx,%ds mov %dx,%es movl $0x17,%edx # fs points to local data space mov %dx,%fs // 跳转指令会将 %eip 压栈，在栈上占用一个空间。 // copy_process设置了一个int none参数来为这个位置预留空间。 call _sys_call_table(,%eax,4) pushl %eax movl _current,%eax cmpl $0,state(%eax) # state jne reschedule cmpl $0,counter(%eax) # counter je reschedule......_sys_fork: // 调用find_empty_process函数寻找下一个空的任务槽位 // 返回值留在栈中，形成了copy_process的int nr参数 call _find_empty_process testl %eax,%eax js 1f // 将第五组参数压入栈 push %gs pushl %esi pushl %edi pushl %ebp pushl %eax call _copy_process addl $20,%esp1: ret 29. 进程 0 创建进程 1 时调用 copy_process 函数，在其中直接、间接调用了两次 get_free_page 函数，在物理内存中获得了两个页，分别用作什么？是怎么设置的？给出代码证据。第一次调用 get_free_page 函数申请的空闲页面用于进程 1 的 task_struct 及内核栈。首先将申请到的页面清0，然后复制进程 0 的 task_struct，再针对进程 1 作微调。其中 esp0 的设置，意味着设置该页末尾为进程 1 的内核栈的起始地址。 12345678910111213141516// 代码路径：kernel/fork.cint copy_process(int nr,long ebp,long edi,long esi,long gs,long none, long ebx,long ecx,long edx, long fs,long es,long ds, long eip,long cs,long eflags,long esp,long ss){ ...... p = (struct task_struct *) get_free_page(); // HERE! if (!p) return -EAGAIN; task[nr] = p; *p = *current; /* NOTE! this doesn't copy the supervisor stack */ ...... p-&gt;tss.esp0 = PAGE_SIZE + (long) p; // 被复制进程的0特权级栈（即内核栈）的起始地址 ......} 第二次调用 get_free_page 函数申请的空闲页面用作进程 1 的页表。在创建进程1执行 copy_process 中，执行 copy_mem(nr,p) 时，内核为进程 1 拷贝了进程 0 的页表（对进程 0 -&gt;进程 1而言只拷贝 160 页表项，否则会拷贝 256 项），同时将页表项的属性修改为只读。 12345678910111213141516// 代码路径：mm/memory.cint copy_page_tables(unsigned long from,unsigned long to,long size){ ...... // size = #要复制的页目录项 = #要复制的页表数 size = ((unsigned) (size+0x3fffff)) &gt;&gt; 22; for( ; size--&gt;0 ; from_dir++,to_dir++) { // from|to_page_table是指向页表所在页的指针 from_page_table = (unsigned long *) (0xfffff000 &amp; *from_dir); // HERE! 用get_free_page获得新页作为页表 if (!(to_page_table = (unsigned long *) get_free_page())) return -1; /* Out of memory, see freeing */ *to_dir = ((unsigned long) to_page_table) | 7; } ......} 30. 分析 get_free_page() 函数的代码，叙述在主内存中获取一个空闲页的技术路线。 通过逆向扫描页表位图 mem_map，找到内存中（从高地址开始）第一个空闲（字节为0）页面，将其在mem_map中对应的位置置为1。 %ecx 左移12位加 LOW_MEM 获得该页的物理地址，并将页面清零。 最后返回空闲页面物理内存的起始地址。 值得注意的是，代码中利用了x86架构提供的字符串批处理指令 (scasb, stosl)，以简化代码、加快速度。 代码如下： 12345678910111213141516171819202122// 代码路径：mm/memory.cunsigned long get_free_page(void){register unsigned long __res asm(&quot;ax&quot;);__asm__(&quot;std ; repne ; scasb\\\\n\\\\t&quot; &quot;jne 1f\\\\n\\\\t&quot; &quot;movb $1,1(%%edi)\\\\n\\\\t&quot; &quot;sall $12,%%ecx\\\\n\\\\t&quot; &quot;addl %2,%%ecx\\\\n\\\\t&quot; &quot;movl %%ecx,%%edx\\\\n\\\\t&quot; &quot;movl $1024,%%ecx\\\\n\\\\t&quot; &quot;leal 4092(%%edx),%%edi\\\\n\\\\t&quot; &quot;rep ; stosl\\\\n\\\\t&quot; &quot;movl %%edx,%%eax\\\\n&quot; &quot;1:&quot; :&quot;=a&quot; (__res) :&quot;0&quot; (0),&quot;i&quot; (LOW_MEM),&quot;c&quot; (PAGING_PAGES), &quot;D&quot; (mem_map+PAGING_PAGES-1) :&quot;di&quot;,&quot;cx&quot;,&quot;dx&quot;);return __res;} 31. 为什么 get_free_page() 将新分配的页面清 0？因为无法预知该内存页的用途，如果用作页表，不清零就有垃圾值，就是隐患。 Linux 在回收页面时并不会将页面清 0，只是将 mem_map 中与该页对应的引用计数置 0。在使用 get_free_page 申请内存页时，便是遍历 mem_map 寻找引用计数为 0 的页，但是该页可能存在垃圾数据，如果不清 0 的话，若将该页用做页表，则可能导致错误的映射，引发错误，所以要将新分配的页面清0。 32. copy_mem() 和 copy_page_tables() 在第一次调用时是如何运行的？copy_mem() 在进程 0 创建进程 1 时被第一次调用，它的作用是拷贝进程的内存管理框架，设置进程 1 的段描述符。它先提取当前进程（进程0）的代码段、数据段的段限长，并将当前进程（进程0）的段限长赋值给子进程（进程1）的段限长。然后提取当前进程（进程0）的代码段、数据段的段基址，检查当前进程（进程0）的段基址、段限长是否有问题。接着设置子进程（进程1）的 LDT 段描述符中代码段和数据段的基地址为 nr(=1)*64MB。最后调用 copy_page_tables() 函数，进行具体的页表拷贝。 copy_page_tables() 的作用是拷贝进程的页目录项和全部页目录表，但不拷贝物理页。该函数的参数是源地址、目的地址和大小，首先检测源地址和目的地址是否都是 4MB 的整数倍，如不是则报错，不符合分页要求。然后取源地址和目的地址所对应的页目录项地址，检测如目的地址所对应的页目录表项已被使用则报错，其中源地址不一定是连续使用的，所以有不存在的跳过。接着，取源地址对应的页表地址，并为目的地址申请一个新页作为子进程的页表。然后，判断源地址是否为 0，即父进程是否为进程 0 ，如果是，则复制160个页表（~640KB），否则复制1024个页表（~4MB）。最后将源页表项复制给目的页表。按理说源页表项和目的页表项都应将对应的页标记为“只读”、方便后续进行写时复制操作，但由于是第一次调用，所以父进程是0，都在1M内，所以不参与写时复制，也不维护引用计数 mem_map。1M内的内核区不参与用户分页管理。对 copy_page_tables 函数的具体分析见问题 33。 33. 分析 copy_page_tables() 函数的代码，叙述父进程如何为子进程复制页表。进入 copy_page_tables 函数后，先为新的页表申请一个空闲页面，并把进程 0 中第一个页表里的前 160 个页表项复制到这个页面中（1个页表项控制一个页面 4KB 内存空间，160个页表项能够控制 640KB 内存空间）。进程0和进程1的页表暂时度指向了相同的页面，意味着进程1也能够操做进程0的页面。以后对进程1的页目录表进行设置。最后，用重置 %cr3 的方法刷新页面变换高速缓存 (TLB)。进程 1 的页表和页目录表设置完毕。进程 1 此时是一个空架子，尚未对应的程序，它的页表又是从进程 0 的页表复制过来的，它们管理的页面彻底一致，也就是它暂时和进程 0 共享一套页面管理结构。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// 代码路径：kernel/fork.cint copy_mem(int nr,struct task_struct * p){ ...... set_base(p-&gt;ldt[1],new_code_base); // 设置子进程代码段基址 set_base(p-&gt;ldt[2],new_data_base); // 设置子进程数据段基址 // 为进程1创建第一个页表、复制进程0的页表，设置进程1的页目录项 if (copy_page_tables(old_data_base,new_data_base,data_limit)) { free_page_tables(new_data_base,data_limit); return -ENOMEM; } return 0;}// 代码路径：mm/memory.c......#define invalidate()\\\\__asm__(&quot;movl%%eax，%%cr3&quot;：&quot;a&quot;(0) // 重置CR3为0，从而强制刷新TLB缓存......int copy_page_tables(unsigned long from,unsigned long to,long size){ unsigned long * from_page_table; unsigned long * to_page_table; unsigned long this_page; unsigned long * from_dir, * to_dir; unsigned long nr; // 0x3fffff = 4MB = 一个页表的管辖范围 // 以下一行代码要求from和to的低22位全为零，即要求地址from和to能被4MB整除 if ((from&amp;0x3fffff) || (to&amp;0x3fffff)) panic(&quot;copy_page_tables called with wrong alignment&quot;); // 一个页表管辖4MB =&gt; from/4MB = 对应页表编号 = from&gt;&gt;22 // 一个页目录表项4B =&gt; (页表编号)*4B = 页目录表项地址 = ((from)&gt;&gt;22)&lt;&lt;2 // 化简：((from)&gt;&gt;22)&lt;&lt;2 = (from&gt;&gt;20) 并置低2位为0 = (from&gt;&gt;20)&amp;0xffc from_dir = (unsigned long *) ((from&gt;&gt;20) &amp; 0xffc); /* _pg_dir = 0 */ to_dir = (unsigned long *) ((to&gt;&gt;20) &amp; 0xffc); size = ((unsigned) (size+0x3fffff)) &gt;&gt; 22; for( ; size--&gt;0 ; from_dir++,to_dir++) { if (1 &amp; *to_dir) panic(&quot;copy_page_tables: already exist&quot;); if (!(1 &amp; *from_dir)) continue; from_page_table = (unsigned long *) (0xfffff000 &amp; *from_dir); if (!(to_page_table = (unsigned long *) get_free_page())) return -1; /* Out of memory, see freeing */ *to_dir = ((unsigned long) to_page_table) | 7; nr = (from==0)?0xA0:1024; for ( ; nr-- &gt; 0 ; from_page_table++,to_page_table++) { this_page = *from_page_table; if (!(1 &amp; this_page)) continue; this_page &amp;= ~2; *to_page_table = this_page; if (this_page &gt; LOW_MEM) { *from_page_table = this_page; this_page -= LOW_MEM; this_page &gt;&gt;= 12; mem_map[this_page]++; } } } invalidate(); return 0;} 34. 进程 0 创建进程 1 时，为进程 1 建立了 task_struct 及内核栈，第一个页表，分别位于 16MB 物理内存的末尾倒数第一页、第二页。请问，这两个页究竟占用的是谁的线性地址空间，内核、进程 0、进程 1、还是没有占用任何线性地址空间？说明理由（可以图示）并给出代码证据。均占用内核的线性地址空间。 需要分页内存时，内核通过调用 get_free_page() 获得空页。而正如前面（问题19）分析，get_free_page()通过逆向扫描页表位图，找到第一个空页后返回，因此得到的内存页位于 16M 内存末端。 代码如下： 12345678910111213141516171819202122// 代码路径：mm/memory.cunsigned long get_free_page(void){register unsigned long __res asm(&quot;ax&quot;);__asm__(&quot;std ; repne ; scasb\\\\n\\\\t&quot; &quot;jne 1f\\\\n\\\\t&quot; &quot;movb $1,1(%%edi)\\\\n\\\\t&quot; &quot;sall $12,%%ecx\\\\n\\\\t&quot; &quot;addl %2,%%ecx\\\\n\\\\t&quot; &quot;movl %%ecx,%%edx\\\\n\\\\t&quot; &quot;movl $1024,%%ecx\\\\n\\\\t&quot; &quot;leal 4092(%%edx),%%edi\\\\n\\\\t&quot; &quot;rep ; stosl\\\\n\\\\t&quot; &quot;movl %%edx,%%eax\\\\n&quot; &quot;1:&quot; :&quot;=a&quot; (__res) :&quot;0&quot; (0),&quot;i&quot; (LOW_MEM),&quot;c&quot; (PAGING_PAGES), &quot;D&quot; (mem_map+PAGING_PAGES-1) :&quot;di&quot;,&quot;cx&quot;,&quot;dx&quot;);return __res;} 进程 0 和进程 1 的 LDT 的限长属性将进程 0 和进程 1 的地址空间限定 0~640KB， 所以进程 0、 进程 1 均无法访问到这两个页面， 故两页面占用内核的线性地址空间。进程 0 的局部描述符如下： 1234567891011121314151617181920212223// 代码路径：boot/head.s.align 2setup_paging: movl $1024*5,%ecx /* 5 pages - pg_dir+4 page tables */ xorl %eax,%eax xorl %edi,%edi /* pg_dir is at 0x000 */ cld;rep;stosl movl $pg0+7,_pg_dir /* set present bit/user r/w */ movl $pg1+7,_pg_dir+4 /* --------- &quot; &quot; --------- */ movl $pg2+7,_pg_dir+8 /* --------- &quot; &quot; --------- */ movl $pg3+7,_pg_dir+12 /* --------- &quot; &quot; --------- */ movl $pg3+4092,%edi movl $0xfff007,%eax /* 16Mb - 4096 + 7 (r/w user,p) */ std1: stosl /* fill pages backwards - more efficient :-) */ subl $0x1000,%eax jge 1b xorl %eax,%eax /* pg_dir is at 0x0000 */ movl %eax,%cr3 /* cr3 - page directory start */ movl %cr0,%eax orl $0x80000000,%eax movl %eax,%cr0 /* set paging (PG) bit */ ret /* this also flushes prefetch-queue */ 上面的代码，指明了内核的线性地址空间为 0x000000~0xffffff（即前16M），且在内核的视角中，线性地址与物理地址一一对应。为进程1分配的这两个页，在16MB的顶端倒数第一页、第二页，因此占用内核的线性地址空间。 进程 0 的线性地址空间是内存前 640KB，因为进程 0 的 LDT 中的 limit 属性限制了进程 0 能够访问的地址空间。进程 1 拷贝了进程 0 的页表（160项），而这160个页表项即为内核第一个页表的前160项，指向的是物理内存前 640KB，因此无法访问到 16MB 的顶端倒数的两个页。 进程 0 创建进程 1 的时候，先后通过get_free_page函数从物理地址中取出了两个页，但是并没有将这两个页的物理地址填入任何新的页表项中。此时，只有内核的页表中包含了与这段物理地址对应的项，也就是说此时只有内核可以访问到这两个页，所以这两个页占用了内核线性空间。 这里的进程 0 是指处在用户态的进程 0。而内核则是运行在所有进程中运行在 0 特权级的那部分。 35. 内核和普通用户进程并不在一个线性地址空间内，为什么仍然能够访问普通用户进程的页面？内核的线性地址空间和用户进程不一样，内核是不能通过跨越线性地址访问进程的。但由于早就占有了所有的页面，而且特权级是 0，所以内核执行时，可以对所有的内容进行改动，“等价于”可以操作所有进程所在的页面。 内核在启动时便在所有内存上（16M）建立了恒等映射的页表，因此内核通过这套页表可以访问所有内存页面。而对于随后建立的用户进程，每个进程有独立的 LDT，其中记录了进程拥有的线性地址段的起始和限长，每个用户进程对应了不同的页表。用户进程只能通过自己的 LDT 访问自己的页表、进而访问物理内存。在合适地地址设置之下，用户进程便无法访问其它进程的地址空间。 36. 假设：经过一段时间的运行，操作系统中已经有5个进程在运行，且内核分别为进程 4、进程 5 分别创建了第一个页表，这两个页表在谁的线性地址空间？用图表示这两个页表在线性地址空间和物理地址空间的映射关系。这两个页面均占用内核的线性地址空间。既然是内核线性地址空间，则与物理地址空间为一一对应关系。根据每一个进程占用 16 个页目录表项，则进程 4 占用从第 65～80 项的页目录表项。同理，进程 5 占用第 81～96 项的页目录表项。因为目前只分配了一个页面（用作进程的第一个页表），则分别只须要使用第一个页目录表项便可。又因为物理页是从后向前分配的，因此进程 5 的第一个页表其实在进程 4 的前面。映射关系如图： 37. switch_to() 代码中的 ljmp %0\\n\\t 很奇怪，按理说 jmp 指令跳转到得位置应该是一条指令的地址，可是这行代码却跳到了 &quot;m&quot; (*&amp;__tmp.a)，这明明是一个数据的地址，更奇怪的，这行代码竟然能正确执行。请论述其中的道理。123456789101112131415// 代码路径：include/linux/sched.h#define switch_to(n) {\\\\struct {long a,b;} __tmp; \\\\__asm__(&quot;cmpl %%ecx,_current\\\\n\\\\t&quot; \\\\ &quot;je 1f\\\\n\\\\t&quot; \\\\ &quot;movw %%dx,%1\\\\n\\\\t&quot; \\\\ &quot;xchgl %%ecx,_current\\\\n\\\\t&quot; \\\\ &quot;ljmp %0\\\\n\\\\t&quot; \\\\ &quot;cmpl %%ecx,_last_task_used_math\\\\n\\\\t&quot; \\\\ &quot;jne 1f\\\\n\\\\t&quot; \\\\ &quot;clts\\\\n&quot; \\\\ &quot;1:&quot; \\\\ ::&quot;m&quot; (*&amp;__tmp.a),&quot;m&quot; (*&amp;__tmp.b), \\\\ &quot;d&quot; (_TSS(n)),&quot;c&quot; ((long) task[n])); \\\\} 这个问题要由 Intel x86 体系结构来回答。80286及以后的x86系列处理器支持多任务，可以在硬件层面上完成任务切换。Intel x86 Manual 指出，可以通过1)跳转至任务门或者2)跳转至任务 TSS 对应的段选择子等方式来进行任务跳转。在这一过程中，由硬件负责保护现场、维护TSS、控制流跳转等工作。因此，ljmp %0\\\\n\\\\t实际上运用了 CPU 的多任务能力来完成任务切换，而不能简单地理解为跳转指令。 ljmp %0\\\\n\\\\t 未使用任务门，而是通过第二种方式（跳转至指向 TSS 的段选择子）进行任务切换。在这一条指令中： CPU 自动将当前各个寄存器值保存在进程 0 的 TSS 中， 将进程1的 TSS 中的各项数据（包括通用寄存器、LDT 中保存的的代码段、数据段描述符等）恢复给 CPU 的各个寄存器， 将控制流转移给进程 1（移交给进程 1 的 tss.eip）。如果深究系统初始化过程，可以发现切换后 %eip 指向的就是 main 中 inline fork 中的 if(__res &gt;= 0) 语句。 并从0特权级的内核代码切换到3特权级。 38. 根据代码详细分析，进程 0 是如何根据调度第一次切换到进程1的？进程 0 切换到进程 1，经历了两个过程： 进程 0 通过 fork 函数创建进程 1，并使其处在就绪态。 进程 0 调用 pause 函数。pause 函数通过 int 0x80 中断跳转到 sys_pause 函数，将进程 0 自身设为可中断等待状态 (TASK_INTERRUPTIBLE)，然后调用 schedule 函数进行进程调度。schedule 函数遍历所有进程，比较进程的运行状态和剩余时间片，找出处于就绪态且剩余时间片最多（即 counter 最大）的进程。此时操作系统上只有进程 0 和进程 1，且进程 0 是挂起状态（可中断等待状态），只有进程 1 是就绪态，于是切换到进程 1 执行。 最终在 schedule 函数中调用 switch_to(1)（见问题 37 ——前一个问题]），通过 x86 芯片提供的任务切换接口切换到进程 1。 参考代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// 代码路径：init/main.cvoid main(void){ ...... sti(); move_to_user_mode(); if (!fork()) { // 1. task 0 create task 1 init(); } ...... for(;;) pause(); // 2. task 0 call pause()}// 代码路径：include/unistd.h......#define __NR_pause 29......// pause() -&gt; int 0x80#define _syscall0(type,name) \\\\type pause(void) \\\\{ \\\\long __res; \\\\__asm__ volatile (&quot;int $0x80&quot; \\\\ : &quot;=a&quot; (__res) \\\\ : &quot;0&quot; (__NR_##name)); \\\\if (__res &gt;= 0) \\\\ return (type) __res; \\\\errno = -__res; \\\\return -1; \\\\}// 代码路径：kernel/system_call.s_system_call: ...... // instructions that push registers into stack call _sys_call_table(,%eax,4) // int 0x80 -&gt; sys_call_table// 代码路径：include/linux/sys.h// sys_call_table -&gt; sys_pausefn_ptr sys_call_table[] = { ...... sys_pause, // element with index 29 ...... };// 代码路径：kernel/sched.cint sys_pause(void){ // 将进程0设置为可中断等待状态，如果产生某种中断，或其他进程给这个进程发送特定信号， // 才有可能将这个进程重新唤醒（即设为就绪态） current-&gt;state = TASK_INTERRUPTIBLE; schedule(); // sys_pause -&gt; schedule return 0;}......// schedule -&gt; task 1void schedule(void){ ...... // variable delaration; signal and alarm handling while (1) { c = -1; next = 0; i = NR_TASKS; p = &amp;task[NR_TASKS]; while (--i) { if (!*--p) continue; if ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c) c = (*p)-&gt;counter, next = i; } if (c) break; for(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p) if (*p) (*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; 1) + (*p)-&gt;priority; } switch_to(next); // finally switch to task 1 by jumping to its tss} 39. 进程 0 进行简单初始化后，通过调用 fork() 创建进程 1。跟踪代码时我们发现，fork代码执行了两次，第一次，执行 fork 代码后，跳过 init() 直接执行了 for(;;) pause();，第二次执行 fork 代码后，执行了 init()。奇怪的是，我们在代码中并没有看到向转向 fork 的 goto 语句，也没有看到循环语句，是什么原因导致 fork 反复执行？请说明理由（可以图示），并给出代码证据。在 Unix 标准中，fork() 是唯一一个调用一次、返回两次的函数。这是由其函数功能决定的：fork 创建了一个与父进程一模一样的新进程，因此在两个进程中势必都会返回一次。为了区分父子进程，fork 在父进程返回子进程的 pid，在子进程返回 0。通过调度后两个进程都会从 fork 处继续执行，随后便根据不同的返回值在 if 处走向了不同的分支。 然而作为一门操作系统课程，仅在用户角度分析 fork 是不够的。下面试从操作系统代码的角度做具体分析。 main.c 中的 fork 为特别处理的 inline 函数，其中调用了 int 0x80 产生系统中断，并最终跳转至内核中的copy_process函数。系统中断时，CPU 自动将 %ss, %esp, %eflags, %cs, %eip 压栈，其中 %eip 为 int 0x80 的下一指令的地址。在 copy_process 中，内核将进程 0 的 TSS 复制得到进程 1 的 TSS，并将进程 1 的 tss.eax 手动设为 0，而将进程 1 的pid（last_pid）返回给进程 0。在进程调度时 TSS 中的值被恢复至相应寄存器中，包括 %eip， %eax 等。所以中断返回后，进程 0 和进程 1 均会从 int 0x80 的下一句开始执行，即 fork 返回了两次。 由于 %eax 代表返回值，所以进程 0 和进程 1 会得到不同的返回值，在 fork 返回到进程0后，进程 0 判断返回值非 0，因此执行代码 for(;;) pause(); 在 sys_pause 函数中，内核设置了进程0的状态为 TASK_INTERRUPTIBLE，并进行进程调度。由于只有进程1处于就绪态，因此调度执行进程 1 的指令。由于进程 1 在 TSS 中设置了 %eip 等寄存器的值，因此从 int 0x80 的下一条指令开始执行，且设定返回 %eax 的值作为 fork 的返回值（值为 0），因此进程1执行了 init() 所在的分支。 参考代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// 代码路径：init/main.cvoid main(void) { // 一些基本的初始化，其中很多需要0特权级 ...... move_to_user_mode(); if (!fork()) { /* we count on this going ok */ init(); }}// 通过宏展开的fork// 代码路径：init/main.c // 展开前为：static inline _syscall0(int,fork)// 宏(_syscall0)定义路径：include/unistd.cstatic inline int fork(void){long __res; __asm__ volatile (&quot;int $0x80&quot; \\\\ : &quot;=a&quot; (__res) \\\\ //%eax的值输出至__res。%eax是copy_process()的返回值last_pid(=1) : &quot;0&quot; (__NR_##name)); \\\\if (__res &gt;= 0) \\\\ //iret后，执行这一行 return (type) __res; \\\\ //返回1！errno = -__res; \\\\return -1; \\\\}// 代码路径：kernel/fork.cint copy_process(int nr,long ebp,long edi,long esi,long gs,long none, long ebx,long ecx,long edx, long fs,long es,long ds, long eip,long cs,long eflags,long esp,long ss){ struct task_struct *p; int i; struct file *f; p = (struct task_struct *) get_free_page(); if (!p) return -EAGAIN; task[nr] = p; *p = *current; /* NOTE! this doesn't copy the supervisor stack */ p-&gt;state = TASK_UNINTERRUPTIBLE; p-&gt;pid = last_pid; p-&gt;father = current-&gt;pid; p-&gt;counter = p-&gt;priority; ...... // 略去一些不相关的元素的copy p-&gt;tss.esp0 = PAGE_SIZE + (long) p; p-&gt;tss.ss0 = 0x10; p-&gt;tss.eip = eip; p-&gt;tss.eflags = eflags; p-&gt;tss.eax = 0; p-&gt;tss.ecx = ecx; p-&gt;tss.edx = edx; ...... // copy其它通用寄存器 p-&gt;tss.es = es &amp; 0xffff; p-&gt;tss.cs = cs &amp; 0xffff; ...... // copy其它段寄存器(ss,ds,fs,gs) p-&gt;tss.ldt = _LDT(nr); p-&gt;tss.trace_bitmap = 0x80000000; if (last_task_used_math == current) __asm__(&quot;clts ; fnsave %0&quot;::&quot;m&quot; (p-&gt;tss.i387)); if (copy_mem(nr,p)) { task[nr] = NULL; free_page((long) p); return -EAGAIN; } for (i=0; i&lt;NR_OPEN;i++) if (f=p-&gt;filp[i]) f-&gt;f_count++; ...... // 略去一些不重要的内容 set_tss_desc(gdt+(nr&lt;&lt;1)+FIRST_TSS_ENTRY,&amp;(p-&gt;tss)); set_ldt_desc(gdt+(nr&lt;&lt;1)+FIRST_LDT_ENTRY,&amp;(p-&gt;ldt)); p-&gt;state = TASK_RUNNING; /* do this last, just in case */ return last_pid;} 40. 详细分析进程调度的全过程。考虑所有可能（signal、alarm除外）Case I 有就绪进程，且时间片没有用完 正常情况下，schedule() 函数首先扫描任务数组。通过比较每个就绪任务（即处于 TASK_RUNNING 状态的进程）的剩余时间片数（即运行时间滴答计数 counter） 来确定哪个进程运行的时间最少。哪一个进程的值大，就表示运行时间还不长，于是选中该进程，调用 switch_to() 执行实际的进程切换操作 Case II 有就绪进程，但所有就绪进程的时间片都已用完（对应 schedule() 中 c==0 分支） 若此时所有就绪进程的时间片都已经用完，系统就会根据每个进程的优先权值 priority ，对所有进程（包括正在睡眠的进程）重新分配时间片。计算公式为： \\mathtt{counter}=\\mathtt{counter}/2+\\mathtt{priority}\\notag对时间片已经用完的就绪进程，计算后会得到数值等于 priority 的时间片；对睡眠进程，剩余时间片会增加，剩余时间片数最终会收敛至 priority 的2倍。 然后 schdeule() 函数重新扫描任务数组中所有处于 TASK_RUNNING 状态的进程，重复上述过程，直到选择出一个进程为止，最后调用 switch_to() 执行实际的进程切换操作。 Case III 无就绪进程（ 退出循环后next==0, c==-1 ） 对操作系统来说这种情况看起来有些奇怪。但事实上是很有可能发生的。例如你运行了一个应用程序，但它正在控制台等待你的输入（例如正在运行 scanf 语句）而被挂起。 此时 schedule() 函数中的 c==-1，next==0，跳出循环后，执行 switch_to(0)，即切换到进程 0 继续执行，即使此时进程 0 处于挂起状态。总之所有进程都不就绪时系统会执行进程 0 陷入空循环，而不是调用芯片的 nop指令。因此，进程 0 在有些操作系统上又被称为 「System Idle Process」。 参考代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 代码路径：kernel/sched.c /* * 'schedule()' is the scheduler function. This is GOOD CODE! There * probably won't be any reason to change this, as it should work well * in all circumstances (ie gives IO-bound processes good response etc). * The one thing you might take a look at is the signal-handler code here. * * NOTE!! Task 0 is the 'idle' task, which gets called when no other * tasks can run. It can not be killed, and it cannot sleep. The 'state' * information in task[0] is never used. */void schedule(void){ int i,next,c; struct task_struct ** p;/* check alarm, wake up any interruptible tasks that have got a signal */ for(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p) if (*p) { if ((*p)-&gt;alarm &amp;&amp; (*p)-&gt;alarm &lt; jiffies) { (*p)-&gt;signal |= (1&lt;&lt;(SIGALRM-1)); (*p)-&gt;alarm = 0; } if (((*p)-&gt;signal &amp; ~(_BLOCKABLE &amp; (*p)-&gt;blocked)) &amp;&amp; (*p)-&gt;state==TASK_INTERRUPTIBLE) (*p)-&gt;state=TASK_RUNNING; }/* this is the scheduler proper: */ while (1) { c = -1; next = 0; i = NR_TASKS; p = &amp;task[NR_TASKS]; while (--i) { if (!*--p) continue; if ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c) c = (*p)-&gt;counter, next = i; } if (c) break; for(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p) if (*p) (*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; 1) + (*p)-&gt;priority; } switch_to(next); // switch_to源码及代码分析见问题23}// 代码路径：init/main.cvoid main(void) { // 一些基本的初始化，其中很多需要0特权级 ...... move_to_user_mode(); if (!fork()) { /* we count on this going ok */ // 进程 1 所在分支 init(); } // 进程 0 中的空循环，在系统无就绪进程时调度运行 for(;;) pause();} 41. 详细分析一个进程从创建、加载程序、执行、退出的全过程。 创建进程，调用fork函数。（详见 copy_process 函数） a) 准备阶段，为进程在 task[64] 找到空闲位置，即 find_empty_process()； b) 为进程管理结构找到储存空间：task_struct和内核栈。 c) 父进程为子进程复制 task_struct 结构 d) 为新进程复制页表及其其对应的页目录项（但不复制页表指向的内存页） e) 为新进程设置新的段，并设置 LDT f) 在新旧进程之间共享打开的文件 g) 将新进程的 TSS 和 LDT 挂载到全局描述符表 GDT 上 h) 将新进程设为就绪态 加载进程（对应 execve 函数） a) 检查参数和外部环境变量和可执行文件 b) 释放进程的页表 c) 重新设置进程的程序代码段和数据段 d) 调整进程的 task_struct 进程运行（运行新程序遭到缺页中断） a) 进程的代码实际未被加载到内存中；试图执行代码时产生缺页中断并由操作系统响应 严格来说是经过编译后的机器码，不是代码 b) 为进程申请一个物理内存页 c) 将程序代码加载到新分配的页面中 d) 将物理内存地址与线性地址空间对应起来 e) 不断通过缺页中断加载进程的全部内容 f) 运行时如果进程内存不足继续产生缺页中断，往复执行这一过程 进程退出 a) 进程先处理退出事务 b) 释放进程所占页面 c) 解除进程与文件有关的内容并给父进程发信号 d) 进程退出后执行进程调度 42. 详细分析多个进程（无父子关系）共享一个可执行程序的完整过程。为了便于分析，我们假设： 三个进程是通过 fork+execve 的经典方式执行的 三个进程执行间隔很短——例如，通过 bash 脚本执行同一可执行文件的多个副本。 程序执行的速度远大于外存读取的速度，且基本是顺序执行，不会在一小段代码中反复循环。 开机后该执行程序还没有执行过，在缓冲区中没有缓存。 ㈠ execve 加载程序头部假设有三个进程 A、B、C，进程 A 先执行，之后是 B 最后是 C，它们没有父子关系。A 进程启动时会调用 execve 函数打开新的可执行文件，然后调用 bread_page() 函数读取文件开头的内容。bread_page 函数会分配缓冲块，进行设备到缓冲块的数据读取。因为此时为设备读入，时间较长，所以会给该缓冲块加锁，调用 sleep_on 函数，A进程被挂起，调用 schedule()， B 进程开始执行。 B进程也首先执行 execve() 函数。B 进程调用 execve 函数，同样会调用 bread_page()，由于此时内核检测到 B 进程需要读的数据已经进入缓冲区中，则直接返回。但是由于此时设备读没有完成，缓冲块已被加锁，所以 B 将因为等待而被系统挂起，之后调用 schedule() 函数。 C 进程开始执行，但是同 B 一样，被系统挂起，调用 schedule() 函数，假设此时无其它进程，则系统进程 0 开始执行。 等到读操作完成，外设产生中断，中断服务程序开始工作。它给读取的文件缓冲区解锁并调用 wake_up() 函数，传递的参数是 &amp;bh-&gt;b_wait，该函数首先将 C 唤醒，此后中断服务程序结束，开始进程调度。此时 C 就绪，C 程序开始执行，并将 B 进程设为就绪态。C 执行结束或者 C 的时间片削减为 0 （严格来说， C 中调用到 schedule() 也会导致进程切换——但我们先忽略这种情况） 时，切换到 B 进程执行。进程 B 也在 sleep_on() 函数中，调用 schedule 函数进程进程切换后，B 最先回到 sleep_on 函数，进程 B 开始执行，并将进程 A 设为就绪态。同理当 B 执行完或者时间片削减为 0 时，切换到进程 A 执行。此时 A 的内核栈中 sleep_on().tmp 对应 NULL，不会再唤醒进程了。 ㈡ 缺页中断加载随后的程序片段可执行程序的最开头部分由 do_execve 调用 bread_page 读入内存，但其它的部分则不会立马读入内存，而是被运行到时才读取。这种 lazy loading 机制（在源码注释中称为“demand-loading”）让程序只在真正运行到时才被加载进入内存，提高了操作系统创建进程的效率。此时，触发文件加载的不再是 execve，而是缺页中断。 严格来说内存页遇到问题产生的中断不是“缺页中断”，而是“页故障”（page fault），后者才是 Intel 体系结构中的名称。前面 假设进程 C 被唤醒之后一路高歌猛进，在进程切换前直接执行到了未被加载的页。此时处理器触发页故障软中断，调用页故障处理程序。页故障处理程序根据页故障的 error code 判断是缺页故障（见 mm/page.s），跳转到 do_no_page 函数执行。do_no_page 函数首先根据缺失页的线性地址计算出需要读取的设备块编号，然后调用 bread_page 读取至空闲的物理页，最后调用 put_page 将物理页映射到 C 的线性地址空间。 在 bread_page 的过程中又会进入 sleep_on，轮到进程 B 执行。很快，进程 B 也遇到了同样问题（缺页），同样来到 do_no_page 执行类似的逻辑。此时若 C 中请求的页已经读取完毕，do_no_page 会共享相同的页，直接返回继续执行。若此时 C 请求的页尚未读取完毕，则进程 B 的缺页中断处理程序仍会调用 bread_page ，请求相同的页，调用 sleep_on() 挂起运行。最后，进程 A 的情况与进程 B 是类似的。 由此可见，进程 A、B、C 会在“运行、缺页中断、运行、缺页中断……”的循环中轮流执行。 最后要强调的是，依次创建的 3 个用户进程，每个进程都有自己的 task 数组项。三个进程虽然共享程序数据，但栈和数据相互独立。操作系统使用不同的 TSS 和 LDT 实现对进程的保护，不同的进程无法相互访问对方的地址空间。 43. 打开保护模式和分页后，逻辑地址到物理地址是如何转换的？打开保护模式后，x86 处理器开始按段寻址，先按段寄存器中的值选择一个段，然后将逻辑地址加上段基址形成线性地址。若不打开分页，此时的线性地址就是物理地址，处理器会直接根据线性地址到内存中寻址。 打开分页后，线性地址需要进一步经过页表的转换才会变换为物理地址。分页机制在线性地址和物理地址之间增加一层新的 indirection，线性地址又成为了“虚拟地址”。 保护模式下，每个线性地址为 32 位，MMU 按照 10-10-12 的长度来识别线性地址的值。%cr3 中存储着页目录表的基址，线性地址的前 10 位指向页目录表中的页目录项，由此得到对应的页表地址。中间 10 位记录了页表中的页表项位置，由此得到页的位置，最后 12 位表示页内偏移。 同时开启分段（即保护模式）和分页后，完整的地址转换如下图所示： Part III 高速缓冲区44. 为什么要设计缓冲区，有什么好处？设计缓冲区的核心思想在于局部性原理：如果一段代码或数据在最近被使用过，那它在随后就很有可能被再次使用。 在计算机中，内存间的读取速度比外部存储设备（e.g. 硬盘）的读取速度快 2~3 个数量级。如果某个进程将硬盘数据读到缓冲区之后，其他进程刚好也需要读取这些数据，那么就可以直接从缓冲区中读取，大大加快读取速度。如果某个进程将新数据写到缓冲区之后，其他进程刚好也需要修改这些数据，那么就可以直接在缓冲区中修改，避免多次写入硬盘。直接从缓冲区读写的数据越多，计算机的整体性能就会越高。 此外，缓冲区页构成所有块设备数据的统一集散地，使操作系统的设计更方便，更灵活。 45. getblk 函数中，申请空闲缓冲块的标准就是 b_count 为 0，而申请到之后，为什么在 wait_on_buffer(bh) 后又执行if(bh-&gt;b_count) 来判断 b_count 是否为0 ？1234567891011121314// 代码路径：fs\\\\buffer.c#define BADNESS(bh) (((bh)-&gt;b_dirt&lt;&lt;1)+(bh)-&gt;b_lock)struct buffer_head * getblk(int dev,int block){repeat: if (bh = get_hash_table(dev,block)) return bh; ...... wait_on_buffer(bh); if (bh-&gt;b_count) goto repeat; ...... return bh;} wait_on_buffer(bh) 内包含睡眠函数，在睡眠中可能已有其它进程执行过。睡眠唤醒后，之前找到的比较合适的空闲缓冲块可能在睡眠阶段又被其他任务所占用，因此必须重新判断是否被修改。若判断被占用则回到 repeat，重新获取资源。 字段 b_count 用于标记「每个缓冲块有多少个进程在共享」。只有当b_count==0 时，该缓冲块才能被再次分配。 举一个可能引发异常的例子：每个缓冲块有一个进程等待队列，假设此时 B、C 两进程在队列中，当该缓冲块被解锁时，进程C被唤醒（它开始使用缓冲区之前需先唤醒进程 B，使进程 B 从挂起进入就绪状态），将缓冲区加锁。一段时间后，进程C又被挂起，但此时缓冲区由进程 C 在使用。此时，若进程B被调度，if (bh-&gt;b_count) 会注意到该缓冲区任是加锁状态，从而进程 B 重新选择缓冲区。如果没有这一额外判断，将造成进程 B 操作一个被加锁的缓冲区，引发异常。 这一问题的本质在于竞争条件，是操作系统编程和并发编程中的一大难题。 46. b_dirt 已经被置为1的缓冲块，同步前能够被进程继续读、写吗？为什么？给出代码证据。这样的缓冲块在同步前能够被继续读、写。 缓冲块是否能被进程读写，并不取决于 b_dirt，而取决于b_uptodate。只要 b_uptodate 为 1，缓冲块就能被进程读写。 这一设计背后的根源在于，我们并不在乎缓冲区是否与硬盘上的数据同步，而是希望缓冲区上的数据总是最新的，只有这样缓冲区才能成为硬盘数据的缓存。 具体来说，读操作不会改变缓冲块中数据的内容，写操作后，改变了缓冲区内容，需要将 b_dirt 置 1 ，为后面的写回做准备。而b_uptodate 设置为1后，内核便支持进程共享该缓冲块的数据了，读写均可。读操作不会改变缓冲块的内容，所以不影响数据；而执行写操作后，就改变了缓冲块的内容，就要将 b_dirt 标志设置为 1 。由于之前缓冲块已经和硬盘块更新了，所以后续同步过程中『缓冲块没有写入新数据的部分』和『原来硬盘对应的部分』相同，向硬盘同步时，所有的数据都是进程希望同步到硬盘数据块上的，不会把垃圾数据同步到硬盘上去。所以 b_uptodate 仍为 1 。所以， b_dirt 为 1 ，进程仍能对缓冲区进行读写。 代码证据： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//代码路径：fs/block_dev.cint block_write(int dev, long * pos, char * buf, int count)//块设备文件内容写入缓冲块{ ....... offset = 0; *pos += chars; written += chars; count -= chars; while (chars--&gt;0) *(p++) = get_fs_byte(buf++); bh-&gt;b_dirt = 1; // HERE! brelse(bh); .......}// 代码路径：fs/file_dev.c// 将普通文件内容写入缓冲块int file_write(struct m_inode * inode, struct file * filp, char * buf, int count){ ...... c = pos % BLOCK_SIZE; p = c + bh-&gt;b_data; bh-&gt;b_dirt = 1; // HERE! c = BLOCK_SIZE-c; if (c &gt; count-i) c = count-i; pos += c; if (pos &gt; inode-&gt;i_size) { inode-&gt;i_size = pos; inode-&gt;i_dirt = 1; } i += c; while (c--&gt;0) *(p++) = get_fs_byte(buf++); brelse(bh); ......}// 代码路径：fs/namei.cstatic struct buffer_head * add_entry(struct m_inode * dir, const char * name, int namelen, struct dir_entry ** res_dir){ ...... if (i*sizeof(struct dir_entry) &gt;= dir-&gt;i_size) { de-&gt;inode=0; dir-&gt;i_size = (i+1)*sizeof(struct dir_entry); dir-&gt;i_dirt = 1; // HERE! dir-&gt;i_ctime = CURRENT_TIME; } if (!de-&gt;inode) { dir-&gt;i_mtime = CURRENT_TIME; for (i=0; i &lt; NAME_LEN ; i++) de-&gt;name[i]=(i&lt;namelen)?get_fs_byte(name+i):0; bh-&gt;b_dirt = 1; // HERE! *res_dir = de; return bh; } ......} 47. 分析 panic() 函数的源代码，根据你学过的操作系统知识，完整、准确的判断 panic() 函数所起的作用。假如操作系统设计为支持内核进程（始终运行在0特权级的进程），你将如何改进 panic() 函数？ panic() 函数是当系统发现无法继续运行下去的故障时将调用它，会导致程序终止，然后由系统显示错误号。如果出现错误的函数不是进程0，那么就要进行数据同步，把缓冲区中的数据尽量同步到硬盘上。遵循了 Linux 尽量简明的原则。 改进 panic 函数：将死循环 for(;;); 改进为跳转到内核进程（始终运行在 0 特权级的进程），让内核继续执行。 12345678910111213// 代码路径：kernel/panic.c#include &lt;linux/kernel.h&gt;#include &lt;linux/sched.h&gt;void sys_sync(void); /* it's really int */volatile void panic(const char * s){ printk(&quot;Kernel panic: %s\\\\n\\\\r&quot;,s); if (current == task[0]) printk(&quot;In swapper task - not syncing\\\\n\\\\r&quot;); else sys_sync(); for(;;); // HERE!} 48. wait_on_buffer函数中为什么不用 if(...) 而是用 while(...) ？一言以蔽之：因为竞争条件。 考虑如下情况：若干($\\ge2$)进程都在等待同一个缓冲块，构成了等待同一资源的进程等待队列。在缓冲块（资源）同步完毕后，会陆续唤醒各等待进程收取资源。陆续唤醒、轮到某一进程时，可能此时缓冲块已被刚刚被唤醒的前一进程重新占用，甚至加上了锁。因此进程被唤醒后需要重新检查资源是否可用，才能保证程序的正确性。 代码参考： 12345678910111213// 代码路径：fs/buffer.cstatic inline void wait_on_buffer(struct buffer_head * bh){ // 为进一步减少竞争条件，（在这一任务的控制流中）关闭中断 // 这样禁止了时钟中断，从而避免了遭到被动调度、意外打断控制流的可能性。 cli(); while (bh-&gt;b_lock) // 为等待资源，主动睡眠 sleep_on(&amp;bh-&gt;b_wait); // 被唤醒后需要重新检查是否获得资源 // 恢复中断 sti();} 49. 操作系统如何利用 b_uptodate 保证缓冲块数据的正确性？ new_block(int dev) 函数新申请一个缓冲块后，并没有读盘，b_uptodate 却被置 1，是否会引起数据混乱？详细分析理由。b_uptodate 是缓冲块管理结构中的标志位，它的作用是告诉内核「缓冲块中的数据是否是最新的」。 当从硬盘读取已有文件时，b_uptodate 意味着硬盘上的数据是否已经同步到缓冲块中。置 1 时，说明缓冲块中的数据已完成同步，内核可以放心地支持进程与缓冲块进行数据交互；如果 b_uptodate 为 0，就提醒内核最新的数据还没有同步到该缓冲块上，向该缓冲块写入会导致竞争，因此也不支持进程共享该缓冲块。 为新建文件（或为文件添加的新数据）创建一个缓冲块时，b_uptodate 被置 1，这是因为此时的新文件刚刚由用户建立，本身就是最新的，硬盘上的内容才是“垃圾数据”、是落后的一方。因此，缓冲块中的 b_uptodate 被置为 1，不会引起混乱，而是读写逻辑需求导致。 严格来说，新建的数据块还可能用于存储文件的 i_zone 间接块管理信息。 如果是间接块管理信息，缓冲区必须清零，表示没有索引间接数据块，否则垃圾数据会导致索引错误，破坏文件操作的正确性。虽然缓冲块与硬盘数据块的数据不一致，但缓冲块上是更加新的数据，将 b_uptodate 置 1 同样不会有问题。 综上所述，设计者采用的策略如下：只要为新建的数据块新申请了缓冲块，不论该缓冲块将来用作什么，由于进程不需要里面原有的数据，干脆全部清零。这样不管与之绑定的数据块用来存储什么信息，都无所谓，同时将该缓冲块的 b_uptodate 字段设置为 1，更新问题“等效于”已解决。 50. add_request() 函数中有下列代码，其中的前两行（不含括号）是什么意思？12345678// 代码路径：kernel/blk_drv/ll_rw_blk.c/add_request(...)if (!(tmp = dev-&gt;current_request)) { dev-&gt;current_request = req; sti(); (dev-&gt;request_fn)(); return;} 前两行为： 12345if (!(tmp = dev-&gt;current_request)) { dev-&gt;current_request = req; ......} 这两行查看指定设备是否有当前请求项，即查看设备是否忙。如果指定设备 dev 当前请求项 dev-&gt;current_request 为空，则表示目前设备没有请求项。本次是头一个请求项，也是当前唯一的一个请求项。因此： 可将「块设备当前请求指针」直接指向该请求项， 需要手动触发「相应设备的请求函数」——这一函数在请求队列非空时循环执行，但请求队列清空后便停止执行。因此放入新请求项时需要再次手动触发。 51. do_hd_request() 函数中 dev 的含义始终一样吗？不一样。 do_hd_request() 函数主要用于处理当前硬盘请求项，但其中的 dev 变量含义并不一致。dev = MINOR(CURRENT-&gt;dev) 意味着取硬盘的逻辑设备号，对硬盘来说，为「物理硬盘号x5+硬盘上的分区号」。dev/=5 这一指令后表示的实际的物理设备号，即「第几块物理硬盘」。 12345678910111213141516//代码路径：kernel/blk_drv/hd.cvoid do_hd_request(void){ int i,r; unsigned int block,dev; ...... dev = MINOR(CURRENT-&gt;dev); // HERE! block = CURRENT-&gt;sector; if (dev &gt;= 5*NR_HD || block+2 &gt; hd[dev].nr_sects) { end_request(0); goto repeat; } block += hd[dev].start_sect; dev /= 5; // HERE! ......} 为什么会有这样复杂的设备号约定呢？Linux 0.11 中，设备号分为主设备号和次设备号。其中，硬盘的主设备号是 3。其它设备的主设备号分别为： 1-内存，2-磁盘， 3-硬盘， 4-ttyx， 5-tty，6-并行口，7-非命名管道 由于 1 个硬盘中可以存在 1-4 个分区，因此硬盘还依据分区的不同用次设备号进行指定分区。因此，硬盘的逻辑设备号由以下方式构成： 设备号=主设备号*256 + 次设备号 以两个硬盘、每个硬盘上有四个分区为例，具体的硬盘号如下表所示： 逻辑设备号 对应设备文件 说明 0x300 /dev/hd0 代表整个第 1 个硬盘 0x301 /dev/hd1 表示第 1 个硬盘的第 1 个分区 0x302 /dev/hd2 表示第 1 个硬盘的第 2 个分区 0x303 /dev/hd3 表示第 1 个硬盘的第 3 个分区 0x304 /dev/hd4 表示第 1 个硬盘的第 4 个分区 0x305 /dev/hd5 代表整个第 2 个硬盘 0x306 /dev/hd6 表示第 2 个硬盘的第 1 个分区 0x307 /dev/hd7 表示第 2 个硬盘的第 2 个分区 0x308 /dev/hd8 表示第 2 个硬盘的第 3 个分区 0x309 /dev/hd9 表示第 2 个硬盘的第 4 个分区 从 linux 内核 0.95 版后已经不使用这种烦琐的命名方式，而是使用与现在相同的命名方法了。 52. read_intr() 函数中，下列代码是什么意思？为什么这样做？12345// 代码路径：kernel/blk_drv/hd.c/read_intr()if (--CURRENT-&gt;nr_sectors) { do_hd = &amp;read_intr; return; } read_intr() 是对磁盘发出读取请求后操作系统用于处理磁盘返回中断的函数。当读取扇区操作成功后，-—CURRENT-&gt;nr_sectors 递减请求项所需读取的扇区数值。若递减后不等于 0，表示本项请求还有扇区没读完，于是再次置中断调用函数指针 do_hd = &amp;read_intr; 并直接返回，等待硬盘在读出下一扇区数据后发出中断并再次调用本函数。 53. bread() 函数代码中为什么要做第二次 if (bh-&gt;b_uptodate) 判断？1234567// 代码路径：fs/buffer.c/bread(int dev, int block)if (bh-&gt;b_uptodate) return bh;ll_rw_block(READ,bh);wait_on_buffer(bh);if (bh-&gt;b_uptodate) return bh; bread() 函数的功能是向内核中的上层函数提供从块设备上读取数据块的函数接口，而内部则为数据块加了一层 RAM 上的缓冲区作为块数据的缓存。 bread() 会调用底层 ll_rw_block() 函数，产生读设备请求。然后等待指定数据块读入，并等待缓冲块解锁。在睡眠醒来之后，如果缓冲块已更新 if (bh-&gt;b_uptodate)，则返回缓冲块指针。否则，表明读设备操作失败，于是释放该缓冲块返回 NULL。 第一次检查：从高速缓冲区中取出需要的缓冲块， 判断缓冲块数据是否已同步，已读取过（严格来说要求缓冲块中数据时最新的）则返回此块。如果该缓冲块数据无效（更新标志未置位——这往往意味着缓冲块中的数据还没有从磁盘中读取）， 则向设备发送数据块读取请求。 第二次检查：等指定数据块被读入，并且缓冲区解锁，睡眠醒来之后，要重新判断缓冲块是否有效。在睡眠等待过程中，数据可能已经发生了改变，所以要第二次判断。 54. getblk() 函数中，两次调用 wait_on_buffer() 函数，两次的意思一样吗？123456789101112131415161718192021222324252627282930313233343536373839// 代码路径：fs/buffer.c#define BADNESS(bh) (((bh)-&gt;b_dirt&lt;&lt;1)+(bh)-&gt;b_lock)struct buffer_head * getblk(int dev,int block){ struct buffer_head * tmp, * bh;repeat: if (bh = get_hash_table(dev,block)) return bh; tmp = free_list; do { if (tmp-&gt;b_count) continue; // 问题37中的continue if (!bh || BADNESS(tmp)&lt;BADNESS(bh)) { bh = tmp; if (!BADNESS(tmp)) break; // 问题37中的break }/* and repeat until we find something good */ } while ((tmp = tmp-&gt;b_next_free) != free_list); if (!bh) { sleep_on(&amp;buffer_wait); goto repeat; } wait_on_buffer(bh); // 第一处 if (bh-&gt;b_count) goto repeat; while (bh-&gt;b_dirt) { sync_dev(bh-&gt;b_dev); wait_on_buffer(bh); // 第二处 if (bh-&gt;b_count) goto repeat; }/* NOTE!! While we slept waiting for this block, somebody else might *//* already have added &quot;this&quot; block to the cache. check it */ if (find_buffer(dev,block)) goto repeat; ......} 相同又不同。都是等待缓冲块解锁，这是相同之处。 第一次调用是无条件的，已找到一个比较合适的空闲缓冲块 (bh-&gt;b_count==0)，但是此块可能是加锁的（往往是因为正在同步至硬盘），于是等待该缓冲块解锁。 第二次调用， 是针对此块中原先的数据已被修改过（”脏的“）但尚未同步的情况，于是 先下达把数据同步到硬盘上的指令 sync_dev(bh-&gt;b_dev) 同步时会加锁， 所以随后需要等待缓冲块解锁，即下一行的 wait_on_buffer(bh)。 值得注意的是，wait_on_buffer(bh) 时原则上可能有一整个缓冲队列（多个进程）在等待同一资源，因此等待结束后、当前进程调度前可能被其它进程抢先占据了资源，因此 Linus 又做了额外判断作为保险： 12if (bh-&gt;b_count) // 缓冲块又被其它某个进程先拿走了 goto repeat; 当然，对缓冲块而言这种情况发生的频率应当是很低的。 55. getblk() 函数中，说明什么情况下执行 continue 、break。12345678910// 代码路径：fs/buffer.c/getblk(...)do { if (tmp-&gt;b_count) continue; if (!bh || BADNESS(tmp)&lt;BADNESS(bh)) { bh = tmp; if (!BADNESS(tmp)) break; }} while ((tmp = tmp-&gt;b_next_free) != free_list); getblk() 函数主要是获取高速缓冲中的指定缓冲块。但缓冲块有可能正在被其它进程使用、有可能内容已修改需要写回，有可能正在写回，情况复杂。如何选取最合适的缓冲块，就成了这段代码要解决的问题。 缓冲块的参数指标有三个： bh-&gt;b_count 是缓冲块的引用计数，指明缓冲块被多少个进程使用。 bh-&gt;b_dirt 指明缓冲块的内容是否被修改过。如果被修改过后又要写入新内容，那原来的内容就需要先同步回磁盘。 bh-&gt;b_lock 是缓冲块的锁，指明缓冲块已被某个进程拥有且正在进行一些不可打断的原子操作。例如，某个进程正在同步缓冲块至磁盘时会给缓冲块加上锁。 free_list 是一个将所有缓冲块串在一起的双向链表。虽叫 “free” list，但实际上并不是包含所有空闲缓冲块的链表，而是一个大致表明缓冲块“空闲程度”的优先队列。每个缓冲块被使用过后会被挪移到链表的末尾，因此距离上次使用时间越长的缓冲块便会越接近链表的队头。因此这一链表逻辑上是一个优先队列，起到了类似 LRU 缓存策略的功能。 下面我们回到问题，作具体分析。 12345678910111213141516171819// 代码路径：fs/buffer.c/getblk(...)#define BADNESS(bh) (((bh)-&gt;b_dirt&lt;&lt;1)+(bh)-&gt;b_lock)...if (bh = get_hash_table(dev,block)) return bh; tmp = free_list;// 1. 走到此处意味着 bh==NULL，且说明函数希望读取的内容不在任何一个已有的缓冲块中。do { if (tmp-&gt;b_count) continue; // 2. 走到此处意味着 tmp-&gt;b_count==0 if (!bh || BADNESS(tmp)&lt;BADNESS(bh)) { // 3. 走到这一分支意味着我们有更好的缓冲块选择 bh = tmp; if (!BADNESS(tmp)) // 4. 走到这一路径说明BADNESS(tmp)==00，完美符合我们的要求，直接退出循环 break; }} while ((tmp = tmp-&gt;b_next_free) != free_list); get_hash_table(...) 会试图找到已经被缓存的块并直接返回，若找不到则返回 NULL。因此若代码运行至 1 处，说明在已有的缓冲区中找不到需要的内容，需要从硬盘中读取内容再返回。 随后函数遍历 free_list 寻找合适的缓冲块。由于是从前向后遍历，距上次使用时间更长的块更有可能被选中。若该缓冲块引用计数不为零，说明正在被其它进程使用；又因为「需要读取的内容」和「任意已有缓冲块中内容」都不一样，不可能使用该缓冲块。直接跳过，即运行 continue。 若程序运行到 3 处，说明找到了一个不被其它进程使用的缓冲块，可以处理掉其中内容之后读取新内容。这样的缓冲块能用就行，但如果不脏就更好了。 若程序运行到 4 处，说明着找到了一个既没有被其它进程使用，也没有被修改过，也没有被加锁的缓冲块。这意味着找到了一个完美的空闲缓冲块，因此直接退出循环，即运行 break。 56. make_request() 函数 ，其中的 sleep_on(&amp;wait_for_request) 是谁在等？等什么？123456789// 代码路径：kernel/blk_drv/ll_rw_blk.c/make_request(...)if (req &lt; request) { if (rw_ahead) { unlock_buffer(bh); return; } sleep_on(&amp;wait_for_request); goto repeat;} 这行代码等待的资源是空闲请求项，等待的进程是包括当前进程在内的所有需要这一资源的进程。 make_request() 函数主要功能为「创建请求项并将其插入请求队列」。执行 if 分支中的内容说明没有找到空请求项，即请求项数组 request[32] 中没有一项是空闲的。因此让进程暂停，等待前面的读写任务完成，等待请求项释放。 严格来说，是没有满足条件的请求项，因为读写操作的可用请求项部分不完全一样，写操作能够占用的请求项只有前 32*2/3=21 个。 如果是预读取请求（即 rw_ahead），那么在这种情况下便直接放弃。 57. 操作系统如何处理多个进程等待同一个正在与硬盘交互的缓冲块？对于一个正在与硬盘交互的缓冲块，操作系统将其加锁。进程遇到加锁的缓冲块，需要执行 wait_on_buffer。 12345678// 代码路径：fs/buffer.cstatic inline void wait_on_buffer(struct buffer_head * bh){ cli(); while (bh-&gt;b_lock) sleep_on(&amp;bh-&gt;b_wait); sti();} 在 wait_on_buffer 中，如果缓冲块加锁，进程需要执行 sleep_on 函数。sleep_on 函数中，先将当前进程记录到 p=&amp;bh-&gt;b_wait 中，供日后唤醒。然后将当前进程挂起、设置为不可打断的等待状态，最后调用 schedule() 切换至其它进程执行，直到当前进程被唤醒。 123456789// 代码路径：kernel/sched.cvoid sleep_on(struct task_struct **p){ ...... *p = current; current-&gt;state = TASK_UNINTERRUPTIBLE; schedule(); ......} 然而，一种更复杂的情况是多个进程等待同一个资源，例如，多个进程同时等待某个正在与硬盘交互的缓冲块。这时，当进程试图睡眠时 bh-&gt;b_wait 已经是一个非空值，里面保存着之前已经在等待的进程。为此，sleep_on 会先将 p=&amp;bh-&gt;b_wait 中的内容暂存到 tmp 中，当自己被唤醒后再唤醒 tmp 中指向的进程。这样一来，所有等待同一资源的进程都会被唤醒。 123456789101112131415161718192021222324// 代码路径：kernel/sched.cvoid sleep_on(struct task_struct **p){ struct task_struct *tmp; // HERE!! if (!p) return; if (current == &amp;(init_task.task)) panic(&quot;task[0] trying to sleep&quot;); tmp = *p; // 将进程 *p = current; current-&gt;state = TASK_UNINTERRUPTIBLE; schedule(); if (tmp) // 唤醒tmp指向的进程 tmp-&gt;state=0; //=TASK_RUNNING}......void wake_up(struct task_struct **p){ if (p &amp;&amp; *p) { (**p).state=0; *p=NULL; }} 某一时刻，多个等待某资源的进程的 sleep_on 函数中可能有多个 tmp 变量，依次指向这条“等待链”中的下一个进程。这时，函数中的临时指针 tmp 其实构成了一个隐式的等待队列，由该资源的 wait 指针（对缓冲块而言，是缓冲头中的 bh-&gt;b_wait）指向队列的队头（见下图）。唤醒时，由队头向后依次唤醒等待队列中的所有进程（见代码）。 58. add_request() 函数中有下列代码1234567// 代码路径：kernel/blk_drv/ll_rw_blk.c/add_request(...)if (!(tmp = dev-&gt;current_request)) { dev-&gt;current_request = req; sti(); (dev-&gt;request_fn)(); return;} 其中的 123if (!(tmp = dev-&gt;current_request)) { dev-&gt;current_request = req;} 是什么意思？ 查看指定设备是否有当前请求项，即查看设备是否忙。如果指定设备当前请求项为空，则表示目前设备没有请求项 (dev-&gt;current_request ==NULL)，本次是第一个请求项，也是唯一的一个。因此可将块设备当前请求指针直接指向该请求项，并立即执行相应设备的请求函数。 59. 操作系统如何利用 buffer_head 中的 b_data, b_blocknr, b_dev, b_uptodate, b_dirt, b_count, b_lock, b_wait 字段管理缓冲块的？管理缓冲块的「缓冲块头结构」struct buffer_head 在源代码中的定义如下： 123456789101112131415// 代码路径：include/linux/fs.hstruct buffer_head { char * b_data; /* pointer to data block (1024 bytes) */ unsigned long b_blocknr; /* block number */ unsigned short b_dev; /* device (0 = free) */ unsigned char b_uptodate; unsigned char b_dirt; /* 0-clean,1-dirty */ unsigned char b_count; /* users using this block */ unsigned char b_lock; /* 0 - ok, 1 -locked */ struct task_struct * b_wait; struct buffer_head * b_prev; struct buffer_head * b_next; struct buffer_head * b_prev_free; struct buffer_head * b_next_free;}; 「缓冲块头结构」buffer_head 负责管理缓冲块以及进程与缓冲块的交互。 b_data 指向被管理的缓冲块数据。 b_dev,b_blocknr 是缓冲块中缓冲的数据（若有）的设备号（例如，硬盘的某个分区）和逻辑块号。 内核在 hash_table 表中搜索带有某内容的缓冲块时，只看设备号与块号（即 b_dev 和 b_blocknr）。只要缓冲块与硬盘数据的绑定关系还在，就认定数据块仍停留在缓冲块中，就可以直接返回、使用。 b_uptodate 与 b_dirt，是为了解决缓冲块的数据同步性而引入的两个标志。 b_uptodate 指明缓冲块中的内容是否是最新的。如果 b_uptodate 为 1，说明缓冲块的数据已经是数据块中最新的，可以支持进程共享缓冲块中的数据；如果 b_uptodate 为 0，提醒内核缓冲块并没有用绑定的数据块中的数据更新，不支持进程共享该缓冲块。当一个缓冲块中未载入硬盘上的数据时，缓冲块的 b_uptodate 为 0；当进程修改了某些内容而未同步入缓冲块中时， b_uptodate 也会置零。 b_dirt 是标记缓冲块中的内容是否被进程修改过了（“脏位”）。为 1 说明缓冲块的内容被进程方向的改写了，最终需要同步到硬盘上；b_dirt 为 0 则说明不需要同步。 b_count 记录每个缓冲块有多少进程共享，即引用计数。b_count 大于 0 表明有进程在共享该缓冲块；当进程不需要共享缓冲块时，内核会解除该进程与缓冲块的关系，并将 b_count 数值减 1，为 0 表明可以被当作新缓冲块来申请使用。 b_lock 为缓冲块的“加锁”标记。具体来说，为 1 说明缓冲块正与硬盘交互，内核会拦截进程对此时该缓冲块的操作，以免发生错误。交互完成后，置0，表明进程可以操作该缓冲块。 b_wait 记录等待缓冲块的解锁而被挂起的进程，指向等待队列的第一个进程的 task_struct。 60. 用图表示下面的几种情况，并从代码中找到证据： (a) 当进程获得第一个缓冲块的时候，哈希表 hash_table 的状态。 (b) 经过一段时间的运行，已经有 2000 多个 buffer_head 挂到 hash_table 上时，hash 表（包括所有的 buffer_head）的整体运行状态。 (c) 经过一段时间的运行，有的缓冲块已经不被进程使用了（空闲），这样的空闲缓冲块是否会从 hash_table 上脱钩？ (d) 经过一段时间的运行，所有的 buffer_head 都挂到 hash_table 上了，这时，又有进程申请空闲缓冲块，将会发生什么？ (a) Linux-0.11 中，采用了两种管理缓冲块的数据结构：一个哈希表 hash_table[307]，用于根据设备号和块号快速找到需要的缓冲块（如果有的话）；和一个实现为双向链环的优先队列 free_list，用于按序存储 least recently used 的缓冲块。代码证据如下所示： 123456789101112131415161718192021222324252627// 代码路径：fs/buffer.cstruct buffer_head * hash_table[NR_HASH]; // NR_HASH=307static struct buffer_head * free_list;......// 哈希函数：(dev XOR block) mod 307#define _hashfn(dev,block) (((unsigned)(dev^block))%NR_HASH)#define hash(dev,block) hash_table[_hashfn(dev,block)]// 管理两个数据结构的函数有很多，这里挑选了一个最有代表性的函数// 插入队列时将bh放在最后，也说明free_list是一个按LRU顺序排列的优先队列static inline void insert_into_queues(struct buffer_head * bh){/* put at end of free list */ bh-&gt;b_next_free = free_list; bh-&gt;b_prev_free = free_list-&gt;b_prev_free; free_list-&gt;b_prev_free-&gt;b_next_free = bh; free_list-&gt;b_prev_free = bh;/* put the buffer in new hash-queue if it has a device */ bh-&gt;b_prev = NULL; bh-&gt;b_next = NULL; if (!bh-&gt;b_dev) return; bh-&gt;b_next = hash(bh-&gt;b_dev,bh-&gt;b_blocknr); hash(bh-&gt;b_dev,bh-&gt;b_blocknr) = bh; bh-&gt;b_next-&gt;b_prev = bh;} 假设第一个缓冲块挂在了 hash_table[1] 上，此时哈希表的状态如下图所示： (b) 运行一段时间、有很多缓冲块被挂在哈希表上时，整体的运行状态大致如下图所示： (c) 不会。缓冲区的设计原则是让缓冲块尽可能久地停留在内存中，从而便于随后重用、减少访存时间。即使一个缓冲块的引用计数减至零，也不会被直接从哈希表上拿走，而是留在内存中，直到重新被引用，或者为了缓冲其它内容而被覆盖。 (d) 为了获取新的、可用的缓冲块，内核沿 free_list 依次遍历查找 least recently used 的缓冲块： 引用计数为零(b_count==0)且不需要同步操作的缓冲块最优先； 引用计数为零且正在同步的(b_lock==1)缓冲块次之； 引用计数为零且需要同步(b_dirt==0)但还没有开始同步的(b_lock==0)块再次； 如果没有引用计数为零的缓冲块，说明所有缓冲块都被其它进程占用了。内核会挂起当前进程，等待空闲缓冲块。 Part IV 文件系统第一步：加载根文件系统61. 在代码中多次出现一个宏 ROOT_DEV，即根设备。什么是根设备？与文件系统、根文件系统有什么关系？操作系统中的文件系统大致可以分为两部分：一部分在操作系统内核中，另一部分在硬盘、软盘、虚拟盘中。每个逻辑盘（例如硬盘的分区、虚拟盘）中由索引节点（i节点，inode）和目录文件形成文件的树状结构，构成了每个逻辑盘中的文件系统。每个逻辑盘中的文件系统有一个根索引节点，由根索引节点便可找到文件系统中的所有文件。 硬盘可以有多个分区，每个分区中有自己单独的文件系统，因此操作系统可能要面对多个文件系统。然而 Unix 和 Linux 系统中最终呈现给用户的是一个单独的文件树，所有的设备、文件都被组织到了一棵单独的树上。这一矛盾是怎么解决的呢？为此，不同的文件系统需要相互挂载，一个文件系统的根索引节点会被挂载到另一文件系统的某个目录上。这样一来，被挂载的文件系统就好像是上层文件系统的一个目录一样。在 Linux 系统中，可以通过大家熟悉的 mount 指令实现文件系统之间的挂载。 当文件系统相互挂载，最上层的文件系统便被称为根文件系统。根文件系统的根节点成为了整个 Linux 文件树的根，而其它文件系统只是 Linux 文件树中的一个目录。进一步的，根文件系统所在的设备就叫根设备。 62. 在虚拟盘被设置为根设备之前，操作系统的根设备是软盘，请说明设置软盘为根设备的技术路线。首先，将软盘的第一个扇区设置为可引导扇区: 123456# 代码路径：boot/bootsect.s.org 508root_dev: .word ROOT_DEVboot_flag: .word 0xAA55 在主 Makefile 文件中设置 ROOT_DEV=/dev/hd6。并且在 bootsect.s 中的第 508 和 509 比特处设置ROOT_DEV=0x306；在 tools/build 中根据 Makefile 中的 ROOT_DEV 设置 MAJOR_TOOT 和 MINOR_ROOT，并将其填充在偏移量为 508 和 509 处： 1234// 代码路径：MakefileImage: boot/bootsect boot/setup tools/system tools/build tools/build boot/bootsect boot/setup tools/system $(ROOT_DEV) &gt; Image sync 随后被移至 0x90000+508=0x901FC 处，最终在 main.c 中设置为 ORIG_ROOT_DEV 并将其赋给 ROOT_DEV 变量： 123// 代码路径：init/main.c#define ORIG_ROOT_DEV (*(unsigned short *)0x901FC)ROOT_DEV = ORIG_ROOT_DEV; 63. Linux-0.11 是怎么将根设备从软盘更换为虚拟盘，并加载了根文件系统？操作系统自启动之后就在不断地挪移、覆盖 ROOT_DEV 变量的值，直到 mount_root 函数中才真正地根据该变量的值挂载根文件系统。 12345678// 代码路径：kernel/blk_drv/hd.cint sys_setup(void * BIOS){ ...... rd_load(); // 格式化虚拟盘，覆盖ROOT_DEV变量为虚拟盘的设备号 mount_root(); // 真正挂载根文件系统 return (0);} rd_load 函数首先从软盘读取虚拟盘的文件系统映像 (image) 并将其复制到虚拟盘中，随后设置 ROOT_DEV 为 0x0101 将根设备从软盘更换为虚拟盘。主设备号是1，代表内存，即将内存虚拟盘设置为根目录。 123456// 代码路径：kernel/blk_drv/ramdisk.cvoid rd_load(void){ ...... ROOT_DEV=0x0101;} 随后，sys_setup 调用 mount_root 函数，真正地挂载根文件系统。过程如下：首先，初始化文件管理结构 file_table[64] 和超级块数据结构 super_block[8]。随后，读取根文件系统的超级块和根索引节点。然后，将超级块和根索引节点关联起来，并将根文件系统的根索引节点设置为1进程的当前工作目录和根目录。最后，统计空闲逻辑块数及空闲索引节点数，并打印显示给用户。 123456789101112131415161718192021222324// 代码路径：fs/super.cvoid mount_root(void){ ...... struct super_block * p; struct m_inode * mi; ...... // 初始化文件管理结构file_table[64] // 初始化内存中的超级块数组super_block[8] ...... if (!(p=read_super(ROOT_DEV))) // 从根设备上读取超级块 panic(&quot;Unable to mount root&quot;); if (!(mi=iget(ROOT_DEV,ROOT_INO))) // 读取根设备上的根索引节点 panic(&quot;Unable to read root i-node&quot;); // 增加i节点的引用计数 mi-&gt;i_count += 3 ; /* NOTE! it is logically used 4 times, not 1 */ // 将超级块关联到根索引节点上 p-&gt;s_isup = p-&gt;s_imount = mi; // 将根文件系统的根索引节点设置为当前进程的当前工作目录和根目录——此时当前进程是1进程。 current-&gt;pwd = mi; current-&gt;root = mi; ...... // 统计根文件系统中的空闲逻辑块数量、逻辑块总数、空闲i节点数量、i节点总数} 参考文献[1] Linux kernel source code, by Linus Torvalds et al., version 0.11(0.95), 1991. [2] 《Linux内核设计的艺术》，新设计团队（即杨力祥老师带领的团队^_^） 著，第2版，2013年出版. [3] 《Linux内核完全注释 内核版本0.11(0.95)》，赵炯 著，修正版1.9.5，2004年. [4] IA-32 Intel® Architecture Software Developer’s Manual, by Intel, 2003. [5] 《IA-32 架构软件开发人员手册 第3卷：系统编程指南（中文版-部分）》，lijshu等 译，2005年. [6] 为什么BIOS要将主引导扇区（MBR）加载到0x7c00这个地址？，by greatgeek，CSDN，https://blog.csdn.net/greatgeek/article/details/102542271，2019年. [7] 知乎问题“在游戏的发展历史中，出现过哪些有意思的加密反盗版机制和破解机制？”下用户「Zign」的回答，by Zign，知乎，https://www.zhihu.com/question/46773069，2018年. [8] OldLinux（赵炯博士创建的在线Linux分享讨论平台），www.oldlinux.org. 附录：思考题调整前后编号对照表在修订时，为了让问题之间的逻辑更加连贯，我重新调整了思考题的顺序。为了方便与原版思考题题目对照参考、查找答案，我把原编号和现编号的对照关系放在这里。 现 → 原 1 → 1 2 → 2 3 → 3 4 → 4 5 → 5 6 → 6 7 → 41 8 → 7 9 → 44 10 → 40 11 → 8 12 → 9 13 → 10 14 → 11 15 → 42 16 → 12 17 → 61 18 → 43 19 → 13 20 → 14 21 → 62 22 → 15 23 → 17 24 → 16 25 → 46 26 → 53 27 → 18 28 → 47 29 → 48 30 → 19 31 → 49 32 → 56 33 → 20 34 → 21 35 → 50 36 → 22 37 → 23 38 → 45 39 → 24 40 → 29 41 → 51 42 → 52 43 → 25 44 → 54 45 → 26 46 → 27 47 → 28 48 → 30 49 → 31 50 → 32 51 → 33 52 → 34 53 → 35 54 → 36 55 → 37 56 → 38 57 → 63 58 → 60 59 → 55 60 → 57 61 → 原创 62 → 58 63 → 59","link":"/2022/12/31/Linux-0-11-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%80%9D%E8%80%83%E9%A2%98/"},{"title":"原子核有结构吗？","text":"〇.引言从初中开始，我们就被告知原子具有这样的结构：而带负电的电子则在核外进行着稀奇古怪的运动，而带正电的质子和不带电的中子则聚成一团，乖巧地待在中央。 到了高中，我们进一步理解了电子的壳层模型，惊讶于如此简洁的电子模型竟可以构建起复杂键价理论，惊讶于电子的简单变化竟可以创造出如此丰富多彩的化学世界。与之相比，原子核便显得有些无趣了。中子和质子缩成一团，均匀而缺乏层次（至少在许多科普插图中是如此）。电子是活泼的，在各种化学反应中总是从一个原子身边跳到另一个原子身边，而通过对这种过程的研究，我们也得以加深对电子的理解。与之相比，原子核便显得高冷许多，只有在核反应中才会发生变化。而核反应，例如裂变、天然衰变，往往条件苛刻，很少发生。这也让我们对原子核知之甚少，如同面对一位深居简出的大人物。 如果你对原子核的”一团浆糊“模型感到不满意，一个自然的问题便是，原子核是否有结构？如果有，是什么样的？这种结构是如何导致神秘的核反应发生的呢？进一步地，原子核是否也像核外电子一样，有可能有丰富多彩的能级呢？如果有，那为什么我们平常没有观测到呢？这便是下面将要回答的问题。 一.深藏不露的原子核具体介绍原子核的内部结构之前，我们先要回答的问题是：为什么我们平时看到的、了解到的原子核现象这么少？我想给出的原因主要有两个： 一是能级太高。为了让读者对这一问题能有直观理解，我们先从主导化学反应的核外电子讲起。 对氢原子的核外电子，其实我们可以解出其波函数，并进一步给出核外电子的能级： E_n=-\\frac{\\mu e_s^4}{2\\hbar}\\frac{1}{n^2}=-13.6\\ \\mathrm{eV}\\cdot\\frac{1}{n^2},n=1,2,3,...这告诉我们，氢原子核外电子的基态能量（最低能量，即$n=1$时）是： \\begin{align*} -13.6eV&=-13.6\\cdot (1.6\\times 10^{-19}C)\\cdot \\mathrm{V}\\\\ &=-2.176\\times 10^{-18}\\mathrm{J}\\\\ &=-1310\\ \\mathrm{kJ/mol} \\end{align*}这个结果的物理意义是，对于$1\\mathrm{mol}$的氢原子，要将其核外电子全部电离，需要$1310kJ$的能量。这是一个什么概念呢？ 如果用热力学的方法进行换算，这么多能量差不多相当于物体处于一万度以上时，每个原子才能具有的内能！与之相比，主导物态变化的范德华力（分子间作用力）往往只有$10\\ \\mathrm{kJ/mol}$每量级，差不多相当于物体在一百度上下时每个分子具有的内能；这也是为什么我们能在日常生活中看到腾云覆雨、物态变化的原因。 对于化合键中的极强者，如氢-氧键，其键能只有$464\\ \\mathrm{kJ/mol}$，即分解一摩尔氢氧键需要$464\\ kJ$能量。这导致由氢氧键结合的水分子极其稳定，即使在$1000$度以上的高温也很少分解。因此，一般来说，化学反应比物态变化要发生得少得多、慢得多，因为需要更高的能量。 原子核的能级一般在什么量级呢？答案是：对于稳定的核素，$\\sim10\\mathrm{MeV}$.其中，M表示”百万“，即一千万$eV$,比氢原子的能级还要高出一百万 倍！这意味着原子核需要极极极高的能量才能发生反应，条件极其苛刻，因此很少被看到。只有非常不稳定的原子核，例如放射性重核，才能在自发地裂变；又或者是非常极端的高温下，如温度高达几百亿度的太阳中心，原子核真的有那么多内能来提供核反应，于是才发生了核聚变反应。 作用力 能量 等价于多少温度时物体具有的能量？ 主导的作用 范德华力 $\\sim10\\mathrm{kJ/mol}$ $\\sim 100^\\circ \\mathrm{C}$ 物态变化（蒸发，凝结等） 化合键 $100\\sim500\\mathrm{kJ/mol}$ $\\sim1000^\\circ \\mathrm{C}$ 化学反应 电子能级 $\\sim10\\mathrm{eV}, \\sim1000\\mathrm{kJ/mol}$ $\\sim10000^\\circ \\mathrm{C}$ 原子电离，极其高能的化学反应 核能级 $&gt;50\\mathrm{MeV}$ $\\sim10000000^\\circ \\mathrm{C}$ 核反应，例如太阳核心的轻核聚变 二是太难计算。曾有人调侃物理学家： 他们知道关于一、二和无穷多的一切，在二和无穷之间，他们便一无所知了。 这句话的意思是，物理学家能精确求解一个或两个物体的运动状态，对于无穷多个物体倒也能通过平均的方法处理；但是对于物体数量大于二，却又不是充分大（从而平均处理时误差会比较大）的多体系统（例如，三体问题），他们便完全没有办法精确处理了。 原子物理中亦是如此。对于简单（质子和电子组成的两体系统）的氢原子，在忽略了电子自旋和亿些其它因素之后，物理学家还是设法求出了其波函数，其表达式看上去已经非常疯狂了： \\begin{align*} \\psi_{nlm}(r,\\theta,\\varphi)&=R_{nl}(r)Y_{lm}(\\theta,\\varphi)\\\\ &=\\sqrt{\\left(\\frac{2}{na_B}\\right)^3\\frac{(n-l-1)!}{2n(n+l)!}}e^{-\\frac{r}{na_B}}L^{2l+1}_{n-l-1}\\left(\\frac{2r}{na_B}\\right)\\cdot\\sqrt{\\frac{(l-|m|)!}{(l+|m|)!}\\frac{2l+1}{4\\pi}}P_l^{|m|}(\\cos\\theta)e^{im\\varphi} \\end{align*}其中的$L,P$代表两个稀奇古怪的多项式（“拉盖尔多项式”和“连带勒让德多项式”）。而将上式画图，我们就能得到我们高中时熟悉的电子云图： 氢原子电子云 好吧，我承认我写出这个式子多少有点吓唬人的想法，但我的目的确实如此，即，让读者认识到求解量子力学问题是一件非常困难的事情。 不幸的是，原子核比氢原子复杂得多。原子核往往由一大团质子和中子组成，通过强相互作用黏合在一起——这是一种比粘合氢原子的库仑力还要复杂得多的相互作用。这个体系求不出精确解，而且，由于核子数量众多，即使是在计算机如此发达的今天，许多时候数值解也非常难求。几十年来，提出了各种近似模型来试图解决这一问题；事实上，在物理学院专门有一门课《量子多体》，就是教授处理类似问题的方法的。 没有简洁清晰的结果，就意味着难以形成公认的规范、也难以向大众进行科普——例如，没有被写进中学的教科书。我想，这则是原子核的结构很少被大众了解的另一个重要原因。 二.原子核结构初探到了这里，我们终于开始正式介绍核模型了。前面说过，物理学家只会处理$N=1,2,+\\infty$的系统。于是，面对原子核这样一个复杂的多体系统，物理学家们便开始疯狂的近似，直到他们能处理为止。 其中最疯狂的近似，无疑是气体模型，即忽略核子（中子和质子）间所有的相互作用，把原子核中的质子和中子看成是一团软绵绵的气体，在球状的原子核“容器”中运动。离谱的是，在进行了如此夸张的简化之后，这一模型竟还是能解释一些现象。 具体来说，气体模型认为每个核子受其余核子形成的总势场作用，每个核子都处在这一势阱之中。外围高高的势阱就好像无法跨越的高墙，将核子围在了里面，从而起到了“容器”的作用。势阱之内，核子则能自由运动。气体模型成功之处，在于它可以证明质子数和中子数相等的核最稳定——这与事实是基本相符的。此外，用气体模型计算出的核势阱深度约为$-50\\mathrm{MeV}$（还记得之前提到的核能级量级吗？），与实验结果接近。不过近似总是有代价的，这一模型过于简单，难以解释后来发现的许多新事实。 如果考虑强相互作用，进行一系列简化，则可以得到一个稍好一些的模型——液滴模型。实验发现，原子核的体积正比于核子数，就好像核子有固定的体积、不可压缩一样（这是液体的典型性质）。另一方面，由于强相互作用力力程很短，核子的大小又差不多，于是便出现了这样的怪事：核子们挤在一起、一个个紧挨着；而每个核子几乎只能受到围绕在周围一圈的核子的相互作用，源头更远的强相互作用因为衰减太快而变得很弱。这样一来，核子之间的强相互作用就好像液体中分子间的范德华力，只和周围的单位有相互作用。将核子比作液体进行处理，这种模型叫液滴模型。 液滴模型示意图 虽然比气体模型进了一步，但液滴模型仍然眉毛胡子一把抓，把所有核子同等对待。有没有更精细（delicate）一些的模型呢？答案是肯定的。 科学家们发现，当质子数Z和中子数 N 分别等于下列数（称作幻数）：2、8、20、28、50、82、126 之一时，原子核特别稳定。这与核外电子的行为模式有些相似，即电子满壳层时特别稳定。这不禁让人联想：原子核中的核子是否也和核外电子一样，具有壳层结构呢？某个核子壳被填满时，核便特别稳定。 于是就真有物理学家这么做了。M. G. Mayer和J. H. D. Jensen在1949年提出了壳层模型(shell model)。在经过了复杂的计算，并考虑了一些奇怪的相对论量子效应（准确来说，自旋-轨道耦合）之后，物理学家们给出了每一个核子所能处在的态及其对应的能级： 壳层模型能级 其中，每一条横线对应一个核子可以处在的态，从下到上能量依次增高，类似电子轨道。可以看到，在前2、8、20、50、82、126、184态和它们的上一个态之间，有一个很大的能级差，我称之为能级裂谷。处在裂谷下岸的核子难以跨过裂谷跃迁到高能级。满壳层的核（又称”幻核“），核子刚好挤满了某个裂谷的下岸，难以向上跃迁，显得稳定。另一方面，处在能级裂谷之上的原子核能量很高，容易发生反应跌落到低能级上。这样一来一去，就给出了幻核特别稳定的结果，成功解释了现象。 换一个角度来看，裂谷之间考得较紧的能级组，构成了核的每一个”壳层“，当壳层被填满时核便特别稳定，这也是”壳层模型“这一名称的由来原因之一。事实上，填充在某个壳层的核子，真的表现得像球壳一样：它们在核中近似地占据一层球壳空间，壳层填满时原子核接近球形，而壳层只填了一半时则会让球壳一边厚一边薄，使得原子核变成一头重一头轻的椭球形。 研究人员计算的重核中的核子密度分布。左侧是中子密度，右侧是质子密度。单位是费米($\\mathrm{fm}$)，$1\\mathrm{fm}=10^{-15}\\mathrm{m}$. 到了这里，我想大家可能发现，在这么多模型中，大家都叫”XX模型“，而不是”XX理论“。一般来说，”理论“是指精确而成熟的物理理论，要求从原理出发导出结果，可以给出细致的物理图像。例如”玻尔的氢原子理论“，可以精确地给出核外电子的轨道半径。而”模型“则是指通过数学进行建模、抽象、演绎，然后唯象而近似地对客体进行描述。很不幸，原子核的复杂程度令物理学家们无法直接攻破，只好用各种方式近似，并给出一个”还算令人满意“的模型，也就是前述的气体模型、液滴模型和壳层模型。 不幸的是，即使是复杂的壳层模型也有不尽如人意的地方，用物理学家的话来说，就是： 对电四极矩的预计与实验值相差甚大，对核能级之间的跃迁速率的计算也大大低于实验值. 唔…这些晦涩的术语我不打算解释了，最后的结局是物理学家们提出了新的“集体运动”模型。将壳层模型和集体模型综合起来，你就得到了现代物理理解原子核最成功的模型，可以很好地解释大部分现象。 壳层模型认为，每个核子填充一个能级，核子之间没什么相互作用——就好像一座高楼中的单人住户一样，自己管自己。但事实上，原子核是一个整体，就如同一个几十个人组成的班级一样，核子之间有着相互作用，是一个整体。考虑这种相互作用给原子核带来的整体形变（转动、振动等），就得到了集体运动模型。集体模型中，最外层壳层只填满了一半的核会因为核子相互作用而偏离球形、变成椭球形；而一旦变成了椭球形，核整体就有了电四极矩，而且可以转动；而转动就会带来不同的转动能级（这是一个量子力学效应）。对于靠近满壳层的球形核来说，则可能发生表面的上下浮动，产生振动能级（也是一个量子力学效应）。这给核的带来了更丰富的能级，能解释更多的现象，同时也让它更复杂了。 球形核的表面振动 你也许会问，既然最外层的核子会对内部的核子壳层有影响从而改变壳层形状，那么，我们高中学过的核外电子体系有没有类似的效应呢？答案是有的，这种理论叫价层电子对互斥理论(VSPER)，描述了最外层的电子如何改变电子云的形状——可以很好的解释一些分子的电子云取向和分子构型，在化学竞赛中有重要的应用，嗯…高中课内不讲也许是因为太难了。 到了这里，我对原子核结构的介绍就结束了。很惊讶，是不是？本以为一团浆糊一样的原子核，竟然也有如此丰富而复杂的结构，其能级结构比核外电子复杂得多。很可惜，原子核，不像核外电子一样能给出一个清晰简洁的结构，因为原子核实在是太复杂了。而且由于原子核的能级总是很高($\\sim\\mathrm{MeV}$)，现实生活中也很少看到核反应。 即使面对这样的复杂性，科学家们也没有放弃。一代又一代的物理学家们前赴后继，不断地完善模型。气体模型，液滴模型，壳层模型…一个个理论在成功与失败之间螺旋上升、徐徐前行，才有了今天人类对原子核的理解。","link":"/2021/06/12/%E5%8E%9F%E5%AD%90%E6%A0%B8%E6%9C%89%E7%BB%93%E6%9E%84%E5%90%97%EF%BC%9F/"},{"title":"用线性规划解决《戴森球计划》中的生产规划问题","text":"李辰剑 2023-6-16 定稿 一、问题引入《戴森球计划》相信大家都很熟悉啦，它是一款科幻主题的模拟经营游戏。在《戴森球计划》中，玩家需要在宇宙中采集材料、解锁科技、进行工业生产，最终建造出一个包裹恒星的戴森球，通过戴森球大量收割恒星的太阳能。然而，《戴森球计划》中科技产品的生产和建造极其复杂（配方很复杂，供应链更复杂）；而建造整个戴森球（包裹整个恒星，物资消耗能不大吗）又需要大量物资，对生产的规模和效率提出了很高的要求。因此，玩家常常需要花费大量时间来设计、建造、调整各种科技产品的生产线，非常痛苦。这也是《戴森球计划》被许多玩家诟病“费肝”的原因。 于是我就想，能否用计算机科学中一些成熟的优化算法来帮忙设计生产线呢？我初步筛选出了三个可以用计算机算法优化的任务： (1) 用线性规划求解最优的资源、产品分配。《戴森球计划》中的产业链很长，一些产品的生产配方较为复杂，需要经过多道生产步骤。例如，以下是低阶科技产品电动马达的生产线路图： 如何合理分配资源（例如，以合适的比例将铁矿分配到铁块和磁铁的生产中）以最大化目标产出（例如，最大化马达的生产速率）是一个麻烦的问题。但这一步骤恰好可以用线性规划（Linear Programming）模型求解。 (2) 用集成芯片设计算法优化工厂和物流的布局布线。 《戴森球计划》中的工厂输入输出和布局可以非常复杂… 其实这和集成芯片物理设计中的元件布局和布线有许多相似之处。 (3) 用非线性模型优化工厂位置和物流。这个我懂，区位条件嘛！哪颗星球铁矿多、就着重生产钢铁、马达；哪颗星球石油多，就着重搞能源工业和石油化工。如果有市场经济，每个工厂的厂长就会自己搬去离原料最近的工厂，从而最小化物流开销。——可惜《戴森球计划》中的所有生产都由玩家一人负责，因此需要玩家自己优化所有工厂的位置，相当繁琐。如果能写出一个目标函数，以工厂选址为输入变量变量、以物流成本为函数值、再对该函数进行最优化，就可以得到最优的工厂选址，从而将玩家从繁琐的工厂规划中解放出来。 虽然三个想法都很诱人，但是布局布线和非线性优化都过于复杂…… 于是我决定先尝试基于线性规划的想法(1)。也许以后可以试试另两个想法 :-) 《戴森球计划》游戏内截图。上：《戴森球计划》中的生产线；下：正在建造中的戴森球。 二、问题建模1. 《戴森球计划》中的产品分配问题《戴森球计划》中的产业链很长，一些产品的生产需要经过多道生产步骤。例如，以下是低阶科技产品电动马达的生产线路图： 在生产马达时，给定铁矿和铜矿生产速度，玩家会面临这样一个问题：如何确定铁块和磁铁的生产比例？如果铁块生产过多、磁线圈就会生产不足，导致铁块积压；相反，如果铁块生产过少、磁铁生产过多，就会导致磁线圈积压。因此，只有合理地分配原料和中间产品，才能达到目标产品的最大产量。合理分配单一资源并非难事。但在《戴森球计划》的实际生产中，往往需要同时平衡十几种原料和产品的供应链，完美平衡所有产物并非易事。 在实际搭建高阶科技产品生产线的时候，常常由于原料生产力不匹配遇到顾此失彼的情况。由于生产线不均衡、无法完美匹配原料生产，从而导致某种材料堆积或缺乏，这会使某一步生产成为瓶颈，无法充分利用星球上的资源禀赋快速生产高级产品。但由于生产链很复杂，手工优化调整很繁琐。 《戴森球计划》中高阶科技产品「能量矩阵」和「结构矩阵」的生产过程。从原材料到成品，构成了一个复杂的有向无环图 (DAG) 结构。图片来自 https://steamah.com/dyson-sphere-program-matrix-production-guide/。 考虑到《戴森球计划》中的生产配方都是「线性的」，即，一份原料一份收获，我们可以将原料分配问题建模为线性规划问题。一旦将问题建模为线性规划问题，就可以调用成熟的线性规划求解器自动求解，从而将玩家从繁琐的手动优化中解放出来。 2. 假设与变量《戴森球计划》中的自动化生产是一个非常复杂的问题。除了原料之外，还要考虑物流、工厂占地、生产速率等等问题。为了将问题规约为简单的线性规划模型，我们做一些简化： 假设星球上的资源总量无限，但每分钟采集的资源数量（即资源采集速率）受到矿脉数量限制。 假设星球上总是有足够的地方修建工厂。 假设有充足的能源供应（依靠正在建造的戴森球）和便捷的物流系统（不用考虑物流运输问题）。 在这些假设下，能源、工厂占地、物流都不成为问题，资源采集速率是对生产的唯一约束。 因此，这一模型求解得到的结果不提供工厂和物流的布局方案，只提供原料和各个工业品的分配方案QAQ 接下来，我们将『每种工业品的每分钟生产量』（即生产速率）建模为线性规划中的变量。例如，铁矿，铁块，齿轮的每分钟生产数量分别对应线性规划中的 $\\#铁矿$,$\\#铁块$,$\\# 齿轮$ 变量。其中，「$\\#$」表示「数量」之意。 以钢铁生产线为例。在《戴森球计划》中，一单位铁矿可以冶炼出一单位铁块，一单位铁块又可以生产一单位齿轮。假设每分钟最多采集 2500 单位铁矿，就可以得到如下约束： \\# 铁矿,\\# 铁块,\\# 齿轮\\ge0\\\\ \\# 铁矿\\le2500\\\\ \\# 铁块\\le\\# 铁矿\\\\ \\# 齿轮\\le\\# 铁块\\notag3. 将原料生产模型转化为线性规划问题假设 $原料_i$ 供应了产品 $产品_1,产品_2,…,产品_{m_i}$的生产，其中生产每份 $产品_j$ 需要 $a_{ji}$ 份 $原料_i$。那线性规划模型中的约束可以写为： \\sum_{j=1}^{m_i}a_{ji}\\cdot\\# 产品_j\\le\\#原料_i\\tag*{[Constraint $i$]}若一种产品的生产配方同时需要多种原料，则需要同时出现在多个原料的约束式里。例如，如果考虑电动马达生产线、忽略其它产品，可以得到以下的模型： \\begin{align*} \\max_{\\# \\mathrm{prod.}\\ge0}\\ & \\# 电动马达\\\\ \\color{teal}{\\# 铁矿}\\ &\\le2500\\\\ \\color{brown}{\\# 铜矿}\\ &\\le2000\\\\ \\# 磁铁+\\color{teal}{\\# 铁块}\\ &\\le \\color{teal}{\\# 铁矿}\\\\ \\color{brown}{\\# 铜块}\\ &\\le \\color{brown}{\\# 铜矿}\\\\[2mm] 2\\cdot\\# 电动马达+\\#齿轮\\ &\\le \\color{teal}{\\#铁块}\\\\ 0.5\\cdot\\# 磁线圈\\ &\\le \\color{brown}{\\#铜块}\\\\ \\# 电动马达&\\le \\#齿轮\\\\ \\# 电动马达&\\le \\#磁线圈 \\end{align*}\\notag在《戴森球计划》中，大多数物品都由单一配方生产，但少部分物品有多种生产渠道，我们需要为此调整生成的公式。例如，游戏中的石墨烯既可以由可燃冰得到，也可以由化工工艺生产。于是，需要将产品分为两部分写入模型，再用一个式子加起来。例如，对石墨烯可以得到下式（下式中省略了系数和一些原料）： ...\\\\ \\begin{align*} \\# 石墨烯^{(可燃冰)}&\\le \\#可燃冰\\\\ \\# 石墨烯^{(化工)}&\\le \\# 化工原料\\\\ \\# 石墨烯&=\\# 石墨烯^{(可燃冰)}+\\# 石墨烯^{(化工)}\\\\ ...(需要石墨烯的产品)...&\\le\\# 石墨烯\\\\ \\end{align*}\\\\ ...三、求解器选择，以及代码实现线性规划是一个非常成熟的数学模型，市面上有许多求解器可供选择。例如，大名鼎鼎的 MATLAB 便提供了线性规划求解函数。然而，最终我选择了 MiniZinc。MiniZinc 是一款通用的求解器，它可以求解的问题范畴比线性规划大得多。更重要的是，MiniZinc 有自己的约束表示语言，可以通过类似高级语言的方式指定复杂的约束。相比之下，MATLAB 只支持求解矩阵输入形式的线性规划。将复杂的生产配方转换为矩阵形式是一件非常麻烦的事，因此我最终选择了 MiniZinc。 MiniZinc 的核心是一个命令行工具，负责求解由 .mzn 后缀文件指定的约束问题。不过除了命令行交互， MiniZinc 官方还提供了具有图形界面的 IDE 来编辑和运行代码，这也是我采用的交互方式。 12# 在命令行使用 MiniZinc 求解器$ minizinc --solver gecode problem.mzn MiniZinc IDE 截图 Remark 严格来说 MiniZinc 是一款约束描述语言，真正求解时可以选择不同的求解器。 求解过程中出现了奇怪的现象：若将模型设置为整数线性规划问题，大多数求解器都可以求解；但如果将数据类型设为实数、将模型设置为实数线性规划模型，一些求解器反而无法求解。按理说，实数规划比整数规划更简单才对。 最后，完整的代码如下。其中，矿物资源的生产速度取自我的存档，使用时请修改为自己的存档数据；有一些极少使用的配方没有包含在内。求解结果见第四部分。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196% % DSP.mzn % %% % 变量定义 % %% 原矿var int: iron_ore; constraint iron_ore &gt;= 0;var int: copper_ore; constraint copper_ore &gt;= 0;var int: coal_ore; constraint coal_ore &gt;= 0;% 初级产品var int: iron; constraint iron &gt;= 0;var int: magnet; constraint magnet &gt;= 0;var int: copper; constraint copper &gt;= 0;var int: coal; constraint coal &gt;= 0;% 次级产品var int: magnet_coil; constraint magnet_coil &gt;= 0;var int: gear; constraint gear &gt;= 0;% 电磁产品生产线var int: EM_turbine; constraint EM_turbine &gt;= 0;var int: motor; constraint motor &gt;= 0;% 电路板var int: PCB; constraint PCB &gt;=0; var int: IC; constraint IC &gt;= 0; % 当前资源禀赋下（硅矿=2250），IC最多每分钟生产250左右var int: micro_unit; constraint micro_unit &gt;= 0; % 硅产线var int: silicon_ore; constraint silicon_ore &gt;= 0;var int: silicon; constraint silicon &gt;= 0;var int: lattice_silicon; constraint lattice_silicon &gt;= 0;% 光学产线var int: raw_stone; constraint raw_stone &gt;= 0;var int: glass; constraint glass &gt;= 0;var int: prism; constraint prism &gt;= 0;var int: plasma_generator; constraint plasma_generator &gt;= 0;var int: photon_merger; constraint photon_merger &gt;= 0;% 结构产线var int: titanium_ore; constraint titanium_ore &gt;= 0;var int: titanium; constraint titanium &gt;= 0;var int: titan_alloy; constraint titan_alloy &gt;= 0;var int: titan_glass; constraint titan_glass &gt;= 0;var int: titan_diamond; constraint titan_diamond &gt;= 0;var int: diamond; constraint diamond &gt;= 0;var int: graphene; constraint graphene &gt;= 0;var int: graphene_tube; constraint graphene_tube &gt;= 0;var int: steel; constraint steel &gt;= 0;% 能源var int: HE_graphite; constraint HE_graphite &gt;= 0;var int: mined_HE_graphite; constraint mined_HE_graphite &gt;= 0;var int: splitted_HE_graphite; constraint splitted_HE_graphite &gt;= 0;HE_graphite = splitted_HE_graphite + mined_HE_graphite;% HE = High Energy, HE_graphite：高能石墨var int: crude_oil; constraint crude_oil &gt;= 0;var int: gasoline; constraint gasoline &gt;= 0;var int: combustible_ice; constraint combustible_ice &gt;= 0;var int: hydrogen; constraint hydrogen &gt;= 0;% 从气态巨行星提取的氢var int: extracted_hydrogen; constraint extracted_hydrogen &gt;= 0;% 裂解得到的氢var int: splitted_hydrogen; constraint splitted_hydrogen &gt;= 0;% 原油分馏得到的氢var int: fractioned_hydrogen; constraint fractioned_hydrogen &gt;= 0;constraint hydrogen = extracted_hydrogen + fractioned_hydrogen + splitted_hydrogen;var int: deuterium; constraint deuterium &gt;= 0;var int: deuterium_unit; constraint deuterium_unit &gt;= 0;% 化工var int: sulfuric_acid; constraint sulfuric_acid &gt;= 0;var int: organic_crystal; constraint organic_crystal &gt;= 0;var int: plastic; constraint plastic &gt;= 0;% quantum/advancedvar int: super_magnet_coil; constraint super_magnet_coil &gt;= 0; % 当前资源，极限=85/分钟var int: QIC; constraint QIC &gt;= 0;var int: particle_broadband; constraint particle_broadband &gt;= 0;var int: Casmir_crystal; constraint Casmir_crystal &gt;= 0;var int: subspace_selector; constraint subspace_selector &gt;= 0;% subspace_selector: 位面过滤器% DSP componentvar int: solar_sail; constraint solar_sail &gt;= 0;var int: DSP_unit; constraint DSP_unit &gt;= 0;% rocketvar int: framework_mat; constraint framework_mat &gt;= 0;var int: rocket; constraint rocket &gt;= 0;% 科技矩阵var int: EM_matrix; constraint EM_matrix &gt;= 0;var int: structure_matrix; constraint structure_matrix &gt;= 0;var int: energy_matrix; constraint energy_matrix &gt;= 0;var int: information_matrix; constraint information_matrix &gt;= 0;var int: gravity_matrix; constraint gravity_matrix &gt;= 0;var int: universe_matrix; constraint universe_matrix &gt;= 0;var int: gravity_len; constraint gravity_len &gt;= 0;var int: particle_container; constraint particle_container &gt;= 0;var int: strange_matter; constraint strange_matter &gt;= 0;% % 原料生产速度 % %% 请根据存档资源分布调整数值 %constraint iron_ore &lt;= 2500;constraint copper_ore &lt;= 2000;constraint coal_ore &lt;= 1300;constraint raw_stone &lt;= 3000;constraint silicon_ore &lt;= 2250;constraint titanium_ore &lt;= 2500;constraint combustible_ice &lt;= 192.04*45;constraint extracted_hydrogen &lt;= 87.1*45; %~3920constraint crude_oil &lt;= 29.28*60; %~1780;% % 生产公式约束 % %% 初级产品constraint iron + magnet &lt;= iron_ore;constraint copper &lt;= copper_ore;constraint 2*silicon &lt;= silicon_ore;constraint 2*titanium &lt;= titanium_ore;constraint 2*mined_HE_graphite &lt;= coal_ore;constraint 2*glass + 2*sulfuric_acid &lt;= raw_stone;constraint 2*splitted_hydrogen &lt;= crude_oil;constraint gasoline = 2*splitted_hydrogen;constraint 2*extracted_hydrogen &lt;= combustible_ice;constraint graphene = 2*extracted_hydrogen;% 第一行（生产面板中的第一行产品，下同）constraint gear + 3*steel + 2*motor + 2*PCB + 2*strange_matter &lt;= iron;constraint magnet_coil + micro_unit + PCB &lt;= copper;constraint lattice_silicon + 2*micro_unit + framework_mat &lt;= silicon;constraint 2*titan_alloy + 2*titan_glass + 6*titan_diamond + graphene_tube &lt;= 2*titanium;constraint plastic + diamond + super_magnet_coil + 2*energy_matrix &lt;= HE_graphite;constraint 2*splitted_HE_graphite + 4*plastic + 2*organic_crystal + 3*sulfuric_acid &lt;= 2*gasoline;constraint 3*graphene_tube + 4*Casmir_crystal + solar_sail &lt;= 2*graphene;constraint 2*organic_crystal + particle_broadband &lt;= plastic;% 第二行constraint 2*magnet_coil + super_magnet_coil &lt;= magnet;constraint motor + 2*EM_turbine + EM_matrix + 4*plasma_generator &lt;= magnet_coil;constraint 2*particle_broadband &lt;= lattice_silicon;constraint deuterium_unit + 2*framework_mat &lt;= 2*titan_alloy;constraint 2*titan_glass + 3*prism &lt;= 2*glass;constraint 4*gravity_len + structure_matrix &lt;= diamond;constraint splitted_hydrogen = 3*splitted_HE_graphite; % 裂解公式constraint organic_crystal &lt;= organic_crystal;constraint 2*splitted_HE_graphite + 2*deuterium + 12*Casmir_crystal + 2*energy_matrix &lt;= hydrogen;constraint 20*deuterium_unit + 10*strange_matter &lt;= deuterium;constraint 4*rocket &lt;= deuterium_unit;% 第三行constraint titan_alloy &lt;= steel;constraint 2*EM_turbine &lt;= motor;constraint 2*subspace_selector &lt;= titan_glass;constraint 2*plasma_generator + 2*photon_merger &lt;= prism;constraint Casmir_crystal + structure_matrix &lt;= titan_diamond;constraint gravity_len &lt;= strange_matter;% 第四行constraint motor &lt;= gear;constraint 2*super_magnet_coil &lt;= EM_turbine;constraint 2*IC + EM_matrix + photon_merger &lt;= PCB;constraint gravity_matrix &lt;= gravity_len;constraint 2*titan_alloy &lt;= sulfuric_acid;constraint 2*particle_broadband + 4*framework_mat &lt;= graphene_tube;% 第五行constraint 0 &lt;= plasma_generator;constraint deuterium_unit &lt;= 2*super_magnet_coil;constraint information_matrix &lt;= particle_broadband;constraint 3*DSP_unit + 2*QIC + 2*information_matrix &lt;= IC;constraint subspace_selector &lt;= Casmir_crystal;constraint 2*strange_matter &lt;= particle_container;constraint 2*QIC &lt;= subspace_selector;constraint 3*DSP_unit &lt;= solar_sail;constraint 3*DSP_unit &lt;= framework_mat;constraint 2*rocket &lt;= DSP_unit;% 第六行constraint solar_sail &lt;= 2*photon_merger;constraint 2*IC &lt;= micro_unit;constraint 2*rocket + gravity_matrix &lt;= QIC;% 第七行constraint universe_matrix &lt;= EM_matrix; % 电磁矩阵瓶颈：铁矿 #=625constraint universe_matrix &lt;= energy_matrix; % 瓶颈：煤矿 #=379constraint universe_matrix &lt;= structure_matrix; % 瓶颈：钛矿 #=416constraint universe_matrix &lt;= information_matrix; % 瓶颈：硅矿 #=112constraint universe_matrix &lt;= gravity_matrix; % 瓶颈：氢和钛矿 #=125%宇宙矩阵还缺一个反物质约束% universe_matrix #=62% % 目标 % %%constraint EM_turbine &gt;= 100;%constraint IC &gt;= 100;%solve maximize EM_matrix;%solve maximize energy_matrix;%solve maximize structure_matrix;%solve maximize information_matrix;%solve maximize gravity_matrix;%solve maximize universe_matrix;solve maximize rocket; 四、求解结果与分析在这一节中，我将以一些终端科技产品为目标，运行优化器，得到有限资源条件下的最优解。有了线性规划求解器的帮助，我们就可以从纷繁复杂的生产线中找到关键的限速路径，并进一步分析其生产瓶颈。 在《戴森球计划》计划中，除去建筑，生产复杂、需求量大的终端科技产品有七种： 电磁矩阵（蓝色矩阵）：需要磁线圈和电磁涡轮生产，象征着电磁学科技。可以看作电磁科技和电磁产品生产力的抽象。 能量矩阵（红色矩阵）：需要高能石墨和氢元素生产，象征着能源工业。可以看作能源的抽象。 结构矩阵（黄色矩阵）：需要金刚石和钛晶石生产，象征着高强度材料科技。可以看作高阶材料科技和高强度材料产能的抽象。 信息矩阵（紫色矩阵）：需要集成芯片（游戏中的“处理器”）和粒子宽带生产，象征着成熟的信息科技。可以看作信息科技和信息产品产能的抽象。 引力矩阵（绿色矩阵）：需要量子芯片和引力透镜进行生产，象征着量子力学和广义相对论的统一（这两个理论之间有矛盾，现实世界中还没做到相互统一），代表了最高阶的科技和最先进的科技产品。 宇宙矩阵（白色矩阵）：一份宇宙矩阵由一份电磁矩阵、一份能量矩阵、一份结构矩阵、一份信息矩阵、一份引力矩阵生产，是消耗资源最多、最综合的产品。象征着最前沿且全面的科技水平。 小型运载火箭：需要戴森球组件、量子芯片和氘核燃料棒生产。小型运载火箭负责将戴森球组件运送到恒星附近并组装，是戴森球的前体。在建造戴森球的过程中，大规模、稳定地量产运载火箭是必不可少的。然而，小型运载火箭的产业链非常长，生产难度高，需求量也非常大，因此设计火箭生产线绝非易事。 接下来，我们分别以前述的七种产品产量为目标，进行最优化，然后对结果进行分析。 六种矩阵的生产步骤和每一步的配方。 图片来自https://imgur.com/。 1. 电磁矩阵在 DSP.mzn 中将最优化目标设为 solve maximize EM_matrix;（即最大化电磁矩阵产量），然后调用求解器，得到以下结果： 为便于观察理解，求解器结果经过了筛选和重排，下同 123456789iron_ore = 2500; % 达到矿物生产速度上限（上限=2500）copper_ore = 1250; % 未达到矿物生产速度上限（上限=2000）iron = 1250;magnet = 1250;copper = 1250;PCB = 625;EM_matrix = 625;...(值为0的变量已忽略)... 线性规划的求解结果给出了电磁矩阵的最大生产速率（最后一行），以及产率最大化时对其它产品的需求（前六行）。在不同玩家的不同存档中，资源条件常常存在差异；而在同一存档中，前期和后期的资源开发利用程度也会有所不同。因此，电磁矩阵最大生产速率的绝对值意义不大；相比之下，更加重要的是分析产品的相对生产比例以及整体的生产规律和特点。 可以看到，电磁矩阵的生产强烈依赖于铁矿和铜矿以及随后的铜铁产业。最后一行告诉我们，（在我的存档条件下，下同）电磁矩阵的最大生产速率为每分钟 625 单位。结合矿物资源上限可以发现，限制电磁矩阵生产的资源是铁矿，铜矿并没有被完全利用起来。 2. 能量矩阵在 DSP.mzn 中将最优化目标设为 solve maximize energy_matrix;，然后调用求解器，得到以下结果： 1234567891011121314coal_ore = 1300; % 达到矿物生产速度上限（上限=1780）mined_HE_graphite = 650;splitted_HE_graphite = 292;HE_graphite = 942;crude_oil = 1752; % 基本达到矿物生产速度上限（上限=1780）gasoline = 1752;combustible_ice = 0;hydrogen = 1526;extracted_hydrogen = 0; % 未开采巨型气态行星，氢元素生产仍有潜力splitted_hydrogen = 876;fractioned_hydrogen = 650;energy_matrix = 471;...(一些值为0的变量已忽略)... 可以看到，能量矩阵的生产强烈依赖于原油生产和煤矿采掘，这很符合大众对能源工业的印象 :-) 能量矩阵的最大生产速率为每分钟 471 单位，低于电磁矩阵，说明能量矩阵的生产难度更高；从数据可以看出，限制能量矩阵生产的关键资源是煤矿。 3. 结构矩阵在 DSP.mzn 中将最优化目标设为 solve maximize structure_matrix;，然后调用求解器，得到以下结果： 1234567891011121314coal_ore = 832; % 未达到矿物生产速度上限（上限=1300）titanium_ore = 2496; % 达到矿物生产速度上限（上限=2500）titanium = 1248;titan_alloy = 0;titan_glass = 0;titan_diamond = 416;diamond = 416;steel = 0;mined_HE_graphite = 416;splitted_HE_graphite = 0;HE_graphite = 416;structure_matrix = 416;...(一些值为0的变量已忽略)... 可以看到，结构矩阵的生产主要依赖于钛材料和金刚石。能量矩阵的最大生产速率为每分钟 416 单位，生产难度与能量矩阵基本持平；从数据可以看出，限制结构矩阵生产的关键资源是钛矿——这非常符合大众对钛“高强度材料元素”印象。 4. 信息矩阵在 DSP.mzn 中将最优化目标设为 solve maximize information_matrix;，然后调用求解器，得到以下结果： 123456789101112131415161718192021222324252627282930iron_ore = 896; % 未达到矿物生产速度上限（上限=2500）copper_ore = 896; % 未达到矿物生产速度上限（上限=2200）coal_ore = 134; % 远未达到矿物生产速度上限（上限=1300）iron = 896;copper = 896;PCB = 448;IC = 224;micro_unit = 448;silicon_ore = 2240; % 达到矿物生产速度上限（上限=2250）silicon = 1120;lattice_silicon = 224;titanium_ore = 224;titanium = 112;graphene = 336;graphene_tube = 224;mined_HE_graphite = 67;splitted_HE_graphite = 45;HE_graphite = 112;crude_oil = 270; % 远未达到矿物生产速度上限（上限=1780）gasoline = 270;combustible_ice = 336; % 远未达到矿物生产速度上限（上限=1300）hydrogen = 303;extracted_hydrogen = 168;splitted_hydrogen = 135;fractioned_hydrogen = 0;plastic = 112;particle_broadband = 112;information_matrix = 112;...(一些值为0的变量已忽略)... 可以看到，信息矩阵的生产比前几种矩阵要困难得多，每分钟最多只能生产 112 单位；而且产业链更复杂，涉及到能源、钛和铁。不过，在所有消耗的资源中，硅的消耗量最大，硅元素产量也直接成为了信息矩阵的生产瓶颈——这非常符合大众对硅元素“信息时代关键原料”的印象。 5. 引力矩阵在 DSP.mzn 中将最优化目标设为 solve maximize gravity_matrix;，然后调用求解器，得到以下结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647iron_ore = 1250; % 未达到矿物生产速度上限（上限=2500）copper_ore = 1000; % 未达到矿物生产速度上限（上限=2000）coal_ore = 1000; % 达到矿物生产速度上限（上限=1300）iron = 1250;magnet = 0;copper = 1000;coal = 0;magnet_coil = 0;gear = 0;EM_turbine = 0;motor = 0;PCB = 500;IC = 250;micro_unit = 500;silicon_ore = 2000; % 未达到矿物生产速度上限（上限=2250）silicon = 1000;lattice_silicon = 0;raw_stone = 1000; % 未达到矿物生产速度上限（上限=3000）glass = 500;prism = 0;plasma_generator = 0;photon_merger = 0;titanium_ore = 2500; % 达到矿物生产速度上限（上限=2500）titanium = 1250;titan_alloy = 0;titan_glass = 500;titan_diamond = 250;diamond = 500;graphene = 500;mined_HE_graphite = 500;splitted_HE_graphite = 0;HE_graphite = 500;combustible_ice = 500;hydrogen = 5500;extracted_hydrogen = 250;splitted_hydrogen = 0;fractioned_hydrogen = 5250;deuterium = 1250;QIC = 125;Casmir_crystal = 250;subspace_selector = 250;gravity_len = 125;particle_container = 250;strange_matter = 125;gravity_matrix = 125; % 引力矩阵最大产量...(一些值为0的变量已忽略)... 可以看到，引力矩阵也是一种生产难度较高的资源，最大生产速率只有每分钟 125 单位，且需要「奇异物质」。在所有消耗的资源中，钛的消耗量最大，这是因为生产过程中需要大量高强度材料来囚禁高能物质。于是，钛元素产量也成为了引力矩阵的生产瓶颈。 实际上，在现实世界中，往往通过超导材料产生的强磁场来囚禁高能物质，而不是传统的高强度材料（钛合金、纳米材料等等）。 5. 宇宙矩阵在 DSP.mzn 中将最优化目标设为 solve maximize universe_matrix;，然后调用求解器，得到以下结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051iron_ore = 1364; % 上限=2500copper_ore = 1116; % 上限=2000coal_ore = 942; % 上限=1300iron = 1240;magnet = 124;copper = 1116;magnet_coil = 62;PCB = 558;IC = 248;micro_unit = 496;silicon_ore = 2232; % 上限=2250silicon = 1116;lattice_silicon = 124;raw_stone = 496; % 上限=3000glass = 248;titanium_ore = 1736; % 上限=2250titanium = 868;titan_alloy = 0;titan_glass = 248;titan_diamond = 186;diamond = 310;graphene = 434;graphene_tube = 124;mined_HE_graphite = 471;splitted_HE_graphite = 25;HE_graphite = 496;crude_oil = 150; % 上限=1780gasoline = 150;combustible_ice = 434;hydrogen = 2902;extracted_hydrogen = 217;splitted_hydrogen = 75;fractioned_hydrogen = 2610;deuterium = 620;deuterium_unit = 0;sulfuric_acid = 0;organic_crystal = 0;plastic = 62;QIC = 62;particle_broadband = 62;Casmir_crystal = 124;subspace_selector = 124;EM_matrix = 62;structure_matrix = 62;energy_matrix = 62;information_matrix = 62;gravity_matrix = 62;universe_matrix = 62;gravity_len = 62;particle_container = 124;strange_matter = 62; 宇宙矩阵是最究极的科技产品，需要五种矩阵（电磁、能量、结构、信息、引力）各一份才能生产一单位的宇宙矩阵。可以看到，宇宙矩阵的产业链最长、也需要最多种类的原料。值得注意的是，虽然只要五种矩阵各一份就能生产一单位宇宙矩阵，但宇宙矩阵的最大产量小于任意一个矩阵的最大产量，即： \\# 宇宙矩阵","link":"/2023/06/16/%E7%94%A8%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%E8%A7%A3%E5%86%B3%E3%80%8A%E6%88%B4%E6%A3%AE%E7%90%83%E8%AE%A1%E5%88%92%E3%80%8B%E4%B8%AD%E7%9A%84%E7%94%9F%E4%BA%A7%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98/"},{"title":"高斯积分","text":"李辰剑初稿 2021-3-16修改&amp;完成 2022-6-23 Contents 引入 求解最简单的两项 利用递推求解所有高斯积分 一点点的进一步讨论 附录：$n\\le9$时的高斯积分 引入高斯积分是形如 \\newcommand\\dd{\\mathrm d} \\newcommand\\lam{\\lambda} \\newcommand\\intr{\\int_0^\\infty} \\newcommand\\ker{e^{-\\lam x^2}} \\intr x^n \\ker\\dd x \\tag{1}的定积分（严格来说是广义积分）。它的核心是$e^{-\\lam x^2}$在$[0,+\\infty)$上的积分，再辅以幂函数$x^n$作为佐料。这个式子看上去有些复杂，却在各种工程计算、数学推导中有着广泛的应用。例如，在麦克斯韦气体速率分布律 p_{\\mathrm{M.B.}}(v)=c\\cdot v^2\\exp\\left(-\\frac{ mv^2}{2k_BT}\\right)\\tag{2}中，为了计算出前面的归一化系数$c$，就需要对后面的部分进行积分，相当于计算$n=2$时的高斯积分。 在温度$T$下，达到热平衡的理想气体中气体分子的「速率」会满足一定的「统计规律」。麦克斯韦气体速率分布是指：气体分子的速率为$v$的概率即为上述的$p(v)$. 又如，在大家耳熟能详的高斯分布 p_{\\mathrm{Gaussian}}(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\tag{3}中，为了计算出前面的归一化系数$1/\\sqrt{2\\pi}\\sigma$，也需要对后面的部分进行积分，然后调整前面的系数使得概率密度函数在全空间的积分为1.这相当于计算$n=0$时的高斯积分： 1=\\int_{-\\infty}^{+\\infty}p(x)\\dd x=\\boxed{\\cdots}\\times\\int e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\dd x=\\boxed{\\cdots}\\times\\sqrt{2\\pi}\\sigma\\notag \\\\ \\implies\\boxed{\\cdots}=\\frac 1{\\sqrt{2\\pi}\\sigma} 怎么感觉都是在计算归一化系数啊喂0.0 下面，我们将高斯积分定义为 I_n(\\lam):=\\intr x^n\\ker\\dd x,\\quad n=0,1,2...,\\ \\lambda>0\\tag{4}并在后面两节中试图求解。这里加入参数$\\lam$，是因为很多实际计算中指数上也会出现系数。 求解最简单的两项由于不定积分$\\int e^{-\\lam x^2}\\dd x$很难用初等函数表示，因此计算高斯积分并不容易。我们先求出$n=0,1$时的高斯积分数值，再通过构建递推关系式得到所有高斯积分。 事实上$n=1$的情况非常好求解，这是因为凑微分可以得到$e^{-\\lam x^2}\\dd x^2$的结构，从而就化归为了平凡的指数函数求积分问题： \\begin{align*} I_1(\\lam)&=\\intr x\\ker\\dd x\\\\ &=\\intr \\ker \\dd\\Big(\\frac{x^2}{2}\\Big)\\\\ &\\overset{\\xi=x^2}{=}\\frac 12\\intr e^{-\\lambda \\xi}\\dd \\xi\\quad\\\\ &=\\frac{1}{2\\lam}\\tag{5} \\end{align*}然而求解$n=0$的情况就麻烦了。没有了”狗腿子“$x$的帮助，我们就凑不出微分，也就不能像前面一样化归为简单函数的积分。因此，我们必须另辟蹊径。下面，我们将一维空间上的$I_0$与一个二维平面上的重积分联系起来，而后者可以转化为对$I_1$的求解，从而最终得到$I_2(\\lam$). 记$A$为下列二重积分： \\begin{align*} A&=\\iint_{\\mathbb{R}^2}e^{-(x^2+y^2)}\\mathrm dx\\mathrm dy\\\\ &=\\iint_{\\mathbb{R}^2}e^{-r^2}\\mathrm d\\sigma\\tag{6}\\\\ \\end{align*}则 \\begin{align*} A&=\\int_{-\\infty}^{+\\infty}\\mathrm dx\\cdot e^{-x^2}\\left[\\int_{-\\infty}^{+\\infty}\\mathrm dy\\cdot e^{-y^2}\\right]\\\\ &=\\left(\\int_{-\\infty}^{+\\infty}\\mathrm dx\\cdot e^{-x^2}\\right)\\cdot\\left(\\int_{-\\infty}^{+\\infty}\\mathrm dy\\cdot e^{-y^2}\\right)\\\\ &=\\left(\\int_{-\\infty}^{+\\infty}\\mathrm dx\\cdot e^{-x^2}\\right)^2=4[I_0(1)]^2\\tag{7} \\end{align*}这样就建立了二重积分$A$和高斯积分的联系。而另一方面，我们又可以在极坐标中直接将$A$积出： \\begin{align*} A&=\\iint_{\\mathbb{R}^2}e^{-r^2}\\mathrm d\\sigma\\\\ &=\\intr\\dd r\\cdot re^{-r^2}\\int_0^{2\\pi}\\mathrm d\\theta\\\\ &=2\\pi\\intr\\dd r\\cdot re^{-r^2}\\\\ &=2\\pi I_1(\\lam=1)=\\pi\\tag{8} \\end{align*} 这两个推导当中有一点细节…有兴趣的话可以慢慢看，没兴趣的话跳过也无妨。 于是我们得到： I_0(1)=\\frac{\\sqrt A} 2=\\frac{\\sqrt\\pi}{2}\\\\ \\begin{align*} \\implies I_0(\\lam)&=\\intr e^{-\\lam x^2}\\dd x\\\\ &=\\frac 1{\\sqrt\\lam}\\intr e^{-(\\sqrt\\lam x)^2}\\dd (\\sqrt\\lam x)\\\\ &=\\frac 1{\\sqrt\\lam}I_0(1)=\\frac12\\sqrt{\\frac{\\pi}{\\lam}}\\quad\\square.\\tag{10} \\end{align*}可以看到。$I_0$的求解并不显然，我们利用二重积分进行“升维打击”，最后才在极坐标中化归为$I_1(\\lam)$.这一技巧看上去很难。但实际上这一方法不是“难”，而是「巧夺天工」：其它大多数无穷积分都没有这样巧妙的求解方法，必须引入留数定理、拉普拉斯变换等更高级的方法才能求解。 通过递推求解所有高斯积分在前一节，我们求出了$I_0(\\lam)$和$I_1(\\lam)$的值。实际上，这已经足够应付不少场景了。但是在诸如麦克斯韦速率分布和$\\chi^2$分布这样的高维场合中仍然不够用。因此我们想要求解所有的$I_n(\\lam)$. 读者可能会想，求解$n=0,1$时的高斯积分已经如此费劲，那$n=2,3,…$时的情况岂不是更难处理？但实际上，只要求一次偏导，就可以很便捷地用$I_0$和$I_1$递推得到所有的$I_n(\\lam)$. 在带参变量的积分$I_n(\\lam)$中，考虑对参量$\\lam$求导： \\begin{align*} \\frac{\\dd}{\\dd\\lam}I_n(\\lam)&=\\frac{\\dd}{\\dd\\lam}\\intr x^n\\ker\\dd x\\\\ &=\\intr x^n\\frac{\\partial }{\\partial \\lam}\\ker\\dd x\\\\ &=\\intr x^n\\cdot (-x^2\\ker)\\dd x\\\\ &=-\\intr x^{n+2}\\ker\\dd x\\\\ &=-I_{n+2}(\\lam)\\tag{11} \\end{align*} 注 第二行中用到了积分与求导交换，严格来说需要考虑这两个微积分运算可交换性的问题。可交换的一个充分条件是：广义积分$I(\\lam)$对不同的$\\lam$一致收敛。因此我们只需确认积分的一致收敛性即可。 一般来说，带有指数压低的积分收敛是很快的，因此收敛性没有问题。但是要考虑「关于参量$\\lam$的」一致收敛性就会微妙一些。 设$I(\\lam)$对于某个给定的$\\lam_0$收敛，那么对$\\forall \\lam&gt;\\lam_0$积分只会收敛得更快。因此$\\lam_0$时的收敛速度可以bound住$\\forall \\lam(&gt;\\lam_0)$时的收敛速度。即，对于$\\forall \\lam_0&gt;0$, $I(\\lam)$在$[\\lam_0,+\\infty)$上一致收敛。进而，积分与求导是可交换的。 唯一的问题是$\\lam\\to 0$时$I(\\lam)\\to\\infty$，此时无法考虑这一广义积分的收敛性和一致收敛性。但是实际使用中并不需要$\\lam\\to0$！对于任意的实际问题，我们只需要取一个足够小的$\\lam_0$即可。 这相当于： I_{n+2}(\\lam)=-\\frac{\\dd}{\\dd \\lam}I_n(\\lam)\\tag{12}\\label{recur1}也就是说，我们建立了由$I_n$到$I_{n+2}$的递推公式！求导是容易计算的，因此这是一个可行的计算式。虽然$n$和$n+2$之间隔隔了一项，但我们正好计算出了$I_0(\\lam)$和$I_1(\\lam)$，可以满足计算所有$I_n(\\lam)$的要求。因此我们得到了一个计算所有$I_n(\\lam)$的通式。 另一种得到递推式的方法是分部积分。在这种含指标参量$n$的积分中，用分部积分改变$n$从而逐渐求解积分是一种很常见的方法。 \\begin{align*} I_{n-1}(\\lam)&=\\intr x^{n-1}\\ker\\dd x\\\\ &=\\frac 1n\\intr \\ker \\dd x^n\\\\ &=\\frac 1n\\left(\\left.x^n\\ker\\right|_0^\\infty-\\intr x^n\\dd(\\ker)\\right)\\\\ &=-\\frac 1n\\intr x^n(-2\\lam x)\\ker\\dd x\\quad (\\text{assume }n\\ge 1)\\\\ &=\\frac{2\\lam}{n}\\intr x^{n+1}\\ker\\dd x = \\frac{2\\lam}{n}I_{n+1}(\\lam)\\tag{13}\\label{recur2} \\end{align*}\\\\ \\implies I_{n+2}(\\lam)=\\frac{n+1}{2\\lam}I_n(\\lam) \\quad (n\\ge0) 这里我选择把$x^n$塞进微分进行分布积分；但事实上把$\\ker$塞进微分进行分部积分也是可以的，会得到相同的结果。有兴趣的同学可以试一试。 可以看到，和微分得到的递推式相比，虽然形式不同，但仍然是相差两次的递推式。这好像在告诉我们：$n=奇数$和$n=偶数$时的高斯积分之间有一道相当深的鸿沟，一般的方法很难跨越。 得到了递推关系，我们就可以很方便地求解次数$n$更高时的高斯积分了。例如，$n=2$时有： I_2(\\lam)=-\\frac{\\dd}{\\dd\\lam}I_0(\\lam)=-\\left(\\frac 12\\sqrt{\\frac\\pi\\lam}\\right)'=\\frac{\\sqrt\\pi}{4}\\lam^{-3/2}\\tag{14}或： I_2(\\lam)=\\frac{1}{2\\lam}I_0(\\lam)=\\frac1{2\\lam}\\cdot\\frac12\\sqrt{\\frac{\\pi}{\\lam}}=\\frac{1}{4}\\sqrt{\\frac{\\pi}{\\lam^3}}\\notag进一步地，还可以求解$n=3$的高斯公式： I_3(\\lam)=-\\frac{\\dd}{\\dd\\lam}I_1(\\lam)=-\\left(\\frac 1{2\\lam}\\right)'=\\frac{1}{2\\lam^2}\\tag{15}一点点的进一步讨论在这一节，我们对上一节得到的结果稍加挖掘；然后给出高斯积分的通项（而非递推）公式。 在上一节，我们给出了高斯积分的两个递推公式$\\eqref{recur1}$和$\\eqref{recur2}$： \\left\\{\\begin{array}c I_{n+2}=-I_n'(\\lam)\\\\ I_{n+2}=\\frac{n+1}{2\\lam}I_n(\\lam) \\end{array}\\right.\\tag{16}虽然两个公式都是二阶递推式，但形式不一样。能不能将$I_{n+2}$消去，求解出一些东西呢？ \\implies I_n'(\\lam)=-\\frac{n+1}{2\\lam}I_n(\\lam)\\tag{17}这是一个关于$\\lam$的一阶微分方程，很容易可以解（凑）出： I_n(\\lam)\\propto \\lam^{-\\frac{n+1}{2}}\\tag{18}将前面计算出的$I_0\\sim I_2$带入验算，很容易发现它是正确的。注意，我们无法用这样的方式求解高斯积分，因为前面还有一个依赖于$I_n$边值条件的常数；但我们可以得到$I$对$\\lam$的依赖关系。由于$-(n+1)/2&lt;0$，因此$I_n(\\lam)$随$\\lam$的增加而减小。这是符合预期的：$\\ker$作为积分中的指数压低因子，$\\lam$越大，积分越小。 前一节我们得到了高斯积分的递推公式。这一递推关系并不复杂，能否推出计算更方便的通项公式呢？答案是肯定的。 分奇偶讨论，不难得到： \\begin{align*} I_{2k}(\\lam)&=\\frac{2k-1}{2\\lam}I_{2k-2}(\\lam)\\\\ &=\\frac{(2k-1)\\cdot(2k-3)\\cdots1}{(2\\lam)^k}I_0(\\lam)\\\\ &=\\frac{(2k-1)!!}{(2\\lam)^k}\\cdot\\frac{\\sqrt{\\pi}}{2}\\lam^{-1/2}\\\\ &=\\frac{(n-1)!!}{(2\\lam)^{n/2}}\\cdot\\sqrt{\\frac{\\pi}2}\\sqrt{\\frac1{2\\lam}}\\\\ &=\\sqrt{\\frac\\pi2}\\cdot\\frac{(n-1)!!}{(2\\lam)^{\\frac{n+1}2}}\\tag{19} \\end{align*}其中，$k\\in\\mathbb N$, n!!=n(n-2)(n-4)\\cdots(到1|2为止)是双阶乘记号（为了处理$n=0$时$(n-1)!!$没有定义的问题，可以约定当$n’&lt;0$时$n’!!=1$）。 对奇数，有： \\begin{align*} I_{2k+1}&=\\frac{2k}{2\\lam}I_{2k-1}(\\lam)\\\\ &=\\frac{(2k)\\cdot(2k-2)\\cdots2}{(2\\lam)^k}I_1(\\lam)\\\\ &=\\frac{(2k)!!}{(2\\lam)^k}\\cdot\\frac 1{2\\lam}\\\\ &=\\frac{(n-1)!!}{(2\\lam)^{\\frac{n-1}2}}\\cdot\\frac1{2\\lam}\\\\ &=\\frac{(n-1)!!}{(2\\lam)^{\\frac{n+1}2}}\\tag{20} \\end{align*}这里没有把分子分母上的$2$全部约去，是为了和$n$为偶数时保持相同的形式。 于是，我们就得到了高斯积分$I_n(\\lam)$的通向公式： I_n(\\lam)=\\left\\{\\begin{array}c \\sqrt{\\frac\\pi2}\\cdot\\frac{(n-1)!!}{(2\\lam)^{(n+1)/2}} & \\quad n偶\\\\ \\phantom{\\sqrt{\\frac12}\\cdot}\\frac{(n-1)!!}{(2\\lam)^{(n+1)/2}} & \\quad n奇 \\end{array}\\right.\\tag{21}通项公式虽然看上去复杂，但其实并没有特别non-trivial的地方——推导过程也是完全初等的。唯一值得注意的是奇数和偶数时通项公式之间相差的$\\sqrt{\\pi/2}$因子——这很容易让人联想到$\\intr\\sin^nx\\dd x$的通项公式。我相信，高斯积分和三角函数、和圆之间还有一些隐藏的联系等待我们去发现。 附录：$n\\le9$时的高斯积分表最后，我将$n=0\\sim9$时的高斯积分$I_n(\\lam)$计算后列于此，以便读者和我日后查阅。 \\begin{align*} &I_0(\\lam)=\\intr \\ker\\dd x=\\frac 12\\sqrt{\\frac{\\pi}{\\lam}} &I_1(\\lam)=\\intr x\\ker\\dd x=\\frac{1}{2\\lam}\\\\ &I_2(\\lam)=\\intr x^2\\ker\\dd x=\\frac 14\\sqrt{\\frac{\\pi}{\\lam^3}} &I_3(\\lam)=\\intr x^3\\ker\\dd x=\\frac{1}{2\\lam^2}\\\\ &I_4(\\lam)=\\intr x^4\\ker\\dd x=\\frac 38\\sqrt{\\frac{\\pi}{\\lam^5}} &I_5(\\lam)=\\intr x^5\\ker\\dd x=\\frac{1}{\\lam^3}\\\\ &I_6(\\lam)=\\intr x^6\\ker\\dd x=\\frac {15}{16}\\sqrt{\\frac{\\pi}{\\lam^7}} &I_7(\\lam)=\\intr x^7\\ker\\dd x=\\frac{3}{\\lam^4}\\\\ &I_8(\\lam)=\\intr x^8\\ker\\dd x=\\frac {105}{32}\\sqrt{\\frac{\\pi}{\\lam^9}} &I_9(\\lam)=\\intr x^9\\ker\\dd x=\\frac{12}{\\lam^5}\\tag{22} \\end{align*}","link":"/2022/06/24/%E9%AB%98%E6%96%AF%E7%A7%AF%E5%88%86/"},{"title":"组合数学中的恒等式","text":"MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: \"all\" } } }); 李辰剑 2024-7-23 近日担任《离散数学》助教，批阅期末考卷的时候发现最后一题有许多等价答案，涉及大量组合数的推导与化简。于是我捡起了自高中以后尘封多年的组合数知识，略加推导后整理得出了这篇文章，以供日后参考。同时，也希望这篇文章能帮助到有需要的老师和同学们。 记号约定本文假设读者有基本的组合数学知识，熟悉组合数 $C_n^k$ 的解析表达式： \\newcommand\\C[2]{C_{ #1}^{ #2}} \\C nk\\equiv\\binom{n}{k}=\\frac{n!}{k!(n-k)!}\\tag{0.1}组合数/二项式系数有两种主流的记号，除了上述的 $C_n^k$，还有一种表达 $\\binom{n}{k}\\equiv \\C nk$，后一种记号主要用在高等数学和二项式系数中。本文中主要采用前一种记号。 文中不加说明时，参数（$m,n,k…$）默认都是自然数。 研究方法：多项式除了组合数，本文还需要读者熟悉多项式的基本用法。读者也许会有些疑惑，明明是学习组合数学，为什么需要熟悉多项式呢？事实上，组合数与多项式之间有着非常深刻的联系。 考察整幂次的二项式展开： \\newcommand\\S[2]{\\sum_{ #1=0}^{ #2}} \\newcommand\\Sn[1]{\\sum_{ #1=0}^{n}} \\newcommand\\Skn{\\sum_{k=0}^{n}} \\newcommand\\Snk\\Skn (a+b)^n=\\Snk \\C nka^kb^{n-k} \\tag{0.2}你会发现，在左边全部展开后（合并同类项之前）得到的的 $2^n$ 个单项式里，恰好有 $\\C nk$ 个 $a$ 的幂次为 $k$ 的项，因此等式右边对应的系数刚好就是 $\\C nk$。多项式乘法展开后的合并同类项刚好是一次单项式的计数过程。当然，这样的例子还有许多。从多项式出发研究组合数将为我们提供新的视角，而且令许多代数（algebraic）方法成为可能。 多项式和组合数之间有着千丝万缕的联系，而采用多项式研究组合数的方法也将贯穿本文的始终。 第一组恒等式：横向求和1. 全部横向和由 2^n=(1+1)^n=\\Snk\\C nk \\cdot 1^n\\cdot 1^{n-k}=\\Snk\\C nk \\notag我们可以得到： \\label{eq:sum_C}\\tag{1.1} \\boxed{\\Snk\\C nk=2^n}这是我们的第一个恒等式，我称之为横向全部和。 全部横向和在杨辉三角上的示意图 2. 交错和为零/奇偶和相等类似地，由 0=(1-1)^n=\\Snk(-)^k\\C nk\\notag我们可以得到： \\boxed{\\Snk(-)^k\\C nk=0} \\tag{1.2}或等价地，表述成奇数项和偶数项和的等式（当$n&gt;0$时）： \\label{eq:even_odd} \\boxed{\\sum_{k\\text{ odd}}^{}\\C nk=\\sum_{k\\text{ even}}\\C nk} \\tag{1.3}即，交错和为零/奇数项=偶数项。 注意到，对于 $n$ 为奇数的情形，利用 $\\C nk=\\C n {n-k}$ 很容易证明奇偶和相等 $\\eqref{eq:even_odd}$；但 $n$ 为偶数的时，必须通过二项式展开才能证明 $\\eqref{eq:even_odd}$，其它方法很难证明。 交错和为零在杨辉三角上的示意图 第二组恒等式：杨辉三角这一组恒等式由杨辉三角中层间的加法关系得到。注意到杨辉三角本身就对应了多项式加法： \\begin{align*} (x^2+2x+1)(x+1)&=x^3+2x^2+x\\\\ &\\phantom{=x^3+}+x^2+2x+1\\\\ &=x^3+3x^2+3x+1\\\\ &\\sim\\,[1\\quad 2\\quad 1]\\\\ &\\qquad\\,+[1\\quad 2\\quad 1]\\\\ &=[1\\quad3\\quad3\\quad 1] \\end{align*}因此这一节的恒等式仍可以看作由多项式导出。 3. 杨辉三角基本关系 \\label{eq:basic}\\tag{2.1} \\boxed{\\C nk=\\C{n-1}{k-1}+\\C{n-1}k} 杨辉三角上的基本关系 虽然我们可以从杨辉三角直接“读”出这个恒等式，但是我们也可以通过代数关系硬证，避免“视察法”得到公式的不严谨性。推导如下： \\begin{align*} \\C{n-1}{k-1}+\\C{n-1}k&=\\frac{(n-1)!}{(k-1)!(n-k)!}+\\frac{(n-1)!}{k!(n-k-1)!}\\\\ &=\\frac{n!}{k!(n-k)!}\\cdot\\frac kn+\\frac{n!}{k!(n-k)!}\\cdot\\frac{n-k}n\\\\ &=\\frac{n!}{k!(n-k)!}\\left(\\frac kn+\\frac{n-k}n\\right)=\\C nk\\qquad\\square. \\end{align*}4~5. 裂项与纵向求和利用二项式定理，组合数的横向求和 $\\Snk \\C nk=2^n$ 很容易得到；但是纵向求和 $\\sum_{m=0}^n\\C{m}k$ 就不那么 trivial 了。 逆用上面的基础关系 $\\eqref{eq:basic}$，可以给出组合数的裂项 $\\C{n-1}{k-1}=\\C nk-\\C{n-1}k$，即 \\boxed{\\C nk=\\C{n+1}{k+1}-\\C n{k+1}} \\tag{2.2}\\label{eq:break_into_two} 杨辉三角上的组合数裂项 对 $n$ 求和，即有： \\begin{align*} \\Sn{m}\\C m k&=\\Sn m \\C{m+1}{k+1}-\\C m{k+1}\\\\ &=\\C{n+1}{k+1}-\\C0{k+1} \\end{align*}$\\C0{k+1}$ 是什么？严谨细心的同学固然会觉得上面的推导搞错了边界条件；但另一种更为霸道取巧的方法是补充定义 $n\\ge k$ 的 $\\C nk$，让记号顺着数学走。 $\\C nk$ 的拓展定义定义 当 $k&gt;n$ 时，补充定义 $\\C nk=0$。即： \\C nk=\\left\\{\\begin{array}l \\frac{n!}{k!(n-k)!} & k\\le n \\\\ 0 & k>n, \\end{array}\\right. \\quad \\text {for } k,n\\in\\mathbb N. \\tag{2.5}\\label{eq:generalization1}不难发现，此时递推关系 $\\C nk=\\C{n-1}{k-1}+\\C{n-1}k$ 仍成立；因此裂项 $\\eqref{eq:break_into_two}$ 仍成立。 在一些涉及代数的问题中，也会给出另一种对 $\\C nk$ 的推广： \\binom{\\nu}{k}:=\\frac{\\nu(\\nu-1)\\cdots(\\nu-k+1)}{k!},\\quad \\text{for }\\nu\\in\\mathbb R,k\\in\\mathbb N. \\label{eq:generalization2}\\tag{2.6}这种推广来自于拓展的二项式定理，分子的形式类似多项式求导的系数，更适合泰勒展开。那么，这两种推广是否兼容呢？案是肯定的。当 $n&lt;k$ 时，代数推广 $\\eqref{eq:generalization2}$ 变为： \\C nk\\overset{\\eqref{eq:generalization2}}{=}\\frac{n\\cdot(n-1)\\overbrace{\\cdots}^{\\text{有一项为0}}(n-k+1)}{k!}=0\\notag与 $\\eqref{eq:generalization1}$ 相符。 5. 纵向求和回到前面。根据我们的推广有 $\\C 0{k+1}=0$，于是我们得到组合数的纵向求和公式： \\boxed{\\Sn{m}\\C m k=\\C{n+1}{k+1}} \\label{eq:n_sum}\\tag{2.3}这是杨辉三角中一整列组合数的求和；根据裂项公式（或者逆用 $\\eqref{eq:n_sum}$）我们还可以给出另一个推论，即部分的纵向求和： \\boxed{\\sum_{m=a}^b\\C m k=\\C{b+1}{k+1}-\\C{a}{k+1}} \\label{eq:partial_n_sum}\\tag{2.4}其中 $a,b\\in\\mathbb N$ 分别是下标求和的下限和上限（即有 $a&lt;b$）。 杨辉三角上证明纵向求和公式 例题：广义球盒问题学数学如果只学定义和定理，便味同嚼蜡，如同纸上谈兵。即使一日千里，也无法真正理解其中的数学。只有通过 nontrivial 问题的磨砺，才能帮助我们窥探到数学理论的深层含义，帮助我们加深对数学工具的理解、认识到数学工具的真正边界。 在这里，我给出一道经典的球盒计数问题，并用经典的排列组合方法和生成函数两种方法分别给出答案。我们将会看到，为了证明两种方法给出的答案相等，必须灵活、综合地运用前述的排列组合恒等式；它们在推导中将起到无可替代的作用。 例题 将 $n$ 个不可区分的小球放入编号为 $1,2,\\cdots,m$ 的盒（即 $m$ 个可区分的盒）中，分别对以下几种情况求方法数。 (1) 没有限制；(2) 第一个盒有 $k$ 个球时；(3) 第一个盒有不超过 $k$ 个球；(4) 对于 $i=1,2,3$ 均有第 $i$ 号盒子中球的个数不等于 $i$，这里 $m\\ge4,n\\ge6$。 解答 (1) $\\langle方法一\\rangle$ 插板法 假象所有的 $n$ 个球排成一列，将 $m$ 个盒子想象为 $m-1$ 个分隔板，只需要在 $n$ 个球中插入所有分隔板即可。所有的 $n$ 个球和 $m-1$ 个分隔板放成一列，一共有 $n+(m-1)$ 个位置，只需在其中 $m-1$ 个位置放入分隔板即可。因此一共有 ${\\rm ans}(n,m)=\\C{n+m-1}{m-1}=\\C{n+m-1}{n}$ 种方法。 插板法解球盒问题示意图 将 $n$ 个不可区分球放入 $m$ 个可区分盒的放法数量记为 $\\mathrm{bib}(n,m)=\\C{n+m-1}{m-1}=\\C{n+m-1}{n}$。 bib = ball in box $\\langle方法二\\rangle$ 生成函数 $n$ 个球放入 $m$ 个盒，只需要计算 $n_1+n_2+\\cdots n_m=n$ 的自然数解的数量即可。这刚好对应了多项式 \\newcommand\\bib{ {\\rm bib}} \\newcommand\\coef{ {\\rm coef}} \\underbrace{(1+x+x^2+\\cdots)(1+x+x^2+\\cdots)\\cdots(1+x+x^2+\\cdots)}_{共m项}\\notag展开后 $x^n$ 的系数。因此，我们只需要计算 F(x)=(1+x+x^2+\\cdots)^m=\\frac{1}{(1-x)^m}\\notag的展开式中 $x^n$ 项的系数即可。$F(x)$ 被称为问题的生成函数。 生成函数又是一个大坑。生成函数在数列、组合数学、离散数学、特殊函数、概率论等领域都有重要的应用。也许以后能再开笔记专门讨论生成函数；这里就不展开了。 记多项式 $f(x)$ 中 $x^n$ 项的系数为 $\\coef_n F(x)$。根据广义的二项式定理（或者，二项式的泰勒展开），则有： F(x)=(1-x)^{-m}=\\sum_{k=0}^{+\\infty}\\binom{-m}{k}(-x)^k\\notag即 $\\coef_k F(x)=(-)^k\\cdot\\binom{-m}{k}$。这里的系数可以由泰勒展开得到： \\begin{align*} \\binom{-m}{k}&=\\frac{(-m)(-m-1)\\cdots(-m-k+1)}{k!}\\\\ &=(-)^k\\frac{m(m+1)\\cdots(m+k-1)}{k!}=(-)^k\\C{m+k-1}{k} \\end{align*}因此答案就是 $(-)^k\\cdot\\left.\\binom{-m}{k}\\right|_{k=n}=\\C{m+n-1}{n}$，与 $\\langle方法一\\rangle$ 得到的结果是一样的。 (2) 第一个盒有 $k$ 个球，则问题退化为 $n-k$ 个球装入 $m-1$ 个盒的情形。答案为： \\bib(n-k,m-1)=\\C{n+m-k-2}{n}\\notag(3) $\\langle方法一\\rangle$ 生成函数 注意到此时第一个盒子里最多只能有 $k$ 个球，这对应了多项式的幂次不超过 $k$。对应的生成函数为： \\begin{align*} F(x)&=(1+x\\cdots x^k)(1+x+\\cdots)^{m-1}\\\\ &=\\frac{1-x^{k+1}}{1-x}\\cdot \\frac{1}{(1-x)^m}\\\\ &=\\frac{1-x^{k+1}}{(1-x)^m} \\end{align*}而 $F(x)$（的展开式中）$x^n$ 的系数即为问题的答案。 注意到 $\\coef_n \\{x^k F(x)\\}=\\coef_{n-k}F(x)$，我们得到： \\begin{align*} {\\rm ans}&=\\coef_n F(x)\\\\ &=\\coef_n\\left\\{\\frac{1-x^{k+1}}{(1-x)^m}\\right\\}\\\\ &=\\coef_n\\{(1-x)^{-m}\\}-\\coef_n\\{x^{k+1}(1-x)^{-m}\\}\\\\ &=\\C{n+m-1}{m-1}-\\C{n+m-k-2}{m-1} \\end{align*}$\\langle方法二\\rangle$ 组合数学 生成函数法给出了非常漂亮的结论；那么组合数学方法能否给出答案呢？答案是肯定的。 从组合数学的视角，盒一中装有不超过 $k$ 个球，可以分为没有球、装有 $1$ 个球、…、装有 $k$ 个球这 $k+1$ 种情况。利用(2)的结论，可以得到答案： \\sum_{i=0}^k \\bib(n-i,m-1)=\\sum_{i=0}^{k}\\C{n+m-i-2}{m-2}\\notag计算并不复杂；但是问题在于，如何验证两种方法给出的答案相等呢？这时我们可以利用组合数的纵向求和公式 $\\eqref{eq:partial_n_sum}$ 化简上式： \\sum_{i=0}^k\\C{n+m-i-2}{m-2}\\overset{\\eqref{eq:partial_n_sum}}{=}\\C{n+m-1}{m-1}-\\C{n+m-k-2}{m-1}\\notag终于得到了相同的答案。 (4) 终于到了最难的最后一小问。这里我们同样有两种选择，走组合数学的老路，或者诉诸生成函数。前期计算并不困难，只是有些繁琐；但最后的化简并不容易。这里，我们还是把组合数学的方法放在前面。 $\\langle方法一\\rangle$ 广义容斥原理|组合数学 解用概率论中的记号，记事件 $P_i=「盒i中球数=i」$，$\\#(P)$ 表示满足事件 $P$ 的不同放法的数量。则题目所求数字可表示为 $\\#(\\overline P_1\\overline P_2\\overline P_3)$，其中 $\\overline P$ 表示事件的反。根据广义容斥原理，我们可以得到： \\#(\\overline P_1\\overline P_2\\overline P_3)=\\#(\\varnothing)-\\sum_i\\#P_i+\\sum_{i\\neq j}\\#P_iP_j-\\#P_1P_2P_3\\notag根据前面几小问的经验，不难得出 \\begin{align*} \\#:=\\#(\\varnothing)&=\\C{n+m-1}{n}\\\\ \\#(P_i)&=\\C{n+m-i-2}{n-i}=\\C{n+m-i-2}{m-2}\\\\ \\#(P_iP_j)&=\\C{n+m-i-j-3}{m-3}\\\\ \\#(P_iP_jP_k)&=\\C{n+m-i-j-k-4}{m-4} \\end{align*}带入上式，即可得到： \\begin{align*} {\\rm ans}&=\\#(\\varnothing)-\\sum_i\\#P_i+\\sum_{i\\neq j}\\#P_iP_j-\\#P_1P_2P_3\\\\ &=\\C{n+m-1}{m-1}-\\sum_i\\C{n+m-i-2}{m-2}+\\sum_{i\\neq j}\\C{n+m-i-j-3}{m-3}-\\C{n+m-i-j-k-4}{m-4}\\big|_{i,j,k=1,2,3}\\\\ &=\\underbrace{\\C{n+m-1}{m-1}-\\sum_{i=1}^3\\C{n+m-i-2}{m-2}+\\sum_{i=3}^5\\C{n+m-i-3}{m-3}-\\C{n+m-10}{m-4}}_{共8项} \\end{align*}大多数同学做到这里便以为结束了，收工大吉。但实际上这个结果可以进一步化简。首先利用纵向求和，再观察到杨辉三角上相邻位置的邻组合数进行化简，最终可以化简为只有 4 项的结果。 \\begin{align*} &&\\phantom{++++++}&\\underbrace{ \\C{n+m-1}{m-1}- \\color{blue}{\\sum_{i=1}^3\\C{n+m-i-2}{m-2}}+ \\color{blue}{\\sum_{i=3}^5\\C{n+m-i-3}{m-3}}- \\C{n+m-10}{m-4} }_{共8项}\\\\ &&\\overset{\\color{grey}{\\sum_{\\l}\\C\\l k=\\C{\\l+1}{k+1}}\\phantom{+..}}{=}& \\C{n+m-1}{m-1}- \\color{blue}{\\big(\\C{n+m-2}{m-1}-\\C{n+m-5}{m-1}\\big)}+ \\color{blue}{\\big(\\C{n+m-5}{m-2}-\\C{n+m-8}{m-2}\\big)}- \\C{n+m-10}{m-4}\\\\ &&=\\overset{\\phantom{===.}}{}& \\color{magenta}{\\big(\\C{n+m-1}{m-1}-\\C{n+m-2}{m-1}\\big)}+ \\color{magenta}{\\big(\\C{n+m-5}{m-1}+\\C{n+m-5}{m-2}\\big)} -\\C{n+m-8}{m-2}-\\C{n+m-10}{m-4}\\\\ &&\\overset{\\color{grey}{\\C nk=\\C{n-1}{k-1}+\\C{n-1}k}}{=}&\\underbrace{ \\color{magenta}{\\C{n+m-2}{m-2}}+ \\color{magenta}{\\C{n+m-4}{m-1}}- \\C{n+m-8}{m-2}-\\C{n+m-10}{m-4}}_{共4项} \\end{align*}这样我们就得到了最简的结果：只有四项，且每项系数绝对值都为 1。我们可以用「不同项之间是否在杨辉三角中相邻」来衡量是否还有进一步化简的空间：任何项在杨辉三角中都不相邻，前述恒等式都无法直接触发，大概率无法进一步化简。 $\\langle方法二\\rangle$ 生成函数 这一小问用生成函数1同样可以求解。而且相比广义容斥原理迂回曲折的计算过程，生成函数更为直接清晰。然而我们将会看到，“复杂性不会消失，只会转移”；作为更清晰的数学图像的代价，生成函数法的计算和化简更为复杂，除非铺开草稿纸仔细演算，否则在压力下几乎不可能算出最终的最简结果。 我们前面提到，计算球盒问题的方法数，等价于计算如下多项式 \\underbrace{(1+x+x^2+\\cdots)(1+x+x^2+\\cdots)\\cdots(1+x+x^2+\\cdots)}_{共m项}\\notag中 $x^n$ 项的系数。于是，计算第 $i$ 个盒子中球数 $\\neq i(i=1,2,3)$ 的情况数量，只需要在前三个盒子（前三个因子）中分别禁止 $x,x^2,x^3$ 即可。于是我们得到对应的生成函数： \\begin{align*} F(x)&=(1+x^2+x^3\\cdots)(1+x+x^3\\cdots)(1+x+x^2+x^4\\cdots)\\cdot(1+x+x^2+\\cdots)^{m-3}\\\\ &=\\left(\\frac{1}{1-x}-x\\right)\\left(\\frac{1}{1-x}-x^2\\right)\\left(\\frac{1}{1-x}-x^3\\right)\\cdot\\left(\\frac{1}{1-x}\\right)^{m-3}\\\\ &=(1-x+x^2)(1-x^2+x^3)(1-x^3+x^4)\\cdot\\frac{1}{(1-x)^m} \\end{align*}这里我们遇到了生成函数法的第一个难点：如何展开并化简前面的多项式？直接展开共有 3x3x3=27 项，极易出错。解决方案是分组展开、竖式合并。 \\begin{align*} &\\phantom{+}(1-x+x^2)(1-x^2+x^3)(1-x^3+x^4)\\\\ &=\\big[1-x(1-x)\\big]\\big[1-x^2(1-x)\\big]\\big[1-x^3(1-x)\\big]\\\\ &=1\\color{blue}{-(x+x^2+x^3)(1-x)}\\\\ &\\phantom{++}\\color{magenta}{+(x^3+x^4+x^5)(1-x)^2}-x^6(1-x)^3\\\\ &=1\\color{blue}{-x-x^2-x^3}\\\\ &\\phantom{++++}\\color{blue}{+x^2+x^3+x^4}\\\\ &\\phantom{++++++.}\\color{magenta}{+x^3+x^4+x^5}\\\\ &\\phantom{++++++++}\\color{magenta}{-2x^4-2x^5-2x^6}\\\\ &\\phantom{+++++++++++}\\color{magenta}{+x^5+\\ \\ x^6+x^7}\\\\ &\\phantom{+++++++++++++.}-x^6+3x^7-3x^8+x^9\\\\ &=1-x\\phantom{++..}+x^3\\phantom{++++..}-2x^6+4x^7-3x^8+x^9\\\\ &=1-x+x^3-2x^6+4x^7-3x^8+x^9 \\end{align*}有了这个结果之后，后面的步骤并不困难，我们很快就能写出答案。记 $\\frac{1}{(1-x)^m}$ 展开式中 $x^n$ 项系数为 $\\C{n-m-1}{m-1}=:c_n$，则 \\begin{align*} {\\rm ans}&=c_n-c_{n-1}+c_{n-3}-2c_{n-6}+4c_{n-7}-3c_{n-8}+c_{n-9}\\\\ &=\\C{n-m-1}{m-1}-\\C{n-m-2}{m-1}+\\C{n-m-4}{m-1}-2\\C{n-m-7}{m-1}+4\\C{n-m-8}{m-1}-3\\C{n-m-9}{m-1}+\\C{n-m-10}{m-1} \\end{align*}接下来我们就遇到了生成函数法的第二个难点：如何化简。根据 $\\langle方法一\\rangle$ 的结果，我们知道上式应该可以化简成只有四项的答案；但如今不仅项数多（仍有七项），而且系数也不规律。真的能化简吗？ 答案是肯定的。实际上，只需要注意观察系数、有方向的凑配即可。真正用到的恒等式只有最简单的杨辉三角基本关系 $\\eqref{eq:basic}$。 \\newcommand\\CC[2]{\\C{n-m-#1}{m-#2}} \\begin{align*} {\\rm ans}&=\\color{blue}{\\CC11-\\CC21}+\\CC41-2\\CC71+4\\CC81-3\\CC91+\\CC{10}1\\\\ &=\\color{blue}{\\CC22}+\\CC41-\\color{blue}{2\\big(\\CC71-\\CC81\\big)}+\\color{blue}{2\\big(\\CC81-\\CC91\\big)}-\\color{blue}{\\big(\\CC91-\\CC{10}1\\big)}\\\\ &=\\CC22+\\CC41-\\color{blue}{2\\CC82}+\\color{blue}{2\\CC92}-\\color{blue}{\\CC{10}2}\\\\ &=\\CC22+\\CC41-\\color{magenta}{\\big(\\CC82-\\CC92\\big)}-\\CC82+\\color{magenta}{\\big(\\CC92-\\CC{10}2\\big)}\\\\ &=\\CC22+\\CC41-\\color{magenta}{\\CC93+\\CC{10}3}-\\CC82\\\\ &=\\CC22+\\CC41-\\CC82-\\color{magenta}{\\CC{10}4} \\end{align*}其中，用颜色标出来的地方便是应用基本关系的项。至此，我们终于得到了最简结果，这一结果也与 $\\langle方法一\\rangle$ 中结果相符。 第三组恒等式：求导6. 带一次项的组合数求和我们先给出恒等式，然后再给出推导。 \\boxed{\\Snk k\\C nk=n2^{n-1}}\\tag{3.1}乍一看，$k\\C nk$ 求和与以往的任何的组合数求和形式都不同，仿佛无从下手；但请读者记住，形如 $kx^k$ 的求和往往和求导有关，因为只有求导会从 $x^k$ 上拉一个 $k$ 下来，而计算 $\\sum x^k$ 就简单多了。因此，我们考虑利用求导来证明上式。 在二项展开 $(1+x)^n=\\Snk \\C nk x^k$ 两边作用 $\\frac{\\mathrm d}{\\mathrm dx}$，得到： n(1+x)^{n-1}=\\S nk k\\C nk x^{k-1}\\notag令 $x=1$，即可得到上式。 利用类似方法，多次求导后还可以得出 \\S nk k^2\\C nk=n(n+1)2^{n-2}\\notag等更多恒等式。这里就不展开赘述了。 第四组恒等式：卷积7. 积之和/卷积公式我们同样先给出恒等式，然后再给出推导。 \\boxed{\\sum_{k=0}^r\\C mk\\C n{r-k}=\\C{m+n}r} \\label{eq:convol}\\tag{4.1}其中 $r\\le\\min\\{m,n\\}$。乍一看，之前的恒等式都是单项组合数的组合；这里是两项组合数乘积的求和，如何处理？理解这个恒等式的关键，在于注意到反向（$k$ 与 $r-k$）相乘这个类似卷积的结构。于是我们可以构造多项式的“卷积”，从多项式乘法中提取出上述等式。考虑 \\left(\\sum_{k=0}^m\\C mk x^k\\right)\\left(\\sum_{k'=0}^n\\C n{k'} x^{k'}\\right)\\notag则其展开式中 $x^r$ 的系数为 \\begin{align*} \\boxed{\\cdots}x^r&=\\C m0x^0\\cdot\\C nr x^r+\\C m1 x^1\\cdot\\C n{r-1}x^{r-1}+\\cdots\\\\ &=\\left(\\sum_{k=0}^r\\C mk\\C n{r-k}\\right)\\cdot x^k \\end{align*}另一边，又有 \\begin{align*} &\\phantom{=}\\left(\\sum_{k=0}^m\\C mk x^k\\right)\\left(\\sum_{k'=0}^n\\C n{k'} x^{k'}\\right)\\\\ &=(1+x)^m\\cdot(1+x)^n=(1+x)^{m+n} \\end{align*}根据二项式定理，其中 $x^r$ 项系数为 $\\C{m+n}r$。于是我们得到 \\sum_{k=0}^r\\C nk\\C n{r-k}=\\C{m+n}r\\quad \\square.\\notag实际上，使用向量记号，我们可以把 $\\eqref{eq:convol}$ 表示成真正的卷积形式： {\\vec C}_{m+n}=\\vec C_m* \\vec C_n\\notag其中 $\\vec C_n:=(\\C n0,\\C n1,\\cdots,\\C nn)$ 是一个组合数构成的向量，$*$ 表示向量间的卷积运算。 由 $\\eqref{eq:convol}$，我们还可以得到两个推论： 推论 1 令 $m=n$，我们有 \\sum_{k=0}^r\\C nk\\C n{r-k}=\\C{2n}r\\notag推论 2 利用 $\\C nk = \\C n{n-k}$，有 \\sum_k\\C mk\\C nk = \\sum_k\\C nk \\C n{n-k}=(\\vec C_{m+n})_n=\\C{m+n}n\\notag因此得到 \\sum_{k=0}^{\\min\\{m,n\\}}\\C mk \\C nk=\\C{m+n}n\\notag推论 3 回顾杨辉三角的基本关系，基本关系 $\\C nk=\\C{n-1}{k-1}+\\C{n-1}k$ 其实是卷积公式 $\\eqref{eq:convol}$ 的一种特殊情况。这是因为基本关系来自于杨辉三角，杨辉三角的构造方法本质上来源于多项式相乘，而多项式相乘又蕴含了卷积。 \\begin{align*} (x+1)(x+1)&=x^2+x\\\\ &\\phantom{++..}+x+1\\\\ &=x^2+2x^2+1\\\\ &\\sim\\,[1\\quad 1]\\\\ &\\qquad\\,+[1\\quad 1]\\\\ &=[1\\quad2\\quad 1] \\end{align*}具体来说，在卷积公式 $\\eqref{eq:convol}$ 中令 $m=1$，$r=k$，将原本的求和哑变量用 $\\l$ 替代，则有 \\sum_{\\l=0}^1\\C 1\\l\\C n{k-\\l}=\\C{n+1}k\\\\ \\implies 1\\cdot \\C nk+1\\cdot \\C n{k-1}=\\C{n+1}k\\\\ \\implies \\C nk+\\C{n}{k-1}=\\C{n+1}k\\notag再令 $k\\to k+1$，就得到了 $\\C nk+\\C n{k+1}=\\C{n+1}{k+1}$，即基本关系。 总结从头至尾，从多项式展开、到基于多项式卷积的杨辉三角，再到多项式求导，可以说所有的组合数恒等式背后都有着多项式的影子。这些组合数学恒等式用定义直接证明往往非常复杂，if not impossible；对于难以使用组合数定义直接证明的恒等式，另一种方法是采用归纳法证明，但是数学归纳法只管证明，却很难展示出等式背后的数学含义和背景。而一旦从多项式出发，困难则迎刃而解，而且往往能很好地揭示看出恒等式背后的数学根源。可以说，组合数学恒等式的赞歌，便是一曲多项式的赞歌。 事实上，多项式对组合数学的贡献并不止步于此。数学家们不满足于用多项式仅仅来证明几个恒等式，随后又发明了生成函数，找到了将多项式直接应用于组合数学的方法。简单来说，数一个多项式展开式中某个 $x^n$ 项的数量（即 $x^n$ 项的系数），就刚好对应了「多项式的各个因子乘起来，有多少种组合方式能得到 $x^n$」，从而可以对应许多 nontrivial 组合计数问题的答案。这一方法不仅仅是将组合数学问题 encode 到多项式中那么简单，它更意味着我们可以利用多项式的丰富的代数性质来进行运算，例如求导、泰勒展开等等。多项式本为代数（algebraic）对象，但通过 exploit（有意或刻意地利用）其算数（arithmetic）性质，数学家得以极大的扩展组合数学的计算方法。可以说，组合数学的赞歌，便是一曲多项式的赞歌。 生成函数又是一个大坑。除了组合数学，生成函数在数列、特殊函数、概率论等领域都有不亚于组合数学中重要性的应用。 也许以后能再开笔记专门讨论生成函数；这里就不展开了。 最后，我将各个恒等式的背景和它们之间的关系梳理成图，以供参考。 组合数恒等式间的关系 参考文献本文中选取的部分恒等式参考了如下文章。 [1] 【组合数学】组合恒等式总结 ( 十一个组合恒等式 | 组合恒等式证明方法 | 求和方法 ) ★，by 韩曙亮，2020 年发布于 CSDN，https://blog.csdn.net/shulianghan/article/details/109180924.","link":"/2024/07/27/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6%E4%B8%AD%E7%9A%84%E6%81%92%E7%AD%89%E5%BC%8F/"}],"tags":[{"name":"数学","slug":"数学","link":"/tags/%E6%95%B0%E5%AD%A6/"},{"name":"论文笔记","slug":"论文笔记","link":"/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"量子计算","slug":"量子计算","link":"/tags/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/"},{"name":"量子通信","slug":"量子通信","link":"/tags/%E9%87%8F%E5%AD%90%E9%80%9A%E4%BF%A1/"},{"name":"等比数列","slug":"等比数列","link":"/tags/%E7%AD%89%E6%AF%94%E6%95%B0%E5%88%97/"},{"name":"视频","slug":"视频","link":"/tags/%E8%A7%86%E9%A2%91/"},{"name":"量子力学","slug":"量子力学","link":"/tags/%E9%87%8F%E5%AD%90%E5%8A%9B%E5%AD%A6/"},{"name":"电子","slug":"电子","link":"/tags/%E7%94%B5%E5%AD%90/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"原子核","slug":"原子核","link":"/tags/%E5%8E%9F%E5%AD%90%E6%A0%B8/"},{"name":"游戏","slug":"游戏","link":"/tags/%E6%B8%B8%E6%88%8F/"},{"name":"建模","slug":"建模","link":"/tags/%E5%BB%BA%E6%A8%A1/"},{"name":"约束求解","slug":"约束求解","link":"/tags/%E7%BA%A6%E6%9D%9F%E6%B1%82%E8%A7%A3/"},{"name":"积分","slug":"积分","link":"/tags/%E7%A7%AF%E5%88%86/"},{"name":"组合数学","slug":"组合数学","link":"/tags/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/"}],"categories":[]}